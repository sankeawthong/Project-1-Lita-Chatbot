{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNZPzNI8kEBAA8utqokwKw2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankeawthong/Project-1-Lita-Chatbot/blob/main/%5B20251021%5D%20Train_all_in_one%20%E2%80%94%20Full%20revision%20with%20derived%20features%20Calibrated%20%26%20Adversarially%20Robust%20IDS%20for%20IoT/IoMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[20251021] Train_all_in_one — Full revision with derived features\n",
        "Calibrated & Adversarially Robust IDS for IoT/IoMT: LR→MLP (Edge–Cloud)\n",
        "This script retrains the full LR→MLP pipeline end-to-end for:\n",
        "*   CIC_IoMT tiny-slice protocol\n",
        "*   NF-ToN-IoT in-domain protocol\n",
        "\n",
        "It reproduces all manuscript figures and exports required results"
      ],
      "metadata": {
        "id": "yXK5N9yiVabY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3XN_enNUD5_"
      },
      "outputs": [],
      "source": [
        "import os, json, zipfile, warnings\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix, auc\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === PATCH: robustness utilities & CIC training with attack pool ===\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================\n",
        "# CONFIGURATION\n",
        "# ====================\n",
        "\n",
        "CIC_CALIB_PATH = \"/content/CIC_tiny_slice_calib (1).csv\"\n",
        "CIC_TEST_PATH  = \"/content/CIC_tiny_slice_test (1).csv\"\n",
        "NF_FULL_PATH   = \"/content/Dataset_NF-ToN-IoT.csv\"\n",
        "OUT_DIR  = Path(\"/content/paper_exports\")\n",
        "MODEL_DIR = Path(\"/content/results_models\")\n",
        "\n",
        "HP = dict(\n",
        "    lr_C=1.0, lr_penalty=\"l2\", lr_max_iter=200,\n",
        "    mlp_hidden=(32,), mlp_alpha=1e-4, mlp_batch_size=512,\n",
        "    mlp_epochs=20, smote_on=True, adv_eps=0.10,\n",
        "    pgd_steps=7, pgd_alpha=0.02, bins_calibration=15\n",
        ")\n",
        "SEED = 42\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "qg0bNUBmVm2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Add this CONFIG path to your header too ----\n",
        "CIC_ATTACK_POOL_PATH = \"/content/CIC_IoMT_2024_WiFi_MQTT_train.csv\"  # attack-only pool\n",
        "\n",
        "def derive_binary_patched(df: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Derive Binary: 0=benign, 1=attack.\n",
        "    Accepts Binary / Class / Label / label. Maps 'o' -> '0', recognizes 'benign' text.\n",
        "    \"\"\"\n",
        "    # 1) Binary column\n",
        "    if \"Binary\" in df.columns:\n",
        "        s = df[\"Binary\"].astype(str).str.strip().str.lower().replace({\"o\":\"0\"})\n",
        "        y = pd.to_numeric(s, errors=\"coerce\")\n",
        "        # If any NaN after coercion, backfill from Class/Label\n",
        "        if y.isna().any():\n",
        "            if \"Class\" in df.columns:\n",
        "                cls = df[\"Class\"].astype(str).str.strip().str.lower().replace({\"o\":\"0\"})\n",
        "                y = y.fillna((cls != \"0\").astype(int))\n",
        "            if \"Label\" in df.columns:\n",
        "                lab = df[\"Label\"].astype(str).str.strip().str.lower()\n",
        "                y = y.fillna((~lab.str.contains(\"benign\")).astype(int))\n",
        "            if \"label\" in df.columns:\n",
        "                lab = df[\"label\"].astype(str).str.strip().str.lower()\n",
        "                y = y.fillna((~lab.str.contains(\"benign\")).astype(int))\n",
        "        return y.fillna(1).astype(int)\n",
        "\n",
        "    # 2) Class numeric\n",
        "    if \"Class\" in df.columns:\n",
        "        cls = df[\"Class\"].astype(str).str.strip().str.lower().replace({\"o\":\"0\"})\n",
        "        return (cls != \"0\").astype(int)\n",
        "\n",
        "    # 3) Label / label textual\n",
        "    for txtcol in (\"Label\",\"label\"):\n",
        "        if txtcol in df.columns:\n",
        "            lab = df[txtcol].astype(str).str.strip().str.lower()\n",
        "            return (~lab.str.contains(\"benign\")).astype(int)\n",
        "\n",
        "    raise ValueError(\"Cannot derive Binary — need one of: Binary, Class, Label/label\")\n",
        "\n",
        "def prepare_Xy_numeric(df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Safer feature builder:\n",
        "    - Build y from patched mapping\n",
        "    - Drop label-ish columns\n",
        "    - Keep numeric columns only (avoids string-to-float errors)\n",
        "    \"\"\"\n",
        "    y = derive_binary_patched(df).values\n",
        "    drop_cols = [c for c in [\"Binary\",\"Label\",\"label\",\"Class\",\"class\"] if c in df.columns]\n",
        "    X = df.drop(columns=drop_cols, errors=\"ignore\")\n",
        "    X = X.select_dtypes(include=[np.number])  # numeric only\n",
        "    return X, y\n",
        "\n",
        "def _safe_smote(X: pd.DataFrame, y: np.ndarray, random_state=42):\n",
        "    \"\"\"Apply SMOTE only if both classes are present and min class >= 2.\"\"\"\n",
        "    classes, counts = np.unique(y, return_counts=True)\n",
        "    if len(classes) < 2:\n",
        "        # single class -> skip SMOTE\n",
        "        return X, y\n",
        "    if counts.min() < 2:\n",
        "        # too few minority samples for SMOTE -> skip\n",
        "        return X, y\n",
        "    return SMOTE(random_state=random_state).fit_resample(X, y)"
      ],
      "metadata": {
        "id": "jY3tgJshYuQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================\n",
        "# UTILITIES\n",
        "# ====================\n",
        "def read_df(path): return pd.read_csv(path, low_memory=False)\n",
        "def derive_binary(df):\n",
        "    if \"Binary\" in df.columns:\n",
        "        s = df[\"Binary\"].astype(str).str.strip().str.lower().replace({\"o\":\"0\"})\n",
        "        y = pd.to_numeric(s, errors=\"coerce\").fillna(1)\n",
        "        return y.astype(int)\n",
        "    if \"Class\" in df.columns:\n",
        "        return (df[\"Class\"].astype(str).str.replace(\"o\",\"0\")!=\"0\").astype(int)\n",
        "    if \"label\" in df.columns:\n",
        "        return (~df[\"label\"].astype(str).str.lower().str.contains(\"benign\")).astype(int)\n",
        "    raise ValueError(\"Cannot derive Binary label\")\n",
        "\n",
        "def prepare_Xy(df):\n",
        "    y = derive_binary(df).values\n",
        "    drop_cols = [c for c in [\"Binary\",\"Label\",\"label\",\"Class\",\"class\"] if c in df.columns]\n",
        "    X = df.drop(columns=drop_cols, errors=\"ignore\")\n",
        "    return X, y\n",
        "\n",
        "def split_nf(df):\n",
        "    if \"Binary\" not in df.columns:\n",
        "        df[\"Binary\"] = derive_binary(df)\n",
        "    tr, tst = train_test_split(df, test_size=0.2, random_state=SEED, stratify=df[\"Binary\"])\n",
        "    cal, _  = train_test_split(tr, test_size=0.9, random_state=SEED, stratify=tr[\"Binary\"])\n",
        "    return cal, tst"
      ],
      "metadata": {
        "id": "Bo0zCXFOV4AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================\n",
        "# PIPELINES\n",
        "# ====================\n",
        "def build_pipe_and_fit(X, y):\n",
        "    pre = ColumnTransformer([(\"num\", Pipeline([\n",
        "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"sc\", StandardScaler())\n",
        "    ]), X.columns)], remainder=\"drop\")\n",
        "    lr = LogisticRegression(C=HP[\"lr_C\"], penalty=HP[\"lr_penalty\"],\n",
        "                            solver=\"lbfgs\", max_iter=HP[\"lr_max_iter\"], random_state=SEED)\n",
        "    pipe = Pipeline([(\"pre\", pre), (\"lr\", lr)])\n",
        "    pipe.fit(X, y)\n",
        "    return pipe, lr\n",
        "\n",
        "def fit_mlp_on_logits(z, y):\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=HP[\"mlp_hidden\"],\n",
        "                        alpha=HP[\"mlp_alpha\"], batch_size=HP[\"mlp_batch_size\"],\n",
        "                        max_iter=HP[\"mlp_epochs\"], random_state=SEED)\n",
        "    mlp.fit(z.reshape(-1,1), y)\n",
        "    return mlp\n",
        "\n",
        "def temperature_fit(z, y, iters=300, lr=0.01):\n",
        "    T = 1.0\n",
        "    for _ in range(iters):\n",
        "        s = 1/(1+np.exp(-(z/T)))\n",
        "        grad = ((s-y)*z).sum()/(T**2+1e-12)\n",
        "        T = max(1e-3, T-lr*grad)\n",
        "    return float(T)"
      ],
      "metadata": {
        "id": "EGChsVCZV5l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================\n",
        "# ADVERSARIAL\n",
        "# ====================\n",
        "def lr_grad(pipe, X, y):\n",
        "    lr = pipe.named_steps[\"lr\"]; pre = pipe.named_steps[\"pre\"]\n",
        "    Xs = pre.transform(X); z = lr.decision_function(X)\n",
        "    s = 1/(1+np.exp(-z)); w = lr.coef_.ravel()\n",
        "    grad = (s-y).reshape(-1,1)*w.reshape(1,-1)\n",
        "    return Xs, grad, w\n",
        "\n",
        "def fgsm(pipe, X, y, T, mlp, iso, eps):\n",
        "    Xs, grad, _ = lr_grad(pipe, X, y)\n",
        "    Xs_adv = Xs + np.sign(grad)*eps\n",
        "    lr = pipe.named_steps[\"lr\"]\n",
        "    z = Xs_adv@lr.coef_.ravel() + lr.intercept_[0]\n",
        "    p_uncal = mlp.predict_proba(z.reshape(-1,1))[:,1]\n",
        "    p_temp = 1/(1+np.exp(-(z/T)))\n",
        "    p_iso = iso.transform(p_uncal)\n",
        "    return dict(z=z, p_uncal=p_uncal, p_temp=p_temp, p_iso=p_iso)"
      ],
      "metadata": {
        "id": "MZQvHVSyV69V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================\n",
        "# EXPORTS\n",
        "# ====================\n",
        "def dump(tag, y, p_uncal, p_temp, p_iso):\n",
        "    pd.DataFrame(dict(y_true=y,p_uncal=p_uncal,p_temp=p_temp,p_iso=p_iso)).to_csv(OUT_DIR/f\"reliability_{tag}.csv\", index=False)\n",
        "def plot_conf(tag, y, p, dr=0.95):\n",
        "    fpr,tpr,thr=roc_curve(y,p); thr=thr[np.argmax(tpr>=dr)]\n",
        "    yhat=(p>=thr).astype(int); tn,fp,fn,tp=confusion_matrix(y,yhat).ravel()\n",
        "    mat=np.array([[tn,fp],[fn,tp]])\n",
        "    plt.imshow(mat); plt.title(tag); plt.savefig(OUT_DIR/f\"conf_{tag}.png\"); plt.close()"
      ],
      "metadata": {
        "id": "BG33CMsKV8Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================\n",
        "# TRAINING\n",
        "# ====================\n",
        "def train_and_export_patched():\n",
        "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # ----- CIC IoMT tiny-slice -----\n",
        "    print(\"[CIC] Loading tiny-slice (benign-only) for calibration & an attack pool for training\")\n",
        "    cic_cal = pd.read_csv(CIC_CALIB_PATH, low_memory=False)\n",
        "    cic_tst = pd.read_csv(CIC_TEST_PATH, low_memory=False)\n",
        "    if not Path(CIC_ATTACK_POOL_PATH).exists():\n",
        "        raise FileNotFoundError(f\"CIC attack pool not found at {CIC_ATTACK_POOL_PATH}\")\n",
        "\n",
        "    cic_attack_pool = pd.read_csv(CIC_ATTACK_POOL_PATH, low_memory=False)\n",
        "\n",
        "    # Build labels\n",
        "    y_cal = derive_binary_patched(cic_cal).values\n",
        "    y_test = derive_binary_patched(cic_tst).values\n",
        "    y_pool = derive_binary_patched(cic_attack_pool).values\n",
        "\n",
        "    # Split into benign/attack pools\n",
        "    cal_ben = cic_cal[y_cal == 0]\n",
        "    pool_att = cic_attack_pool[y_pool == 1]\n",
        "\n",
        "    if len(cal_ben) == 0:\n",
        "        raise ValueError(\"CIC_tiny_slice_calib.csv does not contain benign rows after mapping.\")\n",
        "\n",
        "    if len(pool_att) == 0:\n",
        "        raise ValueError(\"CIC attack pool has no attack rows after mapping. Provide a valid attack CSV.\")\n",
        "\n",
        "    # Sample a modest number of attacks to pair with benign tiny-slice\n",
        "    # Strategy: equal number to benign (cap to avoid heavy training)\n",
        "    n_ben = len(cal_ben)\n",
        "    n_att = min(len(pool_att), n_ben)  # balance\n",
        "    att_sample = pool_att.sample(n=n_att, random_state=SEED)\n",
        "\n",
        "    # Build CIC train set: benign (from tiny-slice) + attacks (from pool)\n",
        "    cic_train_df = pd.concat([cal_ben, att_sample], axis=0, ignore_index=True)\n",
        "    X_cic_tr, y_cic_tr = prepare_Xy_numeric(cic_train_df)\n",
        "    X_cic_te, y_cic_te = prepare_Xy_numeric(cic_tst)\n",
        "\n",
        "    print(f\"[CIC] Train shapes: X={X_cic_tr.shape}, y counts={np.unique(y_cic_tr, return_counts=True)}\")\n",
        "    print(f\"[CIC] Test  shapes: X={X_cic_te.shape}, y counts={np.unique(y_cic_te, return_counts=True)}\")\n",
        "\n",
        "    # Preproc + LR\n",
        "    X_bal, y_bal = (_safe_smote(X_cic_tr, y_cic_tr, random_state=SEED) if HP.get(\"smote_on\", True) else (X_cic_tr, y_cic_tr))\n",
        "    cic_pipe, cic_lr = build_pipe_and_fit(X_bal, y_bal)\n",
        "\n",
        "    # MLP on logits\n",
        "    z_tr = cic_pipe.decision_function(X_cic_tr).ravel()\n",
        "    cic_mlp = fit_mlp_on_logits(z_tr, y_cic_tr)\n",
        "\n",
        "    # Calibrators: use a small calibration mix (benign from tiny-slice + a small attack subset)\n",
        "    n_cal_att = min(len(att_sample), max(50, len(cal_ben)//2))\n",
        "    cal_mix_df = pd.concat([cal_ben, att_sample.sample(n=n_cal_att, random_state=SEED)], axis=0, ignore_index=True)\n",
        "    X_cal_mix, y_cal_mix = prepare_Xy_numeric(cal_mix_df)\n",
        "\n",
        "    z_cal = cic_pipe.decision_function(X_cal_mix).ravel()\n",
        "    T_cic = temperature_fit(z_cal, y_cal_mix)\n",
        "    p_uncal_cal = cic_mlp.predict_proba(z_cal.reshape(-1,1))[:,1]\n",
        "    iso_cic = IsotonicRegression(out_of_bounds='clip').fit(p_uncal_cal, y_cal_mix)\n",
        "\n",
        "    # Save deployables\n",
        "    joblib.dump(cic_pipe, MODEL_DIR/\"CIC_tiny_slice_pipe.joblib\")\n",
        "    joblib.dump(cic_mlp,  MODEL_DIR/\"CIC_tiny_slice_mlp.joblib\")\n",
        "\n",
        "    # Clean eval & exports\n",
        "    z_te = cic_pipe.decision_function(X_cic_te).ravel()\n",
        "    p_uncal = cic_mlp.predict_proba(z_te.reshape(-1,1))[:,1]\n",
        "    p_temp  = 1/(1+np.exp(-(z_te/T_cic)))\n",
        "    p_iso   = iso_cic.transform(p_uncal)\n",
        "\n",
        "    pd.DataFrame({\"y_true\":y_cic_te,\"p_uncal\":p_uncal,\"p_temp\":p_temp,\"p_iso\":p_iso}).to_csv(OUT_DIR/\"reliability_cic_clean.csv\", index=False)\n",
        "\n",
        "    def _plot_conf(tag, y, p, dr=0.95):\n",
        "        fpr,tpr,thr = roc_curve(y,p); thr = thr[np.argmax(tpr>=dr)]\n",
        "        yhat=(p>=thr).astype(int); tn,fp,fn,tp=confusion_matrix(y,yhat).ravel()\n",
        "        mat=np.array([[tn,fp],[fn,tp]])\n",
        "        plt.figure(figsize=(3.4,3.0)); plt.imshow(mat)\n",
        "        for i in range(2):\n",
        "            for j in range(2):\n",
        "                plt.text(j,i,str(mat[i,j]),ha=\"center\",va=\"center\",color=\"white\" if mat[i,j]>0 else \"black\")\n",
        "        plt.title(f\"Confusion @DR=0.95: {tag}\"); plt.tight_layout()\n",
        "        plt.savefig(OUT_DIR/f\"confusion_{tag}.png\", dpi=200); plt.close()\n",
        "\n",
        "    _plot_conf(\"cic_clean\", y_cic_te, p_temp)\n",
        "\n",
        "    # ----- NF-ToN-IoT in-domain (unchanged, but ensure numeric-only features) -----\n",
        "    df_nf = pd.read_csv(NF_FULL_PATH, low_memory=False)\n",
        "    # derive binary\n",
        "    if \"Binary\" not in df_nf.columns:\n",
        "        df_nf[\"Binary\"] = derive_binary_patched(df_nf)\n",
        "\n",
        "    nf_tr, nf_tst = train_test_split(df_nf, test_size=0.2, random_state=SEED, stratify=df_nf[\"Binary\"])\n",
        "    nf_cal, _ = train_test_split(nf_tr, test_size=0.9, random_state=SEED, stratify=nf_tr[\"Binary\"])\n",
        "\n",
        "    X_nf_tr, y_nf_tr = prepare_Xy_numeric(nf_cal)\n",
        "    X_nf_te, y_nf_te = prepare_Xy_numeric(nf_tst)\n",
        "\n",
        "    X_nf_bal, y_nf_bal = (_safe_smote(X_nf_tr, y_nf_tr, random_state=SEED) if HP.get(\"smote_on\", True) else (X_nf_tr, y_nf_tr))\n",
        "    nf_pipe, nf_lr = build_pipe_and_fit(X_nf_bal, y_nf_bal)\n",
        "\n",
        "    z_nf_tr = nf_pipe.decision_function(X_nf_tr).ravel()\n",
        "    nf_mlp = fit_mlp_on_logits(z_nf_tr, y_nf_tr)\n",
        "\n",
        "    T_nf = temperature_fit(z_nf_tr, y_nf_tr)\n",
        "    p_uncal_nf_tr = nf_mlp.predict_proba(z_nf_tr.reshape(-1,1))[:,1]\n",
        "    iso_nf = IsotonicRegression(out_of_bounds='clip').fit(p_uncal_nf_tr, y_nf_tr)\n",
        "\n",
        "    joblib.dump(nf_pipe, MODEL_DIR/\"NF_in_domain_pipe.joblib\")\n",
        "    joblib.dump(nf_mlp,  MODEL_DIR/\"NF_in_domain_mlp.joblib\")\n",
        "\n",
        "    z_nf_te = nf_pipe.decision_function(X_nf_te).ravel()\n",
        "    p_uncal_nf = nf_mlp.predict_proba(z_nf_te.reshape(-1,1))[:,1]\n",
        "    p_temp_nf  = 1/(1+np.exp(-(z_nf_te/T_nf)))\n",
        "    p_iso_nf   = iso_nf.transform(p_uncal_nf)\n",
        "\n",
        "    pd.DataFrame({\"y_true\":y_nf_te,\"p_uncal\":p_uncal_nf,\"p_temp\":p_temp_nf,\"p_iso\":p_iso_nf}).to_csv(OUT_DIR/\"reliability_nf_clean.csv\", index=False)\n",
        "\n",
        "    print(\"[DONE] Patched training finished. Artifacts in:\", OUT_DIR)\n",
        "\n",
        "# === Run the patched entrypoint instead of original ===\n",
        "train_and_export_patched()"
      ],
      "metadata": {
        "id": "MWhVzxY1V9cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Post-training exports (add-on) ===\n",
        "import numpy as np, pandas as pd, joblib, json\n",
        "from pathlib import Path\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.calibration import CalibrationDisplay\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Inputs (same as training)\n",
        "CIC_CALIB_PATH = \"/content/CIC_tiny_slice_calib (1).csv\"\n",
        "CIC_TEST_PATH  = \"/content/CIC_tiny_slice_test (1).csv\"\n",
        "NF_FULL_PATH   = \"/content/Dataset_NF-ToN-IoT.csv\"\n",
        "\n",
        "# Models\n",
        "MODEL_DIR = Path(\"/content/results_models\")\n",
        "cic_pipe   = joblib.load(MODEL_DIR/\"CIC_tiny_slice_pipe.joblib\")\n",
        "cic_mlp    = joblib.load(MODEL_DIR/\"CIC_tiny_slice_mlp.joblib\")\n",
        "nf_pipe    = joblib.load(MODEL_DIR/\"NF_in_domain_pipe.joblib\")\n",
        "nf_mlp     = joblib.load(MODEL_DIR/\"NF_in_domain_mlp.joblib\")\n",
        "\n",
        "OUT_DIR = Path(\"/content/paper_exports\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Utils (match training’s label handling & numeric-only features)\n",
        "def derive_binary(df: pd.DataFrame) -> pd.Series:\n",
        "    if \"Binary\" in df.columns:\n",
        "        s = df[\"Binary\"].astype(str).str.strip().str.lower().replace({\"o\":\"0\"})\n",
        "        y = pd.to_numeric(s, errors=\"coerce\")\n",
        "        # backfills\n",
        "        if y.isna().any() and \"Class\" in df.columns:\n",
        "            cls = df[\"Class\"].astype(str).str.strip().str.lower().replace({\"o\":\"0\"})\n",
        "            y = y.fillna((cls != \"0\").astype(int))\n",
        "        if y.isna().any() and \"Label\" in df.columns:\n",
        "            lab = df[\"Label\"].astype(str).str.strip().str.lower()\n",
        "            y = y.fillna((~lab.str.contains(\"benign\")).astype(int))\n",
        "        if y.isna().any() and \"label\" in df.columns:\n",
        "            lab = df[\"label\"].astype(str).str.strip().str.lower()\n",
        "            y = y.fillna((~lab.str.contains(\"benign\")).astype(int))\n",
        "        return y.fillna(1).astype(int)\n",
        "    if \"Class\" in df.columns:\n",
        "        return (df[\"Class\"].astype(str).str.replace(\"o\",\"0\")!=\"0\").astype(int)\n",
        "    if \"label\" in df.columns:\n",
        "        return (~df[\"label\"].astype(str).str.lower().str.contains(\"benign\")).astype(int)\n",
        "    raise ValueError(\"Cannot derive Binary label\")\n",
        "\n",
        "def prepare_Xy_numeric(df):\n",
        "    y = derive_binary(df).values\n",
        "    X = df.drop(columns=[c for c in [\"Binary\",\"Label\",\"label\",\"Class\",\"class\"] if c in df.columns], errors=\"ignore\")\n",
        "    X = X.select_dtypes(include=[np.number])\n",
        "    return X, y\n",
        "\n",
        "# Re-create calibration objects (T and isotonic) from calibration sets\n",
        "def fit_calibrators(pipe, mlp, cal_df):\n",
        "    Xc, yc = prepare_Xy_numeric(cal_df)\n",
        "    z = pipe.decision_function(Xc).ravel()\n",
        "    # temperature\n",
        "    T = 1.0\n",
        "    for _ in range(300):\n",
        "        s = 1/(1+np.exp(-(z/T))); grad = ((s-yc)*z).sum()/(T**2 + 1e-12); T = max(1e-3, T - 0.01*grad)\n",
        "    # isotonic on uncal MLP probs\n",
        "    p_uncal = mlp.predict_proba(z.reshape(-1,1))[:,1]\n",
        "    iso = IsotonicRegression(out_of_bounds=\"clip\").fit(p_uncal, yc)\n",
        "    return T, iso\n",
        "\n",
        "def predict_variants(pipe, mlp, X_df, T, iso):\n",
        "    z = pipe.decision_function(X_df).ravel()\n",
        "    p_uncal = mlp.predict_proba(z.reshape(-1,1))[:,1]\n",
        "    p_temp  = 1/(1+np.exp(-(z/T)))\n",
        "    p_iso   = iso.transform(p_uncal)\n",
        "    return z, p_uncal, p_temp, p_iso\n",
        "\n",
        "def thr_at_dr(y, scores, dr=0.95):\n",
        "    fpr, tpr, thr = roc_curve(y, scores)\n",
        "    idx = np.argmax(tpr >= dr)\n",
        "    return thr[idx] if idx < len(thr) else thr[-1]\n",
        "\n",
        "def plot_conf(tag, y, scores, dr=0.95):\n",
        "    thr = thr_at_dr(y, scores, dr)\n",
        "    yhat = (scores >= thr).astype(int)\n",
        "    tn, fp, fn, tp = confusion_matrix(y, yhat).ravel()\n",
        "    mat = np.array([[tn,fp],[fn,tp]])\n",
        "    plt.figure(figsize=(3.4,3.0)); plt.imshow(mat)\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            plt.text(j,i,str(mat[i,j]),ha=\"center\",va=\"center\",color=\"white\" if mat[i,j]>0 else \"black\")\n",
        "    plt.xticks([0,1],[\"Pred 0\",\"Pred 1\"]); plt.yticks([0,1],[\"True 0\",\"True 1\"])\n",
        "    plt.title(f\"Confusion @DR=0.95: {tag}\"); plt.tight_layout()\n",
        "    plt.savefig(OUT_DIR/f\"confusion_{tag}.png\", dpi=200); plt.close()\n",
        "\n",
        "def plot_reliability_png(tag, y, p_uncal, p_temp, p_iso, n_bins=15):\n",
        "    plt.figure(figsize=(4.8,3.6))\n",
        "    CalibrationDisplay.from_predictions(y, p_uncal, n_bins=n_bins, name=\"Uncal\", strategy=\"uniform\")\n",
        "    CalibrationDisplay.from_predictions(y, p_temp,  n_bins=n_bins, name=\"Temp\",  strategy=\"uniform\")\n",
        "    CalibrationDisplay.from_predictions(y, p_iso,   n_bins=n_bins, name=\"Isotonic\", strategy=\"uniform\")\n",
        "    plt.title(f\"Reliability: {tag}\"); plt.tight_layout()\n",
        "    plt.savefig(OUT_DIR/f\"reliability_{tag}.png\", dpi=200); plt.close()\n",
        "\n",
        "def plot_roc_pr_overlays(tag, y_clean, p_clean, y_fgsm=None, p_fgsm=None, y_pgd=None, p_pgd=None):\n",
        "    # ROC\n",
        "    plt.figure(figsize=(4.8,3.6))\n",
        "    fpr,tpr,_ = roc_curve(y_clean, p_clean); plt.plot(fpr,tpr,label=\"Clean\")\n",
        "    if y_fgsm is not None: fpr,tpr,_ = roc_curve(y_fgsm, p_fgsm); plt.plot(fpr,tpr,label=\"FGSM\")\n",
        "    if y_pgd  is not None: fpr,tpr,_ = roc_curve(y_pgd,  p_pgd ); plt.plot(fpr,tpr,label=\"PGD\")\n",
        "    plt.plot([0,1],[0,1],'--'); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.legend(); plt.title(f\"ROC: {tag}\")\n",
        "    plt.tight_layout(); plt.savefig(OUT_DIR/f\"roc_overlay_{tag}.png\", dpi=200); plt.close()\n",
        "    # PR\n",
        "    plt.figure(figsize=(4.8,3.6))\n",
        "    rec,pre,_ = precision_recall_curve(y_clean, p_clean); plt.plot(rec,pre,label=\"Clean\")\n",
        "    if y_fgsm is not None: rec,pre,_ = precision_recall_curve(y_fgsm, p_fgsm); plt.plot(rec,pre,label=\"FGSM\")\n",
        "    if y_pgd  is not None: rec,pre,_ = precision_recall_curve(y_pgd,  p_pgd ); plt.plot(rec,pre,label=\"PGD\")\n",
        "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.legend(); plt.title(f\"PR: {tag}\")\n",
        "    plt.tight_layout(); plt.savefig(OUT_DIR/f\"pr_overlay_{tag}.png\", dpi=200); plt.close()\n",
        "\n",
        "def lr_top_pm10(tag, pipe):\n",
        "    lr = pipe.named_steps[\"lr\"]\n",
        "    coefs = lr.coef_.ravel()\n",
        "    # Try to get feature names after preprocessor\n",
        "    try:\n",
        "        feats = pipe.named_steps[\"pre\"].get_feature_names_out()\n",
        "        feats = [f.split(\"__\",1)[-1] for f in feats]\n",
        "    except Exception:\n",
        "        feats = [f\"f{i}\" for i in range(len(coefs))]\n",
        "    order = np.argsort(coefs); idxs = list(order[:10]) + list(order[-10:])\n",
        "    names = [feats[i] if i < len(feats) else f\"f{i}\" for i in idxs]; vals = coefs[idxs]\n",
        "    pd.DataFrame({\"feature\":names,\"coef\":vals}).to_csv(OUT_DIR/f\"lr_top_pm10_{tag}.csv\", index=False)\n",
        "    plt.figure(figsize=(6.2,3.6)); plt.bar(range(len(vals)), vals)\n",
        "    plt.xticks(range(len(vals)), names, rotation=60, ha=\"right\", fontsize=8)\n",
        "    plt.title(f\"LR top ±10: {tag}\"); plt.tight_layout()\n",
        "    plt.savefig(OUT_DIR/f\"lr_top_pm10_{tag}.png\", dpi=200); plt.close()\n",
        "\n",
        "def threshold_stability(tag, y, p_uncal, z, T):\n",
        "    targets = np.linspace(0.80,0.99,20)\n",
        "    fpr_u, fpr_t = [], []\n",
        "    for dr in targets:\n",
        "        fpr, tpr, thr = roc_curve(y, p_uncal); thr_u = thr[np.argmax(tpr>=dr)] if (tpr>=dr).any() else thr[-1]\n",
        "        fpr_u.append(fpr[np.argmax(tpr>=dr)] if (tpr>=dr).any() else fpr[-1])\n",
        "        p_temp = 1/(1+np.exp(-(z/T)))\n",
        "        fpr2, tpr2, thr2 = roc_curve(y, p_temp); thr_t = thr2[np.argmax(tpr2>=dr)] if (tpr2>=dr).any() else thr2[-1]\n",
        "        fpr_t.append(fpr2[np.argmax(tpr2>=dr)] if (tpr2>=dr).any() else fpr2[-1])\n",
        "    plt.figure(figsize=(4.8,3.6))\n",
        "    plt.plot(targets, fpr_u, label=\"Uncalibrated\"); plt.plot(targets, fpr_t, label=\"Temperature\")\n",
        "    plt.xlabel(\"Chosen DR\"); plt.ylabel(\"FPR at DR\"); plt.title(f\"Threshold stability: {tag}\")\n",
        "    plt.legend(); plt.tight_layout(); plt.savefig(OUT_DIR/f\"threshold_stability_{tag}.png\", dpi=200); plt.close()\n",
        "\n",
        "# Adversarial in scaled feature space (same as training logic)\n",
        "def fgsm_scores(pipe, X, y, T, mlp, iso, eps=0.10):\n",
        "    pre = pipe.named_steps[\"pre\"]; lr = pipe.named_steps[\"lr\"]\n",
        "    Xs = pre.transform(X)\n",
        "    z = lr.decision_function(X); s = 1/(1+np.exp(-z)); w = lr.coef_.ravel()\n",
        "    grad = (s - y).reshape(-1,1) * w.reshape(1,-1)\n",
        "    Xs_adv = Xs + np.sign(grad)*eps\n",
        "    z_adv = Xs_adv @ lr.coef_.ravel() + lr.intercept_.ravel()[0]\n",
        "    p_uncal = mlp.predict_proba(z_adv.reshape(-1,1))[:,1]\n",
        "    p_temp  = 1/(1+np.exp(-(z_adv/T)))\n",
        "    p_iso   = iso.transform(p_uncal)\n",
        "    return z_adv, p_uncal, p_temp, p_iso\n",
        "\n",
        "def pgd_scores(pipe, X, y, T, mlp, iso, eps=0.10, alpha=0.02, steps=7):\n",
        "    pre = pipe.named_steps[\"pre\"]; lr = pipe.named_steps[\"lr\"]\n",
        "    Xs = pre.transform(X); Xs_adv = Xs.copy()\n",
        "    for _ in range(steps):\n",
        "        z = Xs_adv @ lr.coef_.ravel() + lr.intercept_.ravel()[0]\n",
        "        s = 1/(1+np.exp(-z)); w = lr.coef_.ravel()\n",
        "        grad = (s - y).reshape(-1,1) * w.reshape(1,-1)\n",
        "        Xs_adv = Xs_adv + np.sign(grad)*alpha\n",
        "        Xs_adv = np.clip(Xs_adv, Xs - eps, Xs + eps)\n",
        "    z_adv = Xs_adv @ lr.coef_.ravel() + lr.intercept_.ravel()[0]\n",
        "    p_uncal = mlp.predict_proba(z_adv.reshape(-1,1))[:,1]\n",
        "    p_temp  = 1/(1+np.exp(-(z_adv/T)))\n",
        "    p_iso   = iso.transform(p_uncal)\n",
        "    return z_adv, p_uncal, p_temp, p_iso\n",
        "\n",
        "# 1) CIC calibrators\n",
        "cic_cal = pd.read_csv(CIC_CALIB_PATH, low_memory=False)\n",
        "cic_tst = pd.read_csv(CIC_TEST_PATH,  low_memory=False)\n",
        "Xc_te, yc_te = prepare_Xy_numeric(cic_tst)\n",
        "T_cic, iso_cic = fit_calibrators(cic_pipe, cic_mlp, cic_cal)\n",
        "\n",
        "# 2) NF calibrators (build from split like in training)\n",
        "df_nf = pd.read_csv(NF_FULL_PATH, low_memory=False)\n",
        "if \"Binary\" not in df_nf.columns:\n",
        "    # derive\n",
        "    if \"Class\" in df_nf.columns:\n",
        "        df_nf[\"Binary\"] = (df_nf[\"Class\"].astype(str).str.replace(\"o\",\"0\")!=\"0\").astype(int)\n",
        "    elif \"Label\" in df_nf.columns:\n",
        "        df_nf[\"Binary\"] = (~df_nf[\"Label\"].astype(str).str.lower().str.contains(\"benign\")).astype(int)\n",
        "    else:\n",
        "        raise ValueError(\"NF needs Binary/Class/Label\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "nf_tr, nf_tst = train_test_split(df_nf, test_size=0.2, random_state=42, stratify=df_nf[\"Binary\"])\n",
        "nf_cal, _ = train_test_split(nf_tr, test_size=0.9, random_state=42, stratify=nf_tr[\"Binary\"])\n",
        "Xn_te, yn_te = prepare_Xy_numeric(nf_tst)\n",
        "T_nf, iso_nf = fit_calibrators(nf_pipe, nf_mlp, nf_cal)\n",
        "\n",
        "# 3) CIC clean + FGSM/PGD exports\n",
        "zc, p_u, p_t, p_i = predict_variants(cic_pipe, cic_mlp, Xc_te, T_cic, iso_cic)\n",
        "pd.DataFrame({\"y_true\":yc_te,\"p_uncal\":p_u,\"p_temp\":p_t,\"p_iso\":p_i}).to_csv(OUT_DIR/\"reliability_cic_clean.csv\", index=False)\n",
        "plot_reliability_png(\"cic_clean\", yc_te, p_u, p_t, p_i, n_bins=15)\n",
        "plot_conf(\"cic_clean\", yc_te, p_t)\n",
        "\n",
        "zc_f, p_uf, p_tf, p_if = fgsm_scores(cic_pipe, Xc_te, yc_te, T_cic, cic_mlp, iso_cic, eps=0.10)\n",
        "zc_p, p_up, p_tp, p_ip = pgd_scores(cic_pipe, Xc_te, yc_te, T_cic, cic_mlp, iso_cic, eps=0.10, alpha=0.02, steps=7)\n",
        "plot_roc_pr_overlays(\"cic_tinyslice\", yc_te, p_t, yc_te, p_tf, yc_te, p_tp)\n",
        "plot_conf(\"cic_pgd010\", yc_te, p_tp)\n",
        "# also dump ROC/PR CSVs\n",
        "fpr,tpr,_ = roc_curve(yc_te, p_t); pd.DataFrame({\"fpr\":fpr,\"tpr\":tpr}).to_csv(OUT_DIR/\"roc_cic_clean.csv\", index=False)\n",
        "rec,pre,_ = precision_recall_curve(yc_te, p_t); pd.DataFrame({\"recall\":rec,\"precision\":pre}).to_csv(OUT_DIR/\"pr_cic_clean.csv\", index=False)\n",
        "\n",
        "# 4) NF clean + FGSM/PGD exports\n",
        "zn, p_un, p_tn, p_in = predict_variants(nf_pipe, nf_mlp, Xn_te, T_nf, iso_nf)\n",
        "pd.DataFrame({\"y_true\":yn_te,\"p_uncal\":p_un,\"p_temp\":p_tn,\"p_iso\":p_in}).to_csv(OUT_DIR/\"reliability_nf_clean.csv\", index=False)\n",
        "plot_reliability_png(\"nf_clean\", yn_te, p_un, p_tn, p_in, n_bins=15)\n",
        "plot_conf(\"nf_clean\", yn_te, p_tn)\n",
        "\n",
        "zn_f, p_unf, p_tnf, p_inf = fgsm_scores(nf_pipe, Xn_te, yn_te, T_nf, nf_mlp, iso_nf, eps=0.10)\n",
        "zn_p, p_unp, p_tnp, p_inp = pgd_scores(nf_pipe, Xn_te, yn_te, T_nf, nf_mlp, iso_nf, eps=0.10, alpha=0.02, steps=7)\n",
        "plot_roc_pr_overlays(\"nf_in_domain\", yn_te, p_tn, yn_te, p_tnf, yn_te, p_tnp)\n",
        "plot_conf(\"nf_pgd010\", yn_te, p_tnp)\n",
        "fpr,tpr,_ = roc_curve(yn_te, p_tn); pd.DataFrame({\"fpr\":fpr,\"tpr\":tpr}).to_csv(OUT_DIR/\"roc_nf_clean.csv\", index=False)\n",
        "rec,pre,_ = precision_recall_curve(yn_te, p_tn); pd.DataFrame({\"recall\":rec,\"precision\":pre}).to_csv(OUT_DIR/\"pr_nf_clean.csv\", index=False)\n",
        "\n",
        "# 5) LR coefficients & threshold stability\n",
        "lr_top_pm10(\"cic_tinyslice\", cic_pipe)\n",
        "threshold_stability(\"cic_tinyslice\", yc_te, p_u, zc, T_cic)\n",
        "lr_top_pm10(\"nf_in_domain\", nf_pipe)\n",
        "threshold_stability(\"nf_in_domain\", yn_te, p_un, zn, T_nf)\n",
        "\n",
        "# 6) Optional manifest + hyperparams sketch (best-effort)\n",
        "hp = {\"adv_eps\":0.10,\"pgd_steps\":7,\"pgd_alpha\":0.02,\"bins\":15}\n",
        "with open(OUT_DIR/\"manifest.json\",\"w\") as f: json.dump({\"models\":[str(p) for p in MODEL_DIR.glob(\"*.joblib\")],\n",
        "                                                        \"fig_dir\":str(OUT_DIR), \"hp\":hp}, f, indent=2)\n",
        "print(\"[OK] All add-on exports written to:\", OUT_DIR)"
      ],
      "metadata": {
        "id": "BrpNbuEYcHrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "OUT = Path(\"/content/paper_exports\"); OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) Hyperparams ledger\n",
        "hp = {\n",
        "  \"lr_C\": 1.0, \"lr_penalty\": \"l2\", \"lr_max_iter\": 200,\n",
        "  \"mlp_hidden\": \"(32,)\", \"mlp_alpha\": 1e-4, \"mlp_batch\": 512, \"mlp_epochs\": 20,\n",
        "  \"SMOTE\": True, \"adv_eps\": 0.10, \"pgd_steps\": 7, \"pgd_alpha\": 0.02, \"seed\": 42\n",
        "}\n",
        "pd.DataFrame([hp]).to_csv(OUT/\"hyperparams.csv\", index=False)\n",
        "\n",
        "# 2) Save adversarial ROC/PR CSVs, reusing the reliability + overlays if present\n",
        "# If you have p_temp for FGSM/PGD in memory, write them; otherwise skip silently.\n",
        "# (If you want, I can give you a small cell to recompute p_temp_FGSM/PGD and dump here.)\n",
        "print(\"Extras written:\", OUT/\"hyperparams.csv\")"
      ],
      "metadata": {
        "id": "UoEFHtIO_9MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Minimal add-on: write adversarial reliability + confusion-inputs + ROC/PR CSVs ===\n",
        "import numpy as np, pandas as pd, joblib\n",
        "from pathlib import Path\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve\n",
        "\n",
        "OUT = Path(\"/content/paper_exports\"); OUT.mkdir(parents=True, exist_ok=True)\n",
        "MODELS = Path(\"/content/results_models\")\n",
        "\n",
        "# Reuse your paths\n",
        "CIC_CAL = \"/content/CIC_tiny_slice_calib (1).csv\"\n",
        "CIC_TST = \"/content/CIC_tiny_slice_test (1).csv\"\n",
        "NF_FULL = \"/content/Dataset_NF-ToN-IoT.csv\"\n",
        "\n",
        "# --- utils (match training) ---\n",
        "def derive_binary(df):\n",
        "    if \"Binary\" in df.columns:\n",
        "        s = df[\"Binary\"].astype(str).str.strip().str.lower().replace({\"o\":\"0\"})\n",
        "        y = pd.to_numeric(s, errors=\"coerce\")\n",
        "        if y.isna().any() and \"Class\" in df.columns:\n",
        "            y = y.fillna((df[\"Class\"].astype(str).str.replace(\"o\",\"0\")!=\"0\").astype(int))\n",
        "        if y.isna().any() and \"Label\" in df.columns:\n",
        "            y = y.fillna((~df[\"Label\"].astype(str).str.lower().str.contains(\"benign\")).astype(int))\n",
        "        return y.fillna(1).astype(int)\n",
        "    if \"Class\" in df.columns:\n",
        "        return (df[\"Class\"].astype(str).str.replace(\"o\",\"0\")!=\"0\").astype(int)\n",
        "    if \"label\" in df.columns:\n",
        "        return (~df[\"label\"].astype(str).str.lower().str.contains(\"benign\")).astype(int)\n",
        "    raise ValueError(\"No label column\")\n",
        "def Xy_numeric(df):\n",
        "    y = derive_binary(df).values\n",
        "    X = df.drop(columns=[c for c in [\"Binary\",\"Label\",\"label\",\"Class\",\"class\"] if c in df.columns], errors=\"ignore\")\n",
        "    return X.select_dtypes(include=[np.number]), y\n",
        "def temp_fit(z,y,steps=300,lr=0.01):\n",
        "    T=1.0; z=z.ravel(); y=y.astype(int).ravel()\n",
        "    for _ in range(steps):\n",
        "        s=1/(1+np.exp(-(z/T))); T=max(1e-3, T - lr*((s-y)*z).sum()/(T**2+1e-12))\n",
        "    return T\n",
        "def cal_objs(pipe, mlp, calib_df):\n",
        "    Xc,yc = Xy_numeric(calib_df); z = pipe.decision_function(Xc).ravel()\n",
        "    T = temp_fit(z,yc)\n",
        "    p_uncal = mlp.predict_proba(z.reshape(-1,1))[:,1]\n",
        "    iso = IsotonicRegression(out_of_bounds=\"clip\").fit(p_uncal, yc)\n",
        "    return T, iso\n",
        "def scores(pipe, mlp, X, T, iso):\n",
        "    z = pipe.decision_function(X).ravel()\n",
        "    p_u = mlp.predict_proba(z.reshape(-1,1))[:,1]\n",
        "    p_t = 1/(1+np.exp(-(z/T)))\n",
        "    p_i = iso.transform(p_u)\n",
        "    return z, p_u, p_t, p_i\n",
        "def fgsm(pipe, X, y, T, mlp, iso, eps=0.10):\n",
        "    pre = pipe.named_steps[\"pre\"]; lr = pipe.named_steps[\"lr\"]\n",
        "    Xs = pre.transform(X); z = lr.decision_function(X); s=1/(1+np.exp(-z)); w = lr.coef_.ravel()\n",
        "    grad=(s-y).reshape(-1,1)*w.reshape(1,-1); Xs_adv = Xs + np.sign(grad)*eps\n",
        "    z_adv = Xs_adv @ lr.coef_.ravel() + lr.intercept_.ravel()[0]\n",
        "    p_u = mlp.predict_proba(z_adv.reshape(-1,1))[:,1]; p_t = 1/(1+np.exp(-(z_adv/T))); p_i = iso.transform(p_u)\n",
        "    return z_adv, p_u, p_t, p_i\n",
        "def pgd(pipe, X, y, T, mlp, iso, eps=0.10, alpha=0.02, steps=7):\n",
        "    pre = pipe.named_steps[\"pre\"]; lr = pipe.named_steps[\"lr\"]\n",
        "    Xs = pre.transform(X); Xs_adv = Xs.copy()\n",
        "    for _ in range(steps):\n",
        "        z = Xs_adv @ lr.coef_.ravel() + lr.intercept_.ravel()[0]\n",
        "        s = 1/(1+np.exp(-z)); w = lr.coef_.ravel()\n",
        "        grad = (s-y).reshape(-1,1) * w.reshape(1,-1)\n",
        "        Xs_adv = np.clip(Xs_adv + np.sign(grad)*alpha, Xs - eps, Xs + eps)\n",
        "    z_adv = Xs_adv @ lr.coef_.ravel() + lr.intercept_.ravel()[0]\n",
        "    p_u = mlp.predict_proba(z_adv.reshape(-1,1))[:,1]; p_t = 1/(1+np.exp(-(z_adv/T))); p_i = iso.transform(p_u)\n",
        "    return z_adv, p_u, p_t, p_i\n",
        "def save_reliability(tag, y, p_u, p_t, p_i):\n",
        "    pd.DataFrame({\"y_true\":y, \"p_uncal\":p_u, \"p_temp\":p_t, \"p_iso\":p_i}).to_csv(OUT/f\"reliability_{tag}.csv\", index=False)\n",
        "def save_curves(tag, y, p):\n",
        "    fpr,tpr,_ = roc_curve(y,p); pd.DataFrame({\"fpr\":fpr,\"tpr\":tpr}).to_csv(OUT/f\"roc_{tag}.csv\", index=False)\n",
        "    rec,pre,_ = precision_recall_curve(y,p); pd.DataFrame({\"recall\":rec,\"precision\":pre}).to_csv(OUT/f\"pr_{tag}.csv\", index=False)\n",
        "def save_conf_inputs(tag, y, p_t):\n",
        "    pd.DataFrame({\"y_true\":y, \"p_temp\":p_t}).to_csv(OUT/f\"confusion_inputs_{tag}.csv\", index=False)\n",
        "\n",
        "# Load models\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve\n",
        "cic_pipe = joblib.load(MODELS/\"CIC_tiny_slice_pipe.joblib\")\n",
        "cic_mlp  = joblib.load(MODELS/\"CIC_tiny_slice_mlp.joblib\")\n",
        "nf_pipe  = joblib.load(MODELS/\"NF_in_domain_pipe.joblib\")\n",
        "nf_mlp   = joblib.load(MODELS/\"NF_in_domain_mlp.joblib\")\n",
        "\n",
        "# CIC\n",
        "cic_cal = pd.read_csv(CIC_CAL, low_memory=False)\n",
        "cic_tst = pd.read_csv(CIC_TST, low_memory=False)\n",
        "Xc, yc = Xy_numeric(cic_tst)\n",
        "T_cic, iso_cic = cal_objs(cic_pipe, cic_mlp, cic_cal)\n",
        "# PGD(ε=0.10)\n",
        "zc_p, puc_p, pt_p, pis_p = pgd(cic_pipe, Xc, yc, T_cic, cic_mlp, iso_cic, eps=0.10, alpha=0.02, steps=7)\n",
        "save_reliability(\"cic_pgd010\", yc, puc_p, pt_p, pis_p)\n",
        "save_conf_inputs(\"cic_pgd010\", yc, pt_p)\n",
        "save_curves(\"cic_pgd010\", yc, pt_p)\n",
        "# Clean confusion inputs too\n",
        "_, puc_c, pt_c, _ = scores(cic_pipe, cic_mlp, Xc, T_cic, iso_cic)\n",
        "save_conf_inputs(\"cic_clean\", yc, pt_c)\n",
        "\n",
        "# NF\n",
        "df_nf = pd.read_csv(NF_FULL, low_memory=False)\n",
        "# build split as in training\n",
        "if \"Binary\" not in df_nf.columns:\n",
        "    if \"Class\" in df_nf.columns:\n",
        "        df_nf[\"Binary\"] = (df_nf[\"Class\"].astype(str).str.replace(\"o\",\"0\")!=\"0\").astype(int)\n",
        "    elif \"Label\" in df_nf.columns:\n",
        "        df_nf[\"Binary\"] = (~df_nf[\"Label\"].astype(str).str.lower().str.contains(\"benign\")).astype(int)\n",
        "from sklearn.model_selection import train_test_split\n",
        "tr, tst = train_test_split(df_nf, test_size=0.2, random_state=42, stratify=df_nf[\"Binary\"])\n",
        "cal, _  = train_test_split(tr, test_size=0.9, random_state=42, stratify=tr[\"Binary\"])\n",
        "Xn, yn = Xy_numeric(tst)\n",
        "T_nf, iso_nf = cal_objs(nf_pipe, nf_mlp, cal)\n",
        "# PGD(ε=0.10)\n",
        "zn_p, pun_p, pt_n_p, pis_n_p = pgd(nf_pipe, Xn, yn, T_nf, nf_mlp, iso_nf, eps=0.10, alpha=0.02, steps=7)\n",
        "save_reliability(\"nf_pgd010\", yn, pun_p, pt_n_p, pis_n_p)\n",
        "save_conf_inputs(\"nf_pgd010\", yn, pt_n_p)\n",
        "save_curves(\"nf_pgd010\", yn, pt_n_p)\n",
        "# Clean confusion inputs too\n",
        "_, pun_c, pt_n_c, _ = scores(nf_pipe, nf_mlp, Xn, T_nf, iso_nf)\n",
        "save_conf_inputs(\"nf_clean\", yn, pt_n_c)\n",
        "\n",
        "print(\"Wrote missing artifacts to:\", OUT)"
      ],
      "metadata": {
        "id": "tofLBsEADabW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}