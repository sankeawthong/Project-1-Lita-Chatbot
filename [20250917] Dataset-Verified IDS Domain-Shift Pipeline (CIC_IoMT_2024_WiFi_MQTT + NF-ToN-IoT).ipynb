{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMSQU8vch7PQzAKVLMob8Rh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankeawthong/Project-1-Lita-Chatbot/blob/main/%5B20250917%5D%20Dataset-Verified%20IDS%20Domain-Shift%20Pipeline%20(CIC_IoMT_2024_WiFi_MQTT%20%2B%20NF-ToN-IoT).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset-Verified IDS Domain-Shift Pipeline (CIC_IoMT_2024_WiFi_MQTT + NF-ToN-IoT)\n",
        "- Uses actual columns detected from the provided files\n",
        "- Builds class-family mapping from string labels (e.g., \"label\", \"Attack\")\n",
        "- Implements MQTT filtering on NF-ToN-IoT via L4_DST_PORT\n",
        "- Trains ablations: LR-only, BiLSTM-only, LR->BiLSTM (+ optional adversarial mixing)\n",
        "- Reports Macro-F1, per-class Recall, AUROC/PR-AUC, calibration (ECE/MCE), and FPR@1e-3/1e-4\n",
        "\n",
        "Author: Sine & Mentor"
      ],
      "metadata": {
        "id": "OdVnKpnEVwHE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "q3ETdjQQVJ56"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import math\n",
        "import time\n",
        "import warnings\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, label_binarize\n",
        "from sklearn.metrics import (f1_score, recall_score, roc_auc_score, average_precision_score,\n",
        "                             roc_curve)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers, callbacks\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Config (set to your files)\n",
        "# ----------------------------\n",
        "CONFIG = {\n",
        "    \"NF_TON_IOT_CSV\": \"Dataset_NF-ToN-IoT.csv\",                 # provided\n",
        "    \"CIC_IOMT_TRAIN_CSV\": \"CIC_IoMT_2024_WiFi_MQTT_train.csv\",  # provided\n",
        "    \"CIC_IOMT_TEST_CSV\":  \"CIC_IoMT_2024_WiFi_MQTT_test.csv\",   # provided\n",
        "    # Column names (verified)\n",
        "    \"NF_NUMERIC_CLASS_COL\": \"Class\",      # 0..9 (0=benign)\n",
        "    \"NF_TEXT_LABEL_COL\": \"Attack\",        # string names: 'Benign','ddos','dos','scanning',...\n",
        "    \"CIC_CLASS_COL\": \"Class\",             # numeric id in both train/test\n",
        "    \"CIC_TEXT_LABEL_COL\": \"label\",        # string like 'TCP_IP-DDoS-UDP2_train'\n",
        "    # Port column for MQTT filtering\n",
        "    \"NF_DST_PORT_COL\": \"L4_DST_PORT\",\n",
        "    \"MQTT_PORTS\": [1883, 8883],\n",
        "    # Experiment toggles\n",
        "    \"SEED\": 42,\n",
        "    \"EPOCHS\": 30,\n",
        "    \"BATCH_SIZE\": 128,\n",
        "    \"LEARNING_RATE\": 1e-3,\n",
        "    \"PATIENCE\": 5,\n",
        "    \"RESAMPLING\": \"none\",                 # \"none\" | \"smote_tomek\"\n",
        "    \"LOSS_MODE\": \"class_balanced_ce\",     # \"ce\" | \"class_balanced_ce\" | \"focal\"\n",
        "    \"USE_ADV_TRAINING\": True,\n",
        "    \"ADV_METHOD\": \"fgsm\",                 # \"fgsm\" | \"pgd\"\n",
        "    \"FGSM_EPS\": 0.05,\n",
        "    \"PGD_EPS\": 0.03,\n",
        "    \"PGD_STEPS\": 5,\n",
        "    \"PGD_ALPHA\": 0.01,\n",
        "    \"ADV_RATIO\": 0.5,\n",
        "    \"OUTDIR\": \"./outputs\"\n",
        "}\n",
        "\n",
        "np.random.seed(CONFIG[\"SEED\"])\n",
        "tf.random.set_seed(CONFIG[\"SEED\"])\n",
        "os.makedirs(CONFIG[\"OUTDIR\"], exist_ok=True)"
      ],
      "metadata": {
        "id": "7bVeR4liVQ8e"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Family mapping from strings\n",
        "# ----------------------------\n",
        "FAMILIES = [\"Benign\", \"DoS_DDoS\", \"Recon_Scan\", \"MQTT\", \"Spoof\", \"Other\"]\n",
        "\n",
        "def map_label_string_to_family(s: str) -> str:\n",
        "    if not isinstance(s, str):\n",
        "        return \"Other\"\n",
        "    st = s.lower()\n",
        "    if \"benign\" in st or st == \"normal\":\n",
        "        return \"Benign\"\n",
        "    if \"mqtt\" in st:\n",
        "        return \"MQTT\"\n",
        "    if \"ddos\" in st or \"dos\" in st:\n",
        "        return \"DoS_DDoS\"\n",
        "    if \"scan\" in st or \"recon\" in st or \"portscan\" in st:\n",
        "        return \"Recon_Scan\"\n",
        "    if \"spoof\" in st or \"mitm\" in st or \"impersonat\" in st or \"man-in-the-middle\" in st:\n",
        "        return \"Spoof\"\n",
        "    return \"Other\""
      ],
      "metadata": {
        "id": "CiE1HX4XVQ5T"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Loading & preprocessing\n",
        "# ----------------------------\n",
        "def load_nf_ton_iot(path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path)\n",
        "    return df\n",
        "\n",
        "def load_cic_iomt(train_path: str, test_path: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    dtr = pd.read_csv(train_path)\n",
        "    dte = pd.read_csv(test_path)\n",
        "    return dtr, dte\n",
        "\n",
        "def mqtt_filter_nf(df: pd.DataFrame, dst_port_col: str, ports: List[int]) -> pd.DataFrame:\n",
        "    if dst_port_col not in df.columns:\n",
        "        print(f\"[WARN] {dst_port_col} not in columns; skip MQTT filter.\")\n",
        "        return df\n",
        "    try:\n",
        "        f = df[df[dst_port_col].astype(int).isin(ports)].copy()\n",
        "    except Exception:\n",
        "        f = df[df[dst_port_col].astype(str).isin(list(map(str, ports)))].copy()\n",
        "    if len(f) == 0:\n",
        "        print(\"[WARN] MQTT filter produced empty set; reverting to full NF-ToN-IoT.\")\n",
        "        return df\n",
        "    return f\n",
        "\n",
        "def encode_and_scale(df: pd.DataFrame, y_col: str) -> Tuple[np.ndarray, np.ndarray, StandardScaler, List[str]]:\n",
        "    df = df.copy()\n",
        "    y = df[y_col].values\n",
        "    Xdf = df.drop(columns=[y_col])\n",
        "    for c in Xdf.columns:\n",
        "        if not np.issubdtype(Xdf[c].dtype, np.number):\n",
        "            Xdf[c] = LabelEncoder().fit_transform(Xdf[c].astype(str))\n",
        "    Xdf = Xdf.fillna(0)\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(Xdf.values)\n",
        "    return X, y, scaler, Xdf.columns.tolist()"
      ],
      "metadata": {
        "id": "jq7WXcSvVQ2X"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Feature builders (schema-aligned)\n",
        "# ----------------------------\n",
        "def build_features_train(df: pd.DataFrame, y_col: str):\n",
        "    df = df.copy()\n",
        "    y = df[y_col].values\n",
        "    Xdf = df.drop(columns=[y_col])\n",
        "\n",
        "    # split numeric vs non-numeric\n",
        "    Xnum = Xdf.select_dtypes(include=[np.number]).copy().fillna(0)\n",
        "    Xcat = Xdf.select_dtypes(exclude=[np.number]).astype(str)\n",
        "    if Xcat.shape[1] > 0:\n",
        "        Xcat = pd.get_dummies(Xcat, dummy_na=False, drop_first=False)\n",
        "    else:\n",
        "        Xcat = pd.DataFrame(index=Xdf.index)\n",
        "\n",
        "    Xall = pd.concat([Xnum, Xcat], axis=1)\n",
        "    scaler = StandardScaler().fit(Xall.values)\n",
        "    X = scaler.transform(Xall.values)\n",
        "    cols = Xall.columns.tolist()\n",
        "    return X, y, scaler, cols\n",
        "\n",
        "def build_features_test(df: pd.DataFrame, y_col: str, scaler: StandardScaler, cols_schema: list):\n",
        "    df = df.copy()\n",
        "    y = df[y_col].values\n",
        "    Xdf = df.drop(columns=[y_col])\n",
        "\n",
        "    Xnum = Xdf.select_dtypes(include=[np.number]).copy().fillna(0)\n",
        "    Xcat = Xdf.select_dtypes(exclude=[np.number]).astype(str)\n",
        "    if Xcat.shape[1] > 0:\n",
        "        Xcat = pd.get_dummies(Xcat, dummy_na=False, drop_first=False)\n",
        "    else:\n",
        "        Xcat = pd.DataFrame(index=Xdf.index)\n",
        "\n",
        "    Xall = pd.concat([Xnum, Xcat], axis=1)\n",
        "\n",
        "    # align to training schema\n",
        "    Xall = Xall.reindex(columns=cols_schema, fill_value=0)\n",
        "    X = scaler.transform(Xall.values)\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "QBadP5IfnJpy"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Resampling\n",
        "# ----------------------------\n",
        "def apply_resampling(X: np.ndarray, y: np.ndarray, mode: str):\n",
        "    if mode == \"smote_tomek\":\n",
        "        sampler = SMOTETomek(random_state=CONFIG[\"SEED\"])\n",
        "        return sampler.fit_resample(X, y)\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "cBYvm-vqVQzs"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Loss functions & calibration\n",
        "# ----------------------------\n",
        "def focal_loss(gamma=2.0, alpha=None):\n",
        "    def loss(y_true, y_pred):\n",
        "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0-1e-7)\n",
        "        ce = -y_true * tf.math.log(y_pred)\n",
        "        if alpha is not None:\n",
        "            ce = alpha * ce\n",
        "        weight = tf.pow(1.0 - y_pred, gamma)\n",
        "        return tf.reduce_sum(weight * ce, axis=1)\n",
        "    return loss\n",
        "\n",
        "def get_loss(num_classes, y_train, mode=\"ce\"):\n",
        "    if mode == \"focal\":\n",
        "        return focal_loss(gamma=2.0), None\n",
        "    if mode == \"class_balanced_ce\":\n",
        "        classes = np.unique(y_train)\n",
        "        weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "        cw = {int(c): float(w) for c, w in zip(classes, weights)}\n",
        "        return tf.keras.losses.CategoricalCrossentropy(), cw\n",
        "    return tf.keras.losses.CategoricalCrossentropy(), None\n",
        "\n",
        "def calibration_bins(probs: np.ndarray, y_true: np.ndarray, n_bins: int = 15):\n",
        "    conf = probs.max(axis=1)\n",
        "    preds = probs.argmax(axis=1)\n",
        "    correct = (preds == y_true).astype(int)\n",
        "    bins = np.linspace(0.0, 1.0, n_bins+1)\n",
        "    ece = 0.0\n",
        "    mce = 0.0\n",
        "    rel = []\n",
        "    for i in range(n_bins):\n",
        "        lo, hi = bins[i], bins[i+1]\n",
        "        idx = np.where((conf >= lo) & (conf < hi))[0]\n",
        "        if len(idx) == 0:\n",
        "            rel.append((0.5*(lo+hi), np.nan, 0))\n",
        "            continue\n",
        "        acc = correct[idx].mean()\n",
        "        conf_mean = conf[idx].mean()\n",
        "        gap = abs(acc - conf_mean)\n",
        "        ece += (len(idx) / len(conf)) * gap\n",
        "        mce = max(mce, gap)\n",
        "        rel.append((conf_mean, acc, len(idx)))\n",
        "    return ece, mce, rel\n",
        "\n",
        "def fpr_at_threshold(y_true_bin: np.ndarray, attack_scores: np.ndarray, target_fpr: float):\n",
        "    fpr, tpr, thr = roc_curve(y_true_bin, attack_scores)[:3]\n",
        "    idx = np.where(fpr <= target_fpr)[0]\n",
        "    if len(idx) == 0:\n",
        "        j = int(np.argmin(fpr))\n",
        "        return float(thr[j]), float(fpr[j]), float(tpr[j])\n",
        "    j = idx[-1]\n",
        "    return float(thr[j]), float(fpr[j]), float(tpr[j])"
      ],
      "metadata": {
        "id": "42aLcjYnVQxB"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Models\n",
        "# ----------------------------\n",
        "def build_bilstm(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Bidirectional(layers.LSTM(64, return_sequences=True, kernel_regularizer=regularizers.l2(1e-4)), input_shape=input_shape),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Bidirectional(layers.LSTM(32, kernel_regularizer=regularizers.l2(1e-4))),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(num_classes, activation=\"softmax\", kernel_regularizer=regularizers.l2(1e-4))\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def fgsm(model, x, y, eps=0.05):\n",
        "    x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
        "    y = tf.convert_to_tensor(y, dtype=tf.float32)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(x)\n",
        "        pred = model(x, training=False)\n",
        "        loss = tf.keras.losses.categorical_crossentropy(y, pred)\n",
        "    grad = tape.gradient(loss, x)\n",
        "    x_adv = x + eps * tf.sign(grad)\n",
        "    return tf.clip_by_value(x_adv, -10, 10).numpy()\n",
        "\n",
        "def pgd(model, x, y, eps=0.03, alpha=0.01, steps=5):\n",
        "    x0 = tf.convert_to_tensor(x, dtype=tf.float32)\n",
        "    x_adv = tf.identity(x0)\n",
        "    y = tf.convert_to_tensor(y, dtype=tf.float32)\n",
        "    for _ in range(steps):\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(x_adv)\n",
        "            pred = model(x_adv, training=False)\n",
        "            loss = tf.keras.losses.categorical_crossentropy(y, pred)\n",
        "        grad = tape.gradient(loss, x_adv)\n",
        "        x_adv = x_adv + alpha * tf.sign(grad)\n",
        "        x_adv = tf.clip_by_value(x_adv, x0 - eps, x0 + eps)\n",
        "    return x_adv.numpy()"
      ],
      "metadata": {
        "id": "iudxFJ6GWwCU"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Evaluation\n",
        "# ----------------------------\n",
        "@dataclass\n",
        "class RunResult:\n",
        "    setting: str\n",
        "    model_name: str\n",
        "    use_adv: bool\n",
        "    resampling: str\n",
        "    loss_mode: str\n",
        "    macro_f1: float\n",
        "    macro_recall: float\n",
        "    roc_auc_ovr: float\n",
        "    pr_auc_ovr: float\n",
        "    ece: float\n",
        "    mce: float\n",
        "    fpr1e3: float\n",
        "    tpr_at_fpr1e3: float\n",
        "    fpr1e4: float\n",
        "    tpr_at_fpr1e4: float\n",
        "\n",
        "def evaluate_multiclass(y_true, proba) -> Tuple[float, float, float, float]:\n",
        "    classes = np.unique(y_true)\n",
        "    Yb = label_binarize(y_true, classes=classes)\n",
        "    try:\n",
        "        roc = roc_auc_score(Yb, proba, average='macro', multi_class='ovr')\n",
        "    except Exception:\n",
        "        roc = float('nan')\n",
        "    try:\n",
        "        pr = average_precision_score(Yb, proba, average='macro')\n",
        "    except Exception:\n",
        "        pr = float('nan')\n",
        "    macro_f1 = f1_score(y_true, proba.argmax(axis=1), average='macro')\n",
        "    macro_rec = recall_score(y_true, proba.argmax(axis=1), average='macro')\n",
        "    return macro_f1, macro_rec, roc, pr"
      ],
      "metadata": {
        "id": "bDgOJXDSWv_U"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Main experiment\n",
        "# ----------------------------\n",
        "\n",
        "def main():\n",
        "    # Load raw CSVs\n",
        "    nf = load_nf_ton_iot(CONFIG[\"NF_TON_IOT_CSV\"])\n",
        "    cic_tr, cic_te = load_cic_iomt(CONFIG[\"CIC_IOMT_TRAIN_CSV\"], CONFIG[\"CIC_IOMT_TEST_CSV\"])\n",
        "\n",
        "    # Map strings -> families\n",
        "    if CONFIG[\"NF_TEXT_LABEL_COL\"] in nf.columns:\n",
        "        nf_family = nf[CONFIG[\"NF_TEXT_LABEL_COL\"]].astype(str).apply(map_label_string_to_family)\n",
        "    else:\n",
        "        nf_family = np.where(nf[CONFIG[\"NF_NUMERIC_CLASS_COL\"]].values == 0, \"Benign\", \"Other\")\n",
        "\n",
        "    cic_tr_family = cic_tr[CONFIG[\"CIC_TEXT_LABEL_COL\"]].astype(str).apply(map_label_string_to_family) if CONFIG[\"CIC_TEXT_LABEL_COL\"] in cic_tr.columns else cic_tr[CONFIG[\"CIC_CLASS_COL\"]].astype(int).apply(lambda _: \"Other\")\n",
        "    cic_te_family = cic_te[CONFIG[\"CIC_TEXT_LABEL_COL\"]].astype(str).apply(map_label_string_to_family) if CONFIG[\"CIC_TEXT_LABEL_COL\"] in cic_te.columns else cic_te[CONFIG[\"CIC_CLASS_COL\"]].astype(int).apply(lambda v: \"Benign\" if v==0 else \"Other\")\n",
        "\n",
        "    cic_tr2 = cic_tr.copy(); cic_tr2[\"Family\"] = cic_tr_family.values\n",
        "    cic_te2 = cic_te.copy(); cic_te2[\"Family\"] = cic_te_family.values\n",
        "\n",
        "    nf_mqtt = mqtt_filter_nf(nf, CONFIG[\"NF_DST_PORT_COL\"], CONFIG[\"MQTT_PORTS\"])\n",
        "    if len(nf_mqtt) == 0:\n",
        "        nf2 = nf.copy()\n",
        "        nf2[\"Family\"] = nf_family.values\n",
        "        print(\"[WARN] MQTT filter empty; using full NF-ToN-IoT.\")\n",
        "    else:\n",
        "        nf2 = nf_mqtt.copy()\n",
        "        nf2[\"Family\"] = nf_family.loc[nf_mqtt.index].values\n",
        "\n",
        "    # Label encoder for target\n",
        "    fam_le = LabelEncoder().fit(FAMILIES)\n",
        "\n",
        "    # Build an in-domain split for NF-ToN-IoT once (train/test for IoTâ†’IoT runs)\n",
        "    y_nf_all_enc = fam_le.transform(nf2[\"Family\"].values)\n",
        "    nf_train, nf_test = train_test_split(nf2, test_size=0.2, random_state=CONFIG[\"SEED\"],\n",
        "                                         stratify=y_nf_all_enc)\n",
        "\n",
        "    results = []\n",
        "    perclass_dfs = []\n",
        "    relbin_dfs = []\n",
        "\n",
        "    def run_setting(train_domain: str, test_domain: str, model_kind: str, use_adv: bool):\n",
        "        # Choose train/test DataFrames by domain\n",
        "        if train_domain == \"IoMT\":\n",
        "            df_tr = cic_tr2\n",
        "        else:\n",
        "            df_tr = nf_train\n",
        "\n",
        "        if test_domain == \"IoMT\":\n",
        "            df_te = cic_te2\n",
        "        else:\n",
        "            df_te = nf_test if train_domain == \"IoT\" and test_domain == \"IoT\" else nf2\n",
        "\n",
        "        # Encode targets\n",
        "        df_tr = df_tr.copy(); df_te = df_te.copy()\n",
        "        df_tr[\"y_enc\"] = fam_le.transform(df_tr[\"Family\"].values)\n",
        "        df_te[\"y_enc\"] = fam_le.transform(df_te[\"Family\"].values)\n",
        "\n",
        "        # Build schema-aligned features using train schema\n",
        "        Xtr, ytr, scaler, cols_schema = build_features_train(df_tr.drop(columns=[\"Family\"]).rename(columns={\"y_enc\": \"Target\"}), y_col=\"Target\")\n",
        "        Xte, yte = build_features_test(df_te.drop(columns=[\"Family\"]).rename(columns={\"y_enc\": \"Target\"}), y_col=\"Target\", scaler=scaler, cols_schema=cols_schema)\n",
        "\n",
        "        # Optional resampling on train only\n",
        "        if CONFIG[\"RESAMPLING\"] == \"smote_tomek\":\n",
        "            sampler = SMOTETomek(random_state=CONFIG[\"SEED\"])\n",
        "            Xtr, ytr = sampler.fit_resample(Xtr, ytr)\n",
        "\n",
        "        # Class weights / loss\n",
        "        if CONFIG[\"LOSS_MODE\"] == \"class_balanced_ce\":\n",
        "            classes = np.unique(ytr)\n",
        "            weights = compute_class_weight(class_weight='balanced', classes=classes, y=ytr)\n",
        "            cw = {int(c): float(w) for c, w in zip(classes, weights)}\n",
        "            loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "        elif CONFIG[\"LOSS_MODE\"] == \"focal\":\n",
        "            cw = None; loss = focal_loss(gamma=2.0)\n",
        "        else:\n",
        "            cw = None; loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "        # Train/eval per model kind\n",
        "        if model_kind == \"LR-only\":\n",
        "            clf = LogisticRegression(max_iter=1000, multi_class='multinomial')\n",
        "            clf.fit(Xtr, ytr)\n",
        "            proba_te = clf.predict_proba(Xte)\n",
        "\n",
        "        elif model_kind == \"BiLSTM-only\":\n",
        "            Xtr_seq = Xtr.reshape((Xtr.shape[0], 1, Xtr.shape[1]))\n",
        "            Xte_seq = Xte.reshape((Xte.shape[0], 1, Xte.shape[1]))\n",
        "            ytr_oh = to_categorical(ytr, num_classes=len(FAMILIES))\n",
        "            model = build_bilstm(Xtr_seq.shape[1:], len(FAMILIES))\n",
        "            model.compile(optimizer=tf.keras.optimizers.Adam(CONFIG[\"LEARNING_RATE\"]), loss=loss, metrics=['accuracy'])\n",
        "            es = callbacks.EarlyStopping(patience=CONFIG[\"PATIENCE\"], restore_best_weights=True, monitor='val_loss')\n",
        "\n",
        "            Xtrain_in, ytrain_in = Xtr_seq, ytr_oh\n",
        "            if use_adv and CONFIG[\"USE_ADV_TRAINING\"]:\n",
        "                model.fit(Xtr_seq, ytr_oh, validation_split=0.1, epochs=5, batch_size=CONFIG[\"BATCH_SIZE\"], verbose=0)\n",
        "                X_adv = fgsm(model, Xtr_seq, ytr_oh, eps=CONFIG[\"FGSM_EPS\"]) if CONFIG[\"ADV_METHOD\"]==\"fgsm\" else pgd(model, Xtr_seq, ytr_oh, eps=CONFIG[\"PGD_EPS\"], alpha=CONFIG[\"PGD_ALPHA\"], steps=CONFIG[\"PGD_STEPS\"])\n",
        "                k = int(CONFIG[\"ADV_RATIO\"] * Xtr_seq.shape[0]); idx = np.random.choice(Xtr_seq.shape[0], size=k, replace=False)\n",
        "                Xtrain_in = np.concatenate([Xtr_seq, X_adv[idx]], axis=0); ytrain_in = np.concatenate([ytr_oh, ytr_oh[idx]], axis=0)\n",
        "\n",
        "            model.fit(Xtrain_in, ytrain_in, validation_split=0.2, epochs=CONFIG[\"EPOCHS\"], batch_size=CONFIG[\"BATCH_SIZE\"], callbacks=[es], verbose=2, class_weight=cw)\n",
        "            proba_te = model.predict(Xte_seq, batch_size=CONFIG[\"BATCH_SIZE\"], verbose=0)\n",
        "\n",
        "        elif model_kind == \"LR->BiLSTM\":\n",
        "            # LR projection (train on aligned features)\n",
        "            lr = LogisticRegression(max_iter=1000, multi_class='multinomial')\n",
        "            lr.fit(Xtr, ytr)\n",
        "            Xtr_lr = lr.predict_proba(Xtr)\n",
        "            Xte_lr = lr.predict_proba(Xte)\n",
        "\n",
        "            Xtr_seq = Xtr_lr.reshape((Xtr_lr.shape[0], 1, Xtr_lr.shape[1]))\n",
        "            Xte_seq = Xte_lr.reshape((Xte_lr.shape[0], 1, Xte_lr.shape[1]))\n",
        "            ytr_oh = to_categorical(ytr, num_classes=len(FAMILIES))\n",
        "\n",
        "            model = build_bilstm(Xtr_seq.shape[1:], len(FAMILIES))\n",
        "            model.compile(optimizer=tf.keras.optimizers.Adam(CONFIG[\"LEARNING_RATE\"]), loss=loss, metrics=['accuracy'])\n",
        "            es = callbacks.EarlyStopping(patience=CONFIG[\"PATIENCE\"], restore_best_weights=True, monitor='val_loss')\n",
        "\n",
        "            Xtrain_in, ytrain_in = Xtr_seq, ytr_oh\n",
        "            if use_adv and CONFIG[\"USE_ADV_TRAINING\"]:\n",
        "                model.fit(Xtr_seq, ytr_oh, validation_split=0.1, epochs=5, batch_size=CONFIG[\"BATCH_SIZE\"], verbose=0)\n",
        "                X_adv = fgsm(model, Xtr_seq, ytr_oh, eps=CONFIG[\"FGSM_EPS\"]) if CONFIG[\"ADV_METHOD\"]==\"fgsm\" else pgd(model, Xtr_seq, ytr_oh, eps=CONFIG[\"PGD_EPS\"], alpha=CONFIG[\"PGD_ALPHA\"], steps=CONFIG[\"PGD_STEPS\"])\n",
        "                k = int(CONFIG[\"ADV_RATIO\"] * Xtr_seq.shape[0]); idx = np.random.choice(Xtr_seq.shape[0], size=k, replace=False)\n",
        "                Xtrain_in = np.concatenate([Xtr_seq, X_adv[idx]], axis=0); ytrain_in = np.concatenate([ytr_oh, ytr_oh[idx]], axis=0)\n",
        "\n",
        "            model.fit(Xtrain_in, ytrain_in, validation_split=0.2, epochs=CONFIG[\"EPOCHS\"], batch_size=CONFIG[\"BATCH_SIZE\"], callbacks=[es], verbose=2, class_weight=cw)\n",
        "            proba_te = model.predict(Xte_seq, batch_size=CONFIG[\"BATCH_SIZE\"], verbose=0)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown model_kind\")\n",
        "\n",
        "        # Metrics\n",
        "        macro_f1, macro_rec, roc_ovr, pr_ovr = evaluate_multiclass(yte, proba_te)\n",
        "        ece, mce, rel = calibration_bins(proba_te, yte, n_bins=15)\n",
        "\n",
        "        # Low-FPR metrics (binary collapse)\n",
        "        benign_idx = FAMILIES.index(\"Benign\")\n",
        "        attack_scores = 1.0 - proba_te[:, benign_idx]\n",
        "        y_true_bin = (yte != benign_idx).astype(int)\n",
        "        t1, f1, T1 = fpr_at_threshold(y_true_bin, attack_scores, 1e-3)\n",
        "        t2, f2, T2 = fpr_at_threshold(y_true_bin, attack_scores, 1e-4)\n",
        "\n",
        "        # Per-class metrics\n",
        "        y_pred = proba_te.argmax(axis=1)\n",
        "        perclass = []\n",
        "        for cidx, cname in enumerate(FAMILIES):\n",
        "            idxs = np.where(yte == cidx)[0]\n",
        "            if len(idxs) == 0:\n",
        "                rec_c = float('nan'); f1_c = float('nan'); sup_c = 0\n",
        "            else:\n",
        "                tp = np.sum(y_pred[idxs] == cidx)\n",
        "                fn = len(idxs) - tp\n",
        "                fp = np.sum((y_pred == cidx) & (yte != cidx))\n",
        "                rec_c = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "                prec_c = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "                f1_c = 2*prec_c*rec_c/(prec_c+rec_c) if (prec_c+rec_c) > 0 else 0.0\n",
        "                sup_c = len(idxs)\n",
        "            perclass.append({\"setting\": f\"{train_domain}->{test_domain}\",\n",
        "                             \"model_name\": model_kind,\n",
        "                             \"use_adv\": use_adv,\n",
        "                             \"class\": cname,\n",
        "                             \"recall\": float(rec_c),\n",
        "                             \"f1\": float(f1_c),\n",
        "                             \"support\": int(sup_c)})\n",
        "        perclass_dfs.append(pd.DataFrame(perclass))\n",
        "\n",
        "        # Reliability bins\n",
        "        rel_rows = []\n",
        "        for (conf_mean, acc, count) in rel:\n",
        "            rel_rows.append({\"setting\": f\"{train_domain}->{test_domain}\",\n",
        "                             \"model_name\": model_kind,\n",
        "                             \"use_adv\": use_adv,\n",
        "                             \"conf_mean\": float(0.0 if (conf_mean!=conf_mean) else conf_mean),\n",
        "                             \"acc\": float(0.0 if (acc!=acc) else acc),\n",
        "                             \"count\": int(count)})\n",
        "        relbin_dfs.append(pd.DataFrame(rel_rows))\n",
        "\n",
        "        return RunResult(setting=f\"{train_domain}->{test_domain}\", model_name=model_kind, use_adv=use_adv,\n",
        "                         resampling=CONFIG[\"RESAMPLING\"], loss_mode=CONFIG[\"LOSS_MODE\"],\n",
        "                         macro_f1=float(macro_f1), macro_recall=float(macro_rec),\n",
        "                         roc_auc_ovr=float(roc_ovr) if not np.isnan(roc_ovr) else np.nan,\n",
        "                         pr_auc_ovr=float(pr_ovr) if not np.isnan(pr_ovr) else np.nan,\n",
        "                         ece=float(ece), mce=float(mce),\n",
        "                         fpr1e3=float(f1), tpr_at_fpr1e3=float(T1),\n",
        "                         fpr1e4=float(f2), tpr_at_fpr1e4=float(T2))\n",
        "\n",
        "    for model_kind in [\"LR-only\", \"BiLSTM-only\", \"LR->BiLSTM\"]:\n",
        "        # In-domain\n",
        "        results.append(run_setting(\"IoMT\", \"IoMT\", model_kind, use_adv=False))\n",
        "        results.append(run_setting(\"IoT\",  \"IoT\",  model_kind, use_adv=False))\n",
        "        # Cross-domain\n",
        "        results.append(run_setting(\"IoMT\", \"IoT\",  model_kind, use_adv=(model_kind!=\"LR-only\")))\n",
        "        results.append(run_setting(\"IoT\",  \"IoMT\", model_kind, use_adv=(model_kind!=\"LR-only\")))\n",
        "\n",
        "    df = pd.DataFrame([asdict(r) for r in results])\n",
        "    out_csv = os.path.join(CONFIG[\"OUTDIR\"], \"domain_shift_results_v2.csv\")\n",
        "    os.makedirs(CONFIG[\"OUTDIR\"], exist_ok=True)\n",
        "    df.to_csv(out_csv, index=False)\n",
        "\n",
        "    out_pc = os.path.join(CONFIG[\"OUTDIR\"], \"domain_shift_perclass_v2.csv\")\n",
        "    pd.concat(perclass_dfs, ignore_index=True).to_csv(out_pc, index=False)\n",
        "\n",
        "    out_rel = os.path.join(CONFIG[\"OUTDIR\"], \"domain_shift_reliability_bins_v2.csv\")\n",
        "    pd.concat(relbin_dfs, ignore_index=True).to_csv(out_rel, index=False)\n",
        "\n",
        "    print(\"\\\\nSaved:\", out_csv)\n",
        "    print(\"\\\\nSaved:\", out_pc)\n",
        "    print(\"\\\\nSaved:\", out_rel)\n",
        "    print(df.to_string(index=False))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67gGnNsCWv8p",
        "outputId": "86cb417a-ac9e-47d4-b80c-33d2f36da529"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] MQTT filter produced empty set; reverting to full NF-ToN-IoT.\n",
            "Epoch 1/30\n",
            "6554/6554 - 47s - 7ms/step - accuracy: 0.9993 - loss: 0.0105 - val_accuracy: 0.8074 - val_loss: 1.8886\n",
            "Epoch 2/30\n",
            "6554/6554 - 42s - 6ms/step - accuracy: 1.0000 - loss: 5.5380e-04 - val_accuracy: 0.8074 - val_loss: 2.1057\n",
            "Epoch 3/30\n",
            "6554/6554 - 44s - 7ms/step - accuracy: 1.0000 - loss: 1.1029e-04 - val_accuracy: 0.8074 - val_loss: 2.4000\n",
            "Epoch 4/30\n",
            "6554/6554 - 44s - 7ms/step - accuracy: 1.0000 - loss: 4.3157e-06 - val_accuracy: 0.8074 - val_loss: 3.0364\n",
            "Epoch 5/30\n",
            "6554/6554 - 43s - 7ms/step - accuracy: 1.0000 - loss: 7.8187e-08 - val_accuracy: 0.8074 - val_loss: 3.3394\n",
            "Epoch 6/30\n",
            "6554/6554 - 44s - 7ms/step - accuracy: 1.0000 - loss: 5.0444e-11 - val_accuracy: 0.8074 - val_loss: 3.4623\n",
            "Epoch 1/30\n",
            "5243/5243 - 41s - 8ms/step - accuracy: 0.9985 - loss: 0.0387 - val_accuracy: 1.0000 - val_loss: 0.0080\n",
            "Epoch 2/30\n",
            "5243/5243 - 35s - 7ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
            "Epoch 3/30\n",
            "5243/5243 - 34s - 7ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
            "Epoch 4/30\n",
            "5243/5243 - 34s - 7ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
            "Epoch 5/30\n",
            "5243/5243 - 36s - 7ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
            "Epoch 6/30\n",
            "5243/5243 - 35s - 7ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 7/30\n",
            "5243/5243 - 35s - 7ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 8/30\n",
            "5243/5243 - 35s - 7ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 9/30\n",
            "5243/5243 - 34s - 7ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 10/30\n",
            "5243/5243 - 34s - 7ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 11/30\n",
            "5243/5243 - 34s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 12/30\n",
            "5243/5243 - 33s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
            "Epoch 13/30\n",
            "5243/5243 - 33s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
            "Epoch 14/30\n",
            "5243/5243 - 33s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
            "Epoch 15/30\n",
            "5243/5243 - 33s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 16/30\n",
            "5243/5243 - 34s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
            "Epoch 17/30\n",
            "5243/5243 - 33s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 18/30\n",
            "5243/5243 - 33s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
            "Epoch 19/30\n",
            "5243/5243 - 33s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 20/30\n",
            "5243/5243 - 33s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 21/30\n",
            "5243/5243 - 33s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 1/30\n",
            "9831/9831 - 69s - 7ms/step - accuracy: 0.9999 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
            "Epoch 2/30\n",
            "9831/9831 - 61s - 6ms/step - accuracy: 0.9999 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
            "Epoch 3/30\n",
            "9831/9831 - 61s - 6ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 4/30\n",
            "9831/9831 - 60s - 6ms/step - accuracy: 0.9999 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 5/30\n",
            "9831/9831 - 64s - 7ms/step - accuracy: 0.9999 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 6/30\n",
            "9831/9831 - 68s - 7ms/step - accuracy: 0.9999 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 7/30\n",
            "9831/9831 - 66s - 7ms/step - accuracy: 0.9999 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 9.5848e-04\n",
            "Epoch 8/30\n",
            "9831/9831 - 64s - 7ms/step - accuracy: 0.9999 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 9.0480e-04\n",
            "Epoch 9/30\n",
            "9831/9831 - 64s - 6ms/step - accuracy: 0.9999 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 10/30\n",
            "9831/9831 - 69s - 7ms/step - accuracy: 0.9999 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 11/30\n",
            "9831/9831 - 65s - 7ms/step - accuracy: 0.9999 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 8.6303e-04\n",
            "Epoch 12/30\n",
            "9831/9831 - 66s - 7ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
            "Epoch 13/30\n",
            "9831/9831 - 66s - 7ms/step - accuracy: 0.9999 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 14/30\n",
            "9831/9831 - 63s - 6ms/step - accuracy: 0.9999 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
            "Epoch 15/30\n",
            "9831/9831 - 62s - 6ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 16/30\n",
            "9831/9831 - 62s - 6ms/step - accuracy: 0.9999 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 1/30\n",
            "7865/7865 - 54s - 7ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
            "Epoch 2/30\n",
            "7865/7865 - 47s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
            "Epoch 3/30\n",
            "7865/7865 - 47s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 4/30\n",
            "7865/7865 - 50s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 5/30\n",
            "7865/7865 - 45s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
            "Epoch 6/30\n",
            "7865/7865 - 44s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
            "Epoch 7/30\n",
            "7865/7865 - 43s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
            "Epoch 8/30\n",
            "7865/7865 - 42s - 5ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
            "Epoch 9/30\n",
            "7865/7865 - 47s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
            "Epoch 10/30\n",
            "7865/7865 - 47s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
            "Epoch 1/30\n",
            "6554/6554 - 45s - 7ms/step - accuracy: 0.9997 - loss: 0.0108 - val_accuracy: 0.8074 - val_loss: 1.8998\n",
            "Epoch 2/30\n",
            "6554/6554 - 41s - 6ms/step - accuracy: 1.0000 - loss: 6.0232e-04 - val_accuracy: 0.8074 - val_loss: 2.1122\n",
            "Epoch 3/30\n",
            "6554/6554 - 50s - 8ms/step - accuracy: 1.0000 - loss: 1.1961e-04 - val_accuracy: 0.8074 - val_loss: 2.3983\n",
            "Epoch 4/30\n",
            "6554/6554 - 42s - 6ms/step - accuracy: 1.0000 - loss: 5.0634e-06 - val_accuracy: 0.8074 - val_loss: 3.0301\n",
            "Epoch 5/30\n",
            "6554/6554 - 42s - 6ms/step - accuracy: 1.0000 - loss: 8.9703e-08 - val_accuracy: 0.8074 - val_loss: 3.3418\n",
            "Epoch 6/30\n",
            "6554/6554 - 41s - 6ms/step - accuracy: 1.0000 - loss: 5.3437e-11 - val_accuracy: 0.8074 - val_loss: 3.4636\n",
            "Epoch 1/30\n",
            "5243/5243 - 36s - 7ms/step - accuracy: 0.9996 - loss: 0.0622 - val_accuracy: 1.0000 - val_loss: 0.0138\n",
            "Epoch 2/30\n",
            "5243/5243 - 33s - 6ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 0.0077\n",
            "Epoch 3/30\n",
            "5243/5243 - 32s - 6ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
            "Epoch 4/30\n",
            "5243/5243 - 33s - 6ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0066\n",
            "Epoch 5/30\n",
            "5243/5243 - 32s - 6ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 0.0067\n",
            "Epoch 6/30\n",
            "5243/5243 - 32s - 6ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 0.0066\n",
            "Epoch 7/30\n",
            "5243/5243 - 33s - 6ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 0.0066\n",
            "Epoch 8/30\n",
            "5243/5243 - 35s - 7ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 0.0066\n",
            "Epoch 9/30\n",
            "5243/5243 - 38s - 7ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 0.0066\n",
            "Epoch 10/30\n",
            "5243/5243 - 34s - 6ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 0.0065\n",
            "Epoch 11/30\n",
            "5243/5243 - 34s - 6ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 0.0066\n",
            "Epoch 12/30\n",
            "5243/5243 - 33s - 6ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 0.0066\n",
            "Epoch 13/30\n",
            "5243/5243 - 32s - 6ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 0.0065\n",
            "Epoch 14/30\n",
            "5243/5243 - 34s - 6ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 0.0066\n",
            "Epoch 15/30\n",
            "5243/5243 - 34s - 6ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 0.0066\n",
            "Epoch 1/30\n",
            "9831/9831 - 71s - 7ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
            "Epoch 2/30\n",
            "9831/9831 - 59s - 6ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
            "Epoch 3/30\n",
            "9831/9831 - 58s - 6ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
            "Epoch 4/30\n",
            "9831/9831 - 58s - 6ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
            "Epoch 5/30\n",
            "9831/9831 - 62s - 6ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
            "Epoch 6/30\n",
            "9831/9831 - 63s - 6ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
            "Epoch 7/30\n",
            "9831/9831 - 62s - 6ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 8/30\n",
            "9831/9831 - 61s - 6ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 9/30\n",
            "9831/9831 - 59s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 10/30\n",
            "9831/9831 - 59s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 11/30\n",
            "9831/9831 - 70s - 7ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 12/30\n",
            "9831/9831 - 59s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 13/30\n",
            "9831/9831 - 60s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 14/30\n",
            "9831/9831 - 61s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 15/30\n",
            "9831/9831 - 63s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 16/30\n",
            "9831/9831 - 63s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 17/30\n",
            "9831/9831 - 62s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 18/30\n",
            "9831/9831 - 62s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 19/30\n",
            "9831/9831 - 63s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 20/30\n",
            "9831/9831 - 62s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 21/30\n",
            "9831/9831 - 61s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 22/30\n",
            "9831/9831 - 61s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 23/30\n",
            "9831/9831 - 60s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 24/30\n",
            "9831/9831 - 62s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 25/30\n",
            "9831/9831 - 62s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 26/30\n",
            "9831/9831 - 61s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 27/30\n",
            "9831/9831 - 59s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 28/30\n",
            "9831/9831 - 58s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 29/30\n",
            "9831/9831 - 60s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 30/30\n",
            "9831/9831 - 61s - 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 1/30\n",
            "7865/7865 - 68s - 9ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
            "Epoch 2/30\n",
            "7865/7865 - 49s - 6ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
            "Epoch 3/30\n",
            "7865/7865 - 50s - 6ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0069\n",
            "Epoch 4/30\n",
            "7865/7865 - 50s - 6ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
            "Epoch 5/30\n",
            "7865/7865 - 50s - 6ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
            "Epoch 6/30\n",
            "7865/7865 - 49s - 6ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
            "Epoch 7/30\n",
            "7865/7865 - 49s - 6ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0069\n",
            "Epoch 8/30\n",
            "7865/7865 - 49s - 6ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
            "Epoch 9/30\n",
            "7865/7865 - 50s - 6ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
            "Epoch 10/30\n",
            "7865/7865 - 49s - 6ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0069\n",
            "\\nSaved: ./outputs/domain_shift_results_v2.csv\n",
            "\\nSaved: ./outputs/domain_shift_perclass_v2.csv\n",
            "\\nSaved: ./outputs/domain_shift_reliability_bins_v2.csv\n",
            "   setting  model_name  use_adv resampling         loss_mode  macro_f1  macro_recall  roc_auc_ovr  pr_auc_ovr      ece      mce   fpr1e3  tpr_at_fpr1e3   fpr1e4  tpr_at_fpr1e4\n",
            "IoMT->IoMT     LR-only    False       none class_balanced_ce  0.003630      0.046829     0.145857    0.430634 0.960322 0.994138 0.000000       0.000000 0.000000       0.000000\n",
            "  IoT->IoT     LR-only    False       none class_balanced_ce  0.333333      0.333333     1.000000    1.000000 0.689737 0.689737 0.000000       1.000000 0.000000       1.000000\n",
            " IoMT->IoT     LR-only    False       none class_balanced_ce  0.054347      0.200000     0.397489    0.304692 0.829762 0.980071 0.000018       0.000000 0.000018       0.000000\n",
            " IoT->IoMT     LR-only    False       none class_balanced_ce  0.091048      0.200000     0.466271    0.536835 0.820616 0.898779 0.000000       1.000000 0.000000       1.000000\n",
            "IoMT->IoMT BiLSTM-only    False       none class_balanced_ce  0.187042      0.200000          NaN         NaN 0.121476 0.121476 0.000957       0.000067 0.000053       0.000056\n",
            "  IoT->IoT BiLSTM-only    False       none class_balanced_ce  1.000000      1.000000          NaN         NaN 0.000258 0.094831 0.000698       1.000000 0.000000       1.000000\n",
            " IoMT->IoT BiLSTM-only     True       none class_balanced_ce  0.000000      0.000000          NaN         NaN 0.538398 0.542992 0.000000       0.000000 0.000000       0.000000\n",
            " IoT->IoMT BiLSTM-only     True       none class_balanced_ce  0.105453      0.166667          NaN         NaN 0.942901 0.997869 0.000000       1.000000 0.000000       1.000000\n",
            "IoMT->IoMT  LR->BiLSTM    False       none class_balanced_ce  0.187042      0.200000          NaN         NaN 0.121468 0.121468 0.000000       0.000000 0.000000       0.000000\n",
            "  IoT->IoT  LR->BiLSTM    False       none class_balanced_ce  1.000000      1.000000          NaN         NaN 0.000359 0.000359 0.000030       1.000000 0.000030       1.000000\n",
            " IoMT->IoT  LR->BiLSTM     True       none class_balanced_ce  0.053052      0.200000          NaN         NaN 0.844745 0.844745 0.000000       0.000000 0.000000       0.000000\n",
            " IoT->IoMT  LR->BiLSTM     True       none class_balanced_ce  0.075873      0.166667          NaN         NaN 0.954755 0.954924 0.000000       1.000000 0.000000       1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.colab.files\n",
        "import os\n",
        "\n",
        "# Define the output directory from the CONFIG\n",
        "output_dir = CONFIG[\"OUTDIR\"]\n",
        "\n",
        "# Define the filenames to download\n",
        "result_files = [\n",
        "    \"domain_shift_results_v2.csv\",\n",
        "    \"domain_shift_perclass_v2.csv\",\n",
        "    \"domain_shift_reliability_bins_v2.csv\"\n",
        "]\n",
        "\n",
        "print(\"Attempting to download result files...\")\n",
        "\n",
        "# Download each file\n",
        "for filename in result_files:\n",
        "    file_path = os.path.join(output_dir, filename)\n",
        "    if os.path.exists(file_path):\n",
        "        try:\n",
        "            google.colab.files.download(file_path)\n",
        "            print(f\"Downloaded: {filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading {filename}: {e}\")\n",
        "    else:\n",
        "        print(f\"File not found: {filename}\")\n",
        "\n",
        "print(\"Download process finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "KeQnNUC6n6ws",
        "outputId": "6d39d45f-da08-4838-b6a7-e68568ff1781"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to download result files...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9abb21c1-2ba5-4712-b1ff-6bb4438666e3\", \"domain_shift_results_v2.csv\", 2001)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: domain_shift_results_v2.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5e5f4ae1-d573-47c5-ad4c-c02e14278a19\", \"domain_shift_perclass_v2.csv\", 3513)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: domain_shift_perclass_v2.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_38bd3897-59e6-4d18-9a3d-0140dba37bb0\", \"domain_shift_reliability_bins_v2.csv\", 8948)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: domain_shift_reliability_bins_v2.csv\n",
            "Download process finished.\n"
          ]
        }
      ]
    }
  ]
}