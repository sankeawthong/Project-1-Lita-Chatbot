{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM0yOxwf+SxNZmauxK0Ch5/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankeawthong/Project-1-Lita-Chatbot/blob/main/%5B20251812%5DComplete%20training%20evaluation%20script%20with%20CLEAN%20ABLATION%20(LR%2C%20MLP%2C%20LR%E2%86%92MLP%20uncal).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Complete training/evaluation script with CLEAN ABLATION (LR, MLP, LRâ†’MLP uncal./Temp/Isot.), SEED-AVERAGED.\n",
        "This file merges your provided code and appends the ablation block + main() call to generate:\n",
        "  - paper_exports/clean_ablation_seedavg.csv\n",
        "  - paper_exports/clean_ablation_seedavg.tex\n",
        "\n",
        "Publication-safe CIC protocol (Option A): strict Train/Val/Test split with validation-only calibration."
      ],
      "metadata": {
        "id": "6Ni1OrD2psBm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4etQuj_zpkbx"
      },
      "outputs": [],
      "source": [
        "import os, json, argparse, re, difflib, traceback, zipfile, time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline as SkPipeline\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import (accuracy_score, f1_score, classification_report,\n",
        "                             average_precision_score, roc_auc_score, precision_recall_curve,\n",
        "                             confusion_matrix, ConfusionMatrixDisplay, log_loss)\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from joblib import dump, load\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "#          Config\n",
        "# -----------------------------\n",
        "CFG = {\n",
        "    \"paths\": {\n",
        "        \"nf_csv\": \"/content/Dataset_NF-ToN-IoT.csv\",\n",
        "        \"cic_train_csv\": \"/content/CIC_IoMT_2024_WiFi_MQTT_train.csv\",\n",
        "        \"cic_test_csv\": \"/content/CIC_IoMT_2024_WiFi_MQTT_test.csv\",\n",
        "        \"outdir\": \"/mnt/data/iot_ids_refactor/outputs\",\n",
        "        \"run_dir\": None\n",
        "},\n",
        "    \"label_columns\": {\n",
        "        \"binary_candidates\": [\"Label\", \"label\", \"Binary\", \"binary\"],\n",
        "        \"multiclass_candidates\": [\"Class\", \"class\", \"Category\", \"category\"],\n",
        "        \"drop_non_feature_if_present\": [\"Attack\", \"attack\", \"Label\", \"label\", \"Class\", \"class\"]\n",
        "    },\n",
        "    \"train\": {\n",
        "        \"random_state\": 42,\n",
        "        \"test_size\": 0.2,\n",
        "        \"use_smote\": True,\n",
        "        \"mlp_hidden_units\": 64,\n",
        "        \"max_epochs\": 25,\n",
        "        \"batch_size\": 2048\n",
        "    },\n",
        "    \"metrics\": {\"target_drs\": [0.90, 0.95]},\n",
        "    \"calibration\": {\"cic_calib_frac\": 0.10},\n",
        "    \"robust\": {\"eps\": [0.05, 0.10], \"pgd_steps\": 10, \"pgd_alpha\": 0.02},\n",
        "    \"automap\": {\"similarity_threshold\": 0.75, \"max_pairs\": 256},\n",
        "    \"cic_optionA\": {\n",
        "        \"train_frac\": 0.60,\n",
        "        \"val_frac\": 0.20,\n",
        "        \"test_frac\": 0.20,\n",
        "        \"val_cal_frac\": 0.50,\n",
        "        \"grid_C\": [0.5, 1.0, 2.0],\n",
        "        \"grid_hidden\": [32, 64, 128]\n",
        "    }\n",
        "}\n",
        "\n",
        "PERF = {\"adv_eval_max_rows\": 200_000, \"plot_max_rows\": 150_000}"
      ],
      "metadata": {
        "id": "-dqjjeMWpx-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------\n",
        "#        Canonical feature aliases\n",
        "# ------------------------------------------\n",
        "CANON = {\n",
        "    \"duration\": [\"dur\",\"flow_duration\",\"duration\",\"dur_ms\",\"flowdur\",\"flow_dur\",\"Flow Duration\"],\n",
        "    \"tot_fwd_pkts\": [\"Tot Fwd Pkts\",\"tot_fwd_pkts\",\"total_fwd_packets\",\"fwd_pkts_tot\",\"fwd_pkts_total\",\"fwd_packets_total\"],\n",
        "    \"tot_bwd_pkts\": [\"Tot Bwd Pkts\",\"tot_bwd_pkts\",\"total_bwd_packets\",\"bwd_pkts_tot\",\"bwd_pkts_total\",\"bwd_packets_total\"],\n",
        "    \"totlen_fwd_pkts\": [\"TotLen Fwd Pkts\",\"totlen_fwd_pkts\",\"total_length_of_fwd_packets\",\"fwd_pkts_len_tot\",\"fwd_bytes_total\",\"total_fwd_bytes\",\"Tot Fwd Bytes\",\"Fwd Bytes\"],\n",
        "    \"totlen_bwd_pkts\": [\"TotLen Bwd Pkts\",\"totlen_bwd_pkts\",\"total_length_of_bwd_packets\",\"bwd_pkts_len_tot\",\"bwd_bytes_total\",\"total_bwd_bytes\",\"Tot Bwd Bytes\",\"Bwd Bytes\"],\n",
        "    \"fwd_pkt_len_mean\": [\"Fwd Pkt Len Mean\",\"fwd_pkt_len_mean\",\"fwd_packet_length_mean\",\"fwd_pkt_length_mean\",\"Fwd Pkt Len Avg\"],\n",
        "    \"bwd_pkt_len_mean\": [\"Bwd Pkt Len Mean\",\"bwd_pkt_len_mean\",\"bwd_packet_length_mean\",\"bwd_pkt_length_mean\",\"Bwd Pkt Len Avg\"],\n",
        "    \"fwd_iat_mean\": [\"Fwd IAT Mean\",\"fwd_iat_mean\",\"fwd_interarrival_mean\",\"fwd_iat_avg\",\"Fwd IAT Avg\"],\n",
        "    \"bwd_iat_mean\": [\"Bwd IAT Mean\",\"bwd_iat_mean\",\"bwd_interarrival_mean\",\"bwd_iat_avg\",\"Bwd IAT Avg\"],\n",
        "    \"pkt_len_mean\": [\"Pkt Len Mean\",\"pkt_len_mean\",\"packet_length_mean\",\"pkt_length_mean\",\"Pkt Len Avg\",\"Average Packet Size\"],\n",
        "    \"pkt_len_std\": [\"Pkt Len Std\",\"pkt_len_std\",\"packet_length_std\",\"pkt_length_std\",\"Std Packet Len\",\"Pkt Len STD\"],\n",
        "    \"flow_pkts_s\": [\"Flow Pkts/s\",\"flow_pkts_s\",\"packets_per_second\",\"pkts_per_sec\",\"pkt_rate\",\"Packet Rate\",\"Pkts/s\"],\n",
        "    \"flow_byts_s\": [\"Flow Byts/s\",\"flow_byts_s\",\"bytes_per_second\",\"byte_rate\",\"bytes_per_sec\",\"throughput\",\"Bps\",\"Bytes/s\"],\n",
        "    \"protocol\": [\"Protocol\",\"proto\",\"protocol\",\"protocol_type\",\"l4_proto\",\"Protocol Type\"],\n",
        "    \"src_port\": [\"Src Port\",\"src_port\",\"sport\",\"source_port\",\"Source Port\"],\n",
        "    \"dst_port\": [\"Dst Port\",\"dst_port\",\"dport\",\"destination_port\",\"Destination Port\"],\n",
        "    \"flags\": [\"flags\",\"tcp_flags\",\"flag_count\",\"tcpflag\",\"flag_total\",\"TCP Flags\",\"Flags\"]\n",
        "}"
      ],
      "metadata": {
        "id": "glktRNCVpx8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "#     Feature utilities\n",
        "# -------------------------\n",
        "def build_rename_map(df_cols):\n",
        "    lower = {c.lower(): c for c in df_cols}\n",
        "    rename = {}\n",
        "    for canon, aliases in CANON.items():\n",
        "        for a in aliases:\n",
        "            key = a.lower()\n",
        "            if key in lower:\n",
        "                rename[lower[key]] = canon\n",
        "                break\n",
        "    return rename\n",
        "\n",
        "def normalize_features(df):\n",
        "    rename = build_rename_map(df.columns)\n",
        "    return df.rename(columns=rename)\n",
        "\n",
        "def add_derived_flow_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    d = df.copy()\n",
        "    dur_cols = [\"flow_duration\", \"Flow Duration\", \"duration\", \"dur\", \"dur_ms\", \"flow_dur\"]\n",
        "    dur = None\n",
        "    for c in dur_cols:\n",
        "        if c in d.columns:\n",
        "            dur = pd.to_numeric(d[c], errors=\"coerce\"); break\n",
        "    if dur is None:\n",
        "        d[\"flow_dur_s\"] = 1.0\n",
        "    else:\n",
        "        perc95 = np.nanquantile(dur, 0.95)\n",
        "        d[\"flow_dur_s\"] = np.where(perc95 > 100.0, dur / 1000.0, dur)\n",
        "    def find(colnames):\n",
        "        for c in colnames:\n",
        "            if c in d.columns: return pd.to_numeric(d[c], errors=\"coerce\")\n",
        "        return None\n",
        "    fwd_pkts = find([\"tot_fwd_pkts\",\"Tot Fwd Pkts\",\"total_fwd_packets\",\"fwd_pkts_total\",\"fwd_packets_total\"])\n",
        "    bwd_pkts = find([\"tot_bwd_pkts\",\"Tot Bwd Pkts\",\"total_bwd_packets\",\"bwd_pkts_tot\",\"bwd_pkts_total\",\"bwd_packets_total\"])\n",
        "    fwd_byts = find([\"totlen_fwd_pkts\",\"TotLen Fwd Pkts\",\"total_fwd_bytes\",\"Fwd Bytes\",\"Tot Fwd Bytes\"])\n",
        "    bwd_byts = find([\"totlen_bwd_pkts\",\"TotLen Bwd Pkts\",\"total_bwd_bytes\",\"Bwd Bytes\",\"Tot Bwd Bytes\"])\n",
        "    d[\"tot_pkts\"] = 0.0\n",
        "    if fwd_pkts is not None: d[\"tot_pkts\"] = d[\"tot_pkts\"] + fwd_pkts.fillna(0)\n",
        "    if bwd_pkts is not None: d[\"tot_pkts\"] = d[\"tot_pkts\"] + bwd_pkts.fillna(0)\n",
        "    d[\"tot_byts\"] = 0.0\n",
        "    if fwd_byts is not None: d[\"tot_byts\"] = d[\"tot_byts\"] + fwd_byts.fillna(0)\n",
        "    if bwd_byts is not None: d[\"tot_byts\"] = d[\"tot_byts\"] + bwd_byts.fillna(0)\n",
        "    safe_dur = np.maximum(d[\"flow_dur_s\"].replace(0, np.nan), 1e-3)\n",
        "    safe_pkts = np.maximum(d[\"tot_pkts\"].replace(0, np.nan), 1.0)\n",
        "    d[\"pkts_per_sec\"] = d[\"tot_pkts\"] / safe_dur\n",
        "    d[\"byts_per_sec\"] = d[\"tot_byts\"] / safe_dur\n",
        "    d[\"avg_pkt_len\"]  = d[\"tot_byts\"] / safe_pkts\n",
        "    for pcol, newcol in [(\"Src Port\",\"src_port\"),(\"src_port\",\"src_port\"),(\"sport\",\"src_port\"),\n",
        "                         (\"Dst Port\",\"dst_port\"),(\"dst_port\",\"dst_port\"),(\"dport\",\"dst_port\")]:\n",
        "        if pcol in d.columns:\n",
        "            d[newcol] = pd.to_numeric(d[pcol], errors=\"coerce\")\n",
        "    proto_col = None\n",
        "    for c in [\"protocol\",\"Protocol\",\"protocol_type\",\"l4_proto\"]:\n",
        "        if c in d.columns: proto_col = c; break\n",
        "    d[\"is_tcp\"] = 0.0; d[\"is_udp\"] = 0.0\n",
        "    if proto_col is not None:\n",
        "        pc = d[proto_col]\n",
        "        if np.issubdtype(pc.dtype, np.number):\n",
        "            d[\"is_tcp\"] = (pc == 6).astype(float)\n",
        "            d[\"is_udp\"] = (pc == 17).astype(float)\n",
        "        else:\n",
        "            pstr = pc.astype(str).str.lower()\n",
        "            d[\"is_tcp\"] = pstr.str.contains(\"tcp\").astype(float)\n",
        "            d[\"is_udp\"] = pstr.str.contains(\"udp\").astype(float)\n",
        "    return d"
      ],
      "metadata": {
        "id": "qt8OvVnXpx5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------\n",
        "#     I/O helpers\n",
        "# -------------------\n",
        "def detect_label_column(df, candidates):\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def pick_features(df, drop_cols):\n",
        "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    feat_cols = [c for c in num_cols if c not in set(drop_cols)]\n",
        "    return feat_cols\n",
        "\n",
        "def load_dataset(path):\n",
        "    df_raw = pd.read_csv(path)\n",
        "    df = normalize_features(df_raw)\n",
        "    df = add_derived_flow_features(df)\n",
        "    bin_col = detect_label_column(df, CFG[\"label_columns\"][\"binary_candidates\"])\n",
        "    mc_col  = detect_label_column(df, CFG[\"label_columns\"][\"multiclass_candidates\"])\n",
        "    feat_cols = pick_features(df, CFG[\"label_columns\"][\"drop_non_feature_if_present\"])\n",
        "    return df, feat_cols, bin_col, mc_col"
      ],
      "metadata": {
        "id": "6Gw9h3DRpx2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------\n",
        "#      Labels\n",
        "# -----------------\n",
        "def map_label_string_to_family(s: str) -> str:\n",
        "    st = str(s).lower().strip()\n",
        "    if \"benign\" in st or \"normal\" in st: return \"Benign\"\n",
        "    return \"Attack\"\n",
        "\n",
        "def build_binary_labels(df, bin_col, mc_col):\n",
        "    if bin_col and bin_col in df.columns:\n",
        "        try:\n",
        "            y_bin = df[bin_col].astype(int).values\n",
        "        except ValueError:\n",
        "            y_bin = df[bin_col].apply(lambda x: 0 if map_label_string_to_family(str(x)) == \"Benign\" else 1).values\n",
        "    elif mc_col and mc_col in df.columns:\n",
        "        try:\n",
        "            y_bin = (df[mc_col].astype(int).values != 0).astype(int)\n",
        "        except ValueError:\n",
        "            y_bin = df[mc_col].apply(lambda x: 0 if map_label_string_to_family(str(x)) == \"Benign\" else 1).values\n",
        "    else:\n",
        "        raise ValueError(\"No binary or multiclass label column found.\")\n",
        "    return y_bin\n",
        "\n",
        "def make_one_hot(y, n_classes):\n",
        "    out = np.zeros((len(y), n_classes), dtype=int)\n",
        "    out[np.arange(len(y)), y] = 1\n",
        "    return out"
      ],
      "metadata": {
        "id": "6yke2YQMp6pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------\n",
        "#     Calibration\n",
        "# -------------------\n",
        "def sigmoid(x): return 1.0/(1.0+np.exp(-x))\n",
        "\n",
        "def fit_temperature(z_val, y_val, n_iters=300, lr=0.05):\n",
        "    T = 1.0\n",
        "    for _ in range(n_iters):\n",
        "        p = sigmoid(z_val / T)\n",
        "        p = np.clip(p, 1e-7, 1-1e-7)\n",
        "        grad = np.mean((p - y_val) * (-z_val/(T*T)))\n",
        "        T -= lr * grad\n",
        "        T = float(np.clip(T, 0.05, 50.0))\n",
        "    return T\n",
        "\n",
        "def apply_temperature(z, T):\n",
        "    return sigmoid(z / T)\n",
        "\n",
        "def calibrate_scores(scores_cal, y_cal_bin, scores_eval, method=\"temperature\"):\n",
        "    s_cal = np.clip(scores_cal, 1e-6, 1-1e-6)\n",
        "    s_eval = np.clip(scores_eval, 1e-6, 1-1e-6)\n",
        "    if method == \"isotonic\":\n",
        "        iso = IsotonicRegression(out_of_bounds=\"clip\")\n",
        "        iso.fit(s_cal, y_cal_bin.astype(int))\n",
        "        s_eval_cal = iso.predict(s_eval)\n",
        "        return s_eval_cal, {\"method\": \"isotonic\"}\n",
        "    else:\n",
        "        z_cal = np.log(s_cal/(1-s_cal))\n",
        "        T = fit_temperature(z_cal, y_cal_bin.astype(int), n_iters=300, lr=0.05)\n",
        "        z_eval = np.log(s_eval/(1-s_eval))\n",
        "        s_eval_cal = apply_temperature(z_eval, T)\n",
        "        return s_eval_cal, {\"method\": \"temperature\", \"T\": float(T)}"
      ],
      "metadata": {
        "id": "fQ6WrrGjp6mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------\n",
        "#     Metrics & plots\n",
        "# ------------------------\n",
        "def fpr_at_dr(y_true, scores, target_dr=0.95, positive_label=1):\n",
        "    thresholds = np.unique(scores)\n",
        "    thresholds.sort()\n",
        "    best_fpr = None\n",
        "    best_thr = None\n",
        "    for thr in thresholds:\n",
        "        y_pred = (scores >= thr).astype(int)\n",
        "        pos = (y_true == positive_label)\n",
        "        neg = ~pos\n",
        "        tp = (pos & (y_pred == 1)).sum()\n",
        "        fn = (pos & (y_pred == 0)).sum()\n",
        "        dr = tp / max(tp + fn, 1)\n",
        "        if dr >= target_dr:\n",
        "            fp = (neg & (y_pred == 1)).sum()\n",
        "            fpr = fp / max(neg.sum(), 1)\n",
        "            if best_fpr is None or fpr < best_fpr:\n",
        "                best_fpr = fpr; best_thr = thr\n",
        "    return best_fpr if best_fpr is not None else np.nan, best_thr\n",
        "\n",
        "def expected_calibration_error(y_true, probas, n_bins=15):\n",
        "    confidences = probas.max(axis=1)\n",
        "    predictions = probas.argmax(axis=1)\n",
        "    correct = (predictions == y_true).astype(float)\n",
        "    bins = np.linspace(0.0, 1.0, n_bins+1)\n",
        "    ece = 0.0\n",
        "    for i in range(n_bins):\n",
        "        mask = (confidences > bins[i]) & (confidences <= bins[i+1])\n",
        "        if mask.sum() == 0: continue\n",
        "        acc = correct[mask].mean()\n",
        "        conf = confidences[mask].mean()\n",
        "        ece += (mask.mean()) * abs(acc - conf)\n",
        "    return ece\n",
        "\n",
        "def plot_pr_curves(y_onehot, probas, class_names, out_png):\n",
        "    if y_onehot.shape[0] > 150000:\n",
        "        idx = np.random.RandomState(42).choice(y_onehot.shape[0], size=150000, replace=False)\n",
        "        y_onehot = y_onehot[idx]; probas = probas[idx]\n",
        "    n_classes = y_onehot.shape[1]\n",
        "    plt.figure()\n",
        "    for c in range(n_classes):\n",
        "        precision, recall, _ = precision_recall_curve(y_onehot[:, c], probas[:, c])\n",
        "        ap = average_precision_score(y_onehot[:, c], probas[:, c])\n",
        "        plt.plot(recall, precision, label=f\"{class_names[c]} (AP={ap:.3f})\")\n",
        "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall Curves\")\n",
        "    plt.legend(); plt.tight_layout(); plt.savefig(out_png, dpi=180); plt.close()\n",
        "\n",
        "def plot_confusion(y_true, y_pred, class_names, out_png, normalize='true'):\n",
        "    if y_true.shape[0] > 150000:\n",
        "        idx = np.random.RandomState(42).choice(y_true.shape[0], size=150000, replace=False)\n",
        "        y_true = y_true[idx]; y_pred = y_pred[idx]\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)), normalize=normalize)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "    fig, ax = plt.subplots(); disp.plot(ax=ax, values_format=\".2f\", cmap=None, colorbar=False)\n",
        "    plt.title(\"Confusion Matrix\" + (f\" (normalized={normalize})\" if normalize else \"\"))\n",
        "    plt.tight_layout(); plt.savefig(out_png, dpi=180); plt.close()"
      ],
      "metadata": {
        "id": "-u5qkHAFp6jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "#          Robust, NaN-safe preprocessing\n",
        "# ----------------------------------------------------\n",
        "class SafeNaNDropper(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        X = np.asarray(X, dtype=float)\n",
        "        X = np.where(np.isfinite(X), X, np.nan)\n",
        "        self.keep_mask_ = ~np.all(np.isnan(X), axis=0)\n",
        "        if not np.any(self.keep_mask_):\n",
        "            raise ValueError(\"All features are NaN after cleaning.\")\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        X = np.asarray(X, dtype=float)\n",
        "        X = np.where(np.isfinite(X), X, np.nan)\n",
        "        return X[:, self.keep_mask_]"
      ],
      "metadata": {
        "id": "0hnc7HtvqH1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------\n",
        "#     Models\n",
        "# -----------------\n",
        "def build_scaler(name):\n",
        "    if name == \"standard\":\n",
        "        return StandardScaler()\n",
        "    elif name == \"robust\":\n",
        "        return RobustScaler(with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0))\n",
        "    elif name == \"quantile\":\n",
        "        return QuantileTransformer(output_distribution=\"normal\", subsample=200000, random_state=42)\n",
        "    else:\n",
        "        return StandardScaler()\n",
        "\n",
        "def get_lr_pipeline(use_smote, random_state, scaler_name='standard', C=1.0):\n",
        "    lr = LogisticRegression(C=C, max_iter=2000, solver=\"lbfgs\", class_weight=\"balanced\", n_jobs=-1)\n",
        "    steps = [\n",
        "        (\"clean\", SafeNaNDropper()),\n",
        "        (\"imputer\", SimpleImputer(strategy='median', add_indicator=True)),\n",
        "        (\"varth\", VarianceThreshold(threshold=0.0)),\n",
        "        (\"scaler\", build_scaler(scaler_name)),\n",
        "    ]\n",
        "    if use_smote:\n",
        "        steps.append((\"smote\", SMOTE(random_state=random_state)))\n",
        "    steps.append((\"lr\", lr))\n",
        "    pipe = ImbPipeline(steps=steps)\n",
        "    return pipe\n",
        "\n",
        "def fit_lr_then_mlp(X_train, y_train, X_val, y_val, use_smote, random_state, max_epochs, batch_size, hidden_units, alpha=1e-4, scaler_name='standard', C=1.0, early_stopping=True):\n",
        "    if X_train.shape[1] != X_val.shape[1]:\n",
        "        print(f\"[ERROR] Feature mismatch: X_train has {X_train.shape[1]} features, X_val has {X_val.shape[1]}.\")\n",
        "        return None, None\n",
        "    if len(np.unique(y_train)) < 2:\n",
        "        print(\"[WARN] Skipping LR pipeline (single-class training data).\")\n",
        "        return None, None\n",
        "    pipe = get_lr_pipeline(use_smote, random_state, scaler_name=scaler_name, C=C)\n",
        "    pipe.fit(X_train, y_train)\n",
        "    try:\n",
        "        Z_train = pipe.decision_function(X_train).reshape(-1, 1)\n",
        "        Z_val = pipe.decision_function(X_val).reshape(-1, 1)\n",
        "    except Exception:\n",
        "        Z_train = np.log(np.clip(pipe.predict_proba(X_train), 1e-7, 1-1e-7))\n",
        "        Z_val = np.log(np.clip(pipe.predict_proba(X_val), 1e-7, 1-1e-7))\n",
        "        if Z_train.ndim == 1: Z_train = Z_train.reshape(-1, 1)\n",
        "        if Z_val.ndim   == 1: Z_val   = Z_val.reshape(-1, 1)\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(hidden_units,), alpha=alpha,\n",
        "                        batch_size=batch_size, learning_rate_init=1e-3,\n",
        "                        max_iter=max_epochs, random_state=random_state,\n",
        "                        early_stopping=True, n_iter_no_change=5, validation_fraction=0.1)\n",
        "    mlp.fit(Z_train, y_train)\n",
        "    return pipe, mlp"
      ],
      "metadata": {
        "id": "vMM-7PyhqHyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------\n",
        "#        Binary / Multiclass evaluation\n",
        "# ------------------------------------------------\n",
        "def eval_binary(y_true, prob_pos, tag, outdir):\n",
        "    if prob_pos is None or len(prob_pos) == 0:\n",
        "        with open(os.path.join(outdir, f\"{tag}__binary_report.txt\"), \"w\") as f:\n",
        "            f.write(\"Binary evaluation skipped due to insufficient classes or probabilities.\\n\")\n",
        "        return\n",
        "    auc = roc_auc_score(y_true, prob_pos)\n",
        "    aupr = average_precision_score(y_true, prob_pos)\n",
        "    metrics = {\"roc_auc\": float(auc), \"aupr\": float(aupr)}\n",
        "    for dr in [0.90, 0.95]:\n",
        "        fpr, thr = fpr_at_dr(y_true, prob_pos, target_dr=dr)\n",
        "        metrics[f\"fpr@dr={dr}\"] = float(fpr) if fpr==fpr else None\n",
        "        metrics[f\"thr@dr={dr}\"] = float(thr) if thr is not None else None\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    with open(os.path.join(outdir, f\"{tag}__binary_metrics.json\"), \"w\") as f:\n",
        "        json.dump(metrics, f, indent=2)\n",
        "    best_thr = metrics.get(\"thr@dr=0.95\", 0.5)\n",
        "    y_pred = (prob_pos >= (best_thr if best_thr is not None else 0.5)).astype(int)\n",
        "    report = classification_report(y_true, y_pred, digits=4)\n",
        "    with open(os.path.join(outdir, f\"{tag}__binary_report.txt\"), \"w\") as f:\n",
        "        f.write(report)\n",
        "\n",
        "def eval_multiclass(y_true, probas, class_names, tag, outdir, train_classes=None):\n",
        "    if probas is None or probas.shape[0] == 0:\n",
        "        with open(os.path.join(outdir, f\"{tag}__multiclass_metrics.json\"), \"w\") as f:\n",
        "            json.dump({\"accuracy\": np.nan, \"f1_macro\": np.nan,\n",
        "                       \"aupr_micro\": np.nan, \"aupr_per_class\": {}, \"ece\": np.nan}, f, indent=2)\n",
        "        return\n",
        "    test_classes = sorted(np.unique(y_true))\n",
        "    if train_classes is None:\n",
        "        k = min(len(test_classes), probas.shape[1])\n",
        "        probas_aligned = np.zeros((probas.shape[0], len(test_classes)))\n",
        "        probas_aligned[:, :k] = probas[:, :k]\n",
        "        used_classes = test_classes\n",
        "    else:\n",
        "        used_classes = test_classes\n",
        "        probas_aligned = np.zeros((probas.shape[0], len(test_classes)))\n",
        "        for j, cls in enumerate(train_classes):\n",
        "            if cls in test_classes:\n",
        "                idx = test_classes.index(cls)\n",
        "                probas_aligned[:, idx] = probas[:, j]\n",
        "    y_pred = probas_aligned.argmax(axis=1)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1m = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    class_names_eval = [f\"C{c}\" for c in used_classes]\n",
        "    y_idx = np.array([used_classes.index(c) for c in y_true])\n",
        "    y_onehot = make_one_hot(y_idx, len(used_classes))\n",
        "    aupr_micro = average_precision_score(y_onehot, probas_aligned, average=\"micro\")\n",
        "    aupr_per = {class_names_eval[i]: float(average_precision_score(y_onehot[:, i], probas_aligned[:, i]))\n",
        "                for i in range(len(used_classes))}\n",
        "    ece = expected_calibration_error(y_idx, probas_aligned, n_bins=15)\n",
        "    with open(os.path.join(outdir, f\"{tag}__multiclass_metrics.json\"), \"w\") as f:\n",
        "        json.dump({\"accuracy\": float(acc), \"f1_macro\": float(f1m),\n",
        "                   \"aupr_micro\": float(aupr_micro),\n",
        "                   \"aupr_per_class\": aupr_per, \"ece\": float(ece)}, f, indent=2)\n",
        "    plot_pr_curves(y_onehot, probas_aligned, class_names_eval, os.path.join(outdir, f\"{tag}__pr_curves.png\"))\n",
        "    plot_confusion(y_idx, y_pred, class_names_eval, os.path.join(outdir, f\"{tag}__confusion.png\"))"
      ],
      "metadata": {
        "id": "-HR-vzYsqS03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "#            Adversarial utils\n",
        "# --------------------------------------------\n",
        "def fgsm(X_std, y, model, eps):\n",
        "    W = model.coef_.reshape(1, -1)\n",
        "    z = model.decision_function(X_std)\n",
        "    p = 1.0/(1.0+np.exp(-z))\n",
        "    grad = (p - y.reshape(-1))[:, None] * W\n",
        "    return X_std + eps * np.sign(grad)\n",
        "\n",
        "def pgd(X_std, y, model, eps, alpha, steps):\n",
        "    X_adv = X_std.copy()\n",
        "    for _ in range(steps):\n",
        "        X_adv = fgsm(X_adv, y, model, alpha)\n",
        "        delta = np.clip(X_adv - X_std, -eps, eps)\n",
        "        X_adv = X_std + delta\n",
        "    return X_adv\n",
        "\n",
        "def clip_to_train_range(X_std, scaler, X_train_std_min, X_train_std_max):\n",
        "    X_raw = X_std\n",
        "    X_raw = np.clip(X_raw, X_train_std_min, X_train_std_max)\n",
        "    return X_raw"
      ],
      "metadata": {
        "id": "4SxTbpwGqSx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "#       Automapper\n",
        "# ----------------------\n",
        "_token_map = {\n",
        "    \"packets\":\"pkts\",\"packet\":\"pkt\",\"length\":\"len\",\"average\":\"mean\",\"stddev\":\"std\",\"std_dev\":\"std\",\n",
        "    \"backward\":\"bwd\",\"forward\":\"fwd\",\"persec\":\"persec\",\"per_second\":\"persec\",\"rate\":\"persec\",\n",
        "    \"bytes\":\"byts\",\"byte\":\"byt\",\"duration\":\"dur\",\"interarrival\":\"iat\",\"src\":\"src\",\"dst\":\"dst\",\n",
        "    \"throughput\":\"bytspersec\",\"bps\":\"bytspersec\",\"bpss\":\"bytspersec\"\n",
        "}\n",
        "def keyify(name: str) -> str:\n",
        "    s = re.sub(r'[^a-zA-Z0-9]+', '', name.lower())\n",
        "    for k,v in _token_map.items():\n",
        "        s = s.replace(k, v)\n",
        "    s = re.sub(r'[aeiou]', '', s)\n",
        "    return s\n",
        "\n",
        "def automap_features(dfA, featsA, dfB, featsB, threshold=0.86, max_pairs=64):\n",
        "    keysA = {f: keyify(f) for f in featsA}\n",
        "    keysB = {f: keyify(f) for f in featsB}\n",
        "    pairs = []\n",
        "    for a,ka in keysA.items():\n",
        "        best_b = None; best_sim = 0.0\n",
        "        for b,kb in keysB.items():\n",
        "            sim = difflib.SequenceMatcher(None, ka, kb).ratio()\n",
        "            if sim > best_sim: best_sim, best_b = sim, b\n",
        "        if best_sim >= threshold and np.issubdtype(dfA[a].dtype, np.number) and np.issubdtype(dfB[best_b].dtype, np.number):\n",
        "            pairs.append((a, b, float(sim)))\n",
        "    pairs.sort(key=lambda x: -x[2])\n",
        "    usedA, usedB, final = set(), set(), []\n",
        "    for a,b,sim in pairs:\n",
        "        if a in usedA or b in usedB: continue\n",
        "        final.append((a,b,sim))\n",
        "        usedA.add(a); usedB.add(b)\n",
        "        if len(final) >= max_pairs: break\n",
        "    return final\n",
        "\n",
        "def apply_automap_and_rename(df_src, feats_src, df_tgt, feats_tgt, outdir, tag_prefix):\n",
        "    common = list(sorted(set(feats_src).intersection(set(feats_tgt))))\n",
        "    audit = {\"mode\": \"intersection\", \"count\": len(common), \"pairs\": []}\n",
        "    audit_path = os.path.join(outdir, f\"{tag_prefix}__feature_automap.json\")\n",
        "    if len(common) > 0:\n",
        "        with open(audit_path, \"w\") as f: json.dump(audit, f, indent=2)\n",
        "        with open(os.path.join(outdir, f\"{tag_prefix}_common_features.json\"), \"w\") as f:\n",
        "            json.dump({\"count\": len(common), \"features\": common, \"audit\": os.path.basename(audit_path)}, f, indent=2)\n",
        "        return df_src, df_tgt, common, audit_path\n",
        "    matches = automap_features(df_src, feats_src, df_tgt, feats_tgt,\n",
        "                               threshold=CFG[\"automap\"][\"similarity_threshold\"],\n",
        "                               max_pairs=CFG[\"automap\"][\"max_pairs\"])\n",
        "    audit = {\"mode\": \"automap\", \"count\": len(matches),\n",
        "             \"pairs\": [{\"src\":a,\"tgt\":b,\"similarity\":sim} for a,b,sim in matches]}\n",
        "    df_tgt2 = df_tgt.copy()\n",
        "    rename_map = {b:a for a,b,_ in matches}\n",
        "    df_tgt2 = df_tgt2.rename(columns=rename_map)\n",
        "    common2 = [a for a,_,_ in matches]\n",
        "    audit[\"renamed\"] = rename_map\n",
        "    with open(audit_path, \"w\") as f: json.dump(audit, f, indent=2)\n",
        "    with open(os.path.join(outdir, f\"{tag_prefix}_common_features.json\"), \"w\") as f:\n",
        "        json.dump({\"count\": len(common2), \"features\": common2, \"audit\": os.path.basename(audit_path)}, f, indent=2)\n",
        "    return df_src, df_tgt2, common2, audit_path"
      ],
      "metadata": {
        "id": "txUSlWEMqWuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------\n",
        "#         Helpers: RUN_DIR + artifact I/O\n",
        "# --------------------------------------------------\n",
        "def get_run_dir(outdir):\n",
        "    rd = CFG[\"paths\"][\"run_dir\"] or os.path.join(outdir, \"artifacts\")\n",
        "    os.makedirs(rd, exist_ok=True)\n",
        "    return rd\n",
        "\n",
        "def save_artifact(obj, path):\n",
        "    tmp = path + f\".tmp{int(time.time()*1000)}\"\n",
        "    dump(obj, tmp)\n",
        "    os.replace(tmp, path)\n",
        "\n",
        "def metric_row_csv(csv_path, header, row):\n",
        "    new = not os.path.exists(csv_path)\n",
        "    with open(csv_path, \"a\") as f:\n",
        "        if new: f.write(\",\".join(header)+\"\\n\")\n",
        "        f.write(\",\".join(map(str,row))+\"\\n\")"
      ],
      "metadata": {
        "id": "w7yPlUabqWre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "#      NF in-domain\n",
        "# -----------------------\n",
        "def run_in_domain_nf(nf_df, nf_feats, nf_bin_col, nf_mc_col, outdir):\n",
        "    RUN_DIR = get_run_dir(outdir)\n",
        "\n",
        "    yb = build_binary_labels(nf_df, nf_bin_col, nf_mc_col)\n",
        "    X = nf_df[nf_feats].values\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(X, yb, test_size=CFG[\"train\"][\"test_size\"],\n",
        "                                              stratify=yb, random_state=CFG[\"train\"][\"random_state\"])\n",
        "\n",
        "    pipe, mlp = fit_lr_then_mlp(X_tr, y_tr, X_te, y_te,\n",
        "                                CFG[\"train\"][\"use_smote\"], CFG[\"train\"][\"random_state\"],\n",
        "                                CFG[\"train\"][\"max_epochs\"], CFG[\"train\"][\"batch_size\"],\n",
        "                                CFG[\"train\"][\"mlp_hidden_units\"])\n",
        "\n",
        "    if pipe is not None and mlp is not None:\n",
        "        save_artifact(pipe, os.path.join(RUN_DIR, \"NF_in_domain_pipe.joblib\"))\n",
        "        save_artifact(mlp,  os.path.join(RUN_DIR, \"NF_in_domain_mlp.joblib\"))\n",
        "\n",
        "    prob_pos = None\n",
        "    if pipe is not None:\n",
        "        try:\n",
        "            Z_te = pipe.decision_function(X_te).reshape(-1,1)\n",
        "        except Exception:\n",
        "            Z_te = np.log(np.clip(pipe.predict_proba(X_te), 1e-7, 1-1e-7)).reshape(-1,1)\n",
        "        prob_pos = mlp.predict_proba(Z_te)[:,1] if mlp is not None else pipe.predict_proba(X_te)[:,1]\n",
        "    eval_binary(y_te, prob_pos, \"NF_ToN_IoT__in_domain\", outdir)\n",
        "\n",
        "    if prob_pos is not None:\n",
        "        roc = roc_auc_score(y_te, prob_pos)\n",
        "        aupr = average_precision_score(y_te, prob_pos)\n",
        "        f90, _ = fpr_at_dr(y_te, prob_pos, 0.90); f95, _ = fpr_at_dr(y_te, prob_pos, 0.95)\n",
        "        metric_row_csv(os.path.join(RUN_DIR, \"metrics_log.csv\"),\n",
        "                       [\"phase\",\"roc_auc\",\"aupr\",\"fpr@0.90\",\"fpr@0.95\"],\n",
        "                       [\"NF_clean\", roc, aupr, f90, f95])\n",
        "\n",
        "    if pipe is not None:\n",
        "        Xt_tr_std = pipe.named_steps[\"scaler\"].transform(\n",
        "            pipe.named_steps[\"varth\"].transform(\n",
        "                pipe.named_steps[\"imputer\"].transform(\n",
        "                    pipe.named_steps[\"clean\"].transform(X_tr))))\n",
        "        Xt_te_std = pipe.named_steps[\"scaler\"].transform(\n",
        "            pipe.named_steps[\"varth\"].transform(\n",
        "                pipe.named_steps[\"imputer\"].transform(\n",
        "                    pipe.named_steps[\"clean\"].transform(X_te))))\n",
        "        Xmin, Xmax = Xt_tr_std.min(axis=0), Xt_tr_std.max(axis=0)\n",
        "\n",
        "        if Xt_te_std.shape[0] > 200000:\n",
        "            rs = np.random.RandomState(42)\n",
        "            idx = rs.choice(Xt_te_std.shape[0], size=200000, replace=False)\n",
        "            Xt_te_std = Xt_te_std[idx]; y_te_adv = y_te[idx]\n",
        "        else:\n",
        "            y_te_adv = y_te\n",
        "\n",
        "        lr = pipe.named_steps[\"lr\"]\n",
        "        for eps in CFG[\"robust\"][\"eps\"]:\n",
        "            X_fgsm = fgsm(Xt_te_std, y_te_adv, lr, eps)\n",
        "            X_fgsm = clip_to_train_range(X_fgsm, pipe.named_steps[\"scaler\"], Xmin, Xmax)\n",
        "            z_fgsm = lr.decision_function(X_fgsm).reshape(-1,1)\n",
        "            prob_fgsm = mlp.predict_proba(z_fgsm)[:,1] if mlp is not None else 1.0/(1.0+np.exp(-z_fgsm)).ravel()\n",
        "            eval_binary(y_te_adv, prob_fgsm, f\"NF_ToN_IoT__in_domain__FGSM_eps={eps}\", outdir)\n",
        "\n",
        "            X_pgd = pgd(Xt_te_std, y_te_adv, lr, eps, CFG[\"robust\"][\"pgd_alpha\"], CFG[\"robust\"][\"pgd_steps\"])\n",
        "            X_pgd = clip_to_train_range(X_pgd, pipe.named_steps[\"scaler\"], Xmin, Xmax)\n",
        "            z_pgd = lr.decision_function(X_pgd).reshape(-1,1)\n",
        "            prob_pgd = mlp.predict_proba(z_pgd)[:,1] if mlp is not None else 1.0/(1.0+np.exp(-z_pgd)).ravel()\n",
        "            eval_binary(y_te_adv, prob_pgd, f\"NF_ToN_IoT__in_domain__PGD_eps={eps}\", outdir)\n",
        "\n",
        "    if nf_mc_col:\n",
        "        ym = nf_df[nf_mc_col].astype(int).values\n",
        "        Xm_tr, Xm_te, ym_tr, ym_te = train_test_split(X, ym, test_size=CFG[\"train\"][\"test_size\"],\n",
        "                                                      stratify=ym, random_state=CFG[\"train\"][\"random_state\"])\n",
        "        if len(np.unique(ym_tr)) >= 2:\n",
        "            pipe_m = SkPipeline([\n",
        "              (\"clean\", SafeNaNDropper()),\n",
        "              (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
        "              (\"scaler\", StandardScaler()),\n",
        "              (\"clf\", LogisticRegression(max_iter=2000, n_jobs=-1))\n",
        "            ])\n",
        "            pipe_m.fit(Xm_tr, ym_tr)\n",
        "            probas = pipe_m.predict_proba(Xm_te)\n",
        "\n",
        "            class_names = [f\"C{c}\" for c in sorted(np.unique(ym))]\n",
        "            eval_multiclass(ym_te, probas, class_names, \"NF_ToN_IoT__in_domain_native_mc\", outdir,\n",
        "                            train_classes=list(pipe_m.named_steps[\"clf\"].classes_))"
      ],
      "metadata": {
        "id": "zPY0rEAMqi-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------\n",
        "# CIC native multiclass\n",
        "# -----------------------------------\n",
        "def run_in_domain_cic_native_mc(cic_tr_df, cic_tr_feats, cic_tr_mc_col,\n",
        "                                cic_te_df, cic_te_feats, cic_te_mc_col, outdir):\n",
        "    common = list(sorted(set(cic_tr_feats).intersection(set(cic_te_feats))))\n",
        "    if len(common) == 0: return\n",
        "    Xtr = cic_tr_df[common].values\n",
        "    Xte = cic_te_df[common].values\n",
        "    ym_tr = cic_tr_df[cic_tr_mc_col].astype(int).values if cic_tr_mc_col else None\n",
        "    ym_te = cic_te_df[cic_te_mc_col].astype(int).values if cic_te_mc_col else None\n",
        "    if ym_tr is None or ym_te is None or len(np.unique(ym_tr)) < 2: return\n",
        "\n",
        "    pipe_m = SkPipeline([\n",
        "    (\"clean\", SafeNaNDropper()),\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=2000, n_jobs=-1))\n",
        "    ])\n",
        "    pipe_m.fit(Xtr, ym_tr)\n",
        "    probas = pipe_m.predict_proba(Xte)\n",
        "\n",
        "    class_names = [f\"C{c}\" for c in sorted(np.unique(ym_te))]\n",
        "    train_classes = list(pipe_m.named_steps[\"clf\"].classes_)\n",
        "    eval_multiclass(ym_te, probas, class_names, \"CIC_IoMT__native_multiclass__train_to_test\", outdir, train_classes=train_classes)"
      ],
      "metadata": {
        "id": "Y4LgEKImqi6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------------\n",
        "#        CIC tiny benign slice experiment (with artifacts + robustness)\n",
        "# --------------------------------------------------------------------------------\n",
        "def run_cic_with_tiny_benign_slice(cic_tr_df, cic_tr_feats, cic_tr_bin_col, cic_tr_mc_col,\n",
        "                                   cic_te_df, cic_te_feats, cic_te_bin_col, cic_te_mc_col,\n",
        "                                   outdir, slice_frac=0.015, seed=42):\n",
        "    RUN_DIR = get_run_dir(outdir)\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    try:\n",
        "        rs = np.random.RandomState(seed)\n",
        "        common = list(sorted(set(cic_tr_feats).intersection(set(cic_te_feats))))\n",
        "        if len(common) == 0:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: no shared numeric features between CIC_train and CIC_test.\\n\")\n",
        "            return\n",
        "        if cic_tr_mc_col is None or cic_te_mc_col is None:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: multiclass label column not found in CIC train/test.\\n\")\n",
        "            return\n",
        "\n",
        "        y_tr_mc = cic_tr_df[cic_tr_mc_col].astype(int).values\n",
        "        X_tr_all = cic_tr_df[common].values\n",
        "        A_idx = np.where(y_tr_mc != 0)[0]\n",
        "        if len(A_idx) == 0:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: CIC_train has no attacks; cannot build binary head.\\n\")\n",
        "            return\n",
        "        X_attack_all = X_tr_all[A_idx]\n",
        "\n",
        "        y_te_mc = cic_te_df[cic_te_mc_col].astype(int).values\n",
        "        X_te_all = cic_te_df[common].values\n",
        "        ben_idx_all = np.where(y_te_mc == 0)[0]\n",
        "        atk_idx_all = np.where(y_te_mc != 0)[0]\n",
        "        if len(ben_idx_all) == 0:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: no benign samples in CIC_test.\\n\")\n",
        "            return\n",
        "\n",
        "        n_ben_slice = max(1, int(len(ben_idx_all) * slice_frac))\n",
        "        ben_slice = rs.choice(ben_idx_all, size=n_ben_slice, replace=False)\n",
        "        n_ben_cal  = max(1, n_ben_slice // 2)\n",
        "        n_ben_train = n_ben_slice - n_ben_cal\n",
        "        rs.shuffle(ben_slice)\n",
        "        ben_train_idx = ben_slice[:n_ben_train]\n",
        "        ben_cal_idx   = ben_slice[n_ben_train:]\n",
        "        n_atk_cal = min(len(atk_idx_all), n_ben_cal)\n",
        "        atk_cal_idx = rs.choice(atk_idx_all, size=n_atk_cal, replace=False)\n",
        "\n",
        "        held_out_mask = np.ones(len(y_te_mc), dtype=bool)\n",
        "        held_out_mask[ben_slice] = False\n",
        "        held_out_mask[atk_cal_idx] = False\n",
        "        X_eval = X_te_all[held_out_mask]\n",
        "        y_eval_bin = (y_te_mc[held_out_mask] != 0).astype(int)\n",
        "        if X_eval.shape[0] == 0 or len(np.unique(y_eval_bin)) < 2:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: empty or single-class held-out evaluation set after slicing.\\n\")\n",
        "            return\n",
        "\n",
        "        X_train = np.vstack([X_attack_all, X_te_all[ben_train_idx]])\n",
        "        y_train_bin = np.concatenate([np.ones(len(X_attack_all), dtype=int),\n",
        "                                      np.zeros(len(ben_train_idx), dtype=int)])\n",
        "\n",
        "        X_cal = np.vstack([X_te_all[atk_cal_idx], X_te_all[ben_cal_idx]])\n",
        "        y_cal_bin = np.concatenate([np.ones(len(atk_cal_idx), dtype=int),\n",
        "                                    np.zeros(len(ben_cal_idx), dtype=int)])\n",
        "\n",
        "        pipe_b, mlp_b = fit_lr_then_mlp(\n",
        "            X_train, y_train_bin,\n",
        "            X_eval,  y_eval_bin,\n",
        "            CFG[\"train\"][\"use_smote\"], CFG[\"train\"][\"random_state\"],\n",
        "            CFG[\"train\"][\"max_epochs\"], CFG[\"train\"][\"batch_size\"],\n",
        "            CFG[\"train\"][\"mlp_hidden_units\"]\n",
        "        )\n",
        "        if pipe_b is None:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: training pipeline failed (single-class or pipeline error).\\n\")\n",
        "            return\n",
        "\n",
        "        save_artifact(pipe_b, os.path.join(RUN_DIR, \"CIC_tiny_slice_pipe.joblib\"))\n",
        "        save_artifact(mlp_b,  os.path.join(RUN_DIR, \"CIC_tiny_slice_mlp.joblib\"))\n",
        "\n",
        "        try:\n",
        "            Z_eval = pipe_b.decision_function(X_eval).reshape(-1,1)\n",
        "            Z_cal  = pipe_b.decision_function(X_cal).reshape(-1,1)\n",
        "            prob_eval = mlp_b.predict_proba(Z_eval)[:,1]\n",
        "            prob_cal  = mlp_b.predict_proba(Z_cal)[:,1]\n",
        "        except Exception:\n",
        "            prob_eval = pipe_b.predict_proba(X_eval)[:,1]\n",
        "            prob_cal  = pipe_b.predict_proba(X_cal)[:,1]\n",
        "\n",
        "        auc_unc = float(roc_auc_score(y_eval_bin, prob_eval))\n",
        "        aupr_unc = float(average_precision_score(y_eval_bin, prob_eval))\n",
        "        fpr90_unc, thr90_unc = fpr_at_dr(y_eval_bin, prob_eval, target_dr=0.90)\n",
        "        fpr95_unc, thr95_unc = fpr_at_dr(y_eval_bin, prob_eval, target_dr=0.95)\n",
        "        eval_binary(y_eval_bin, prob_eval, \"CIC_IoMT__tiny_benign_slice\", outdir)\n",
        "\n",
        "        rows = []\n",
        "        def _row(kind, auc, aupr, f90, t90, f95, t95):\n",
        "            return {\"scenario\": f\"CIC_tiny_slice__{kind}\",\n",
        "                    \"roc_auc\": auc, \"aupr\": aupr,\n",
        "                    \"fpr@dr=0.90\": f90, \"thr@dr=0.90\": t90,\n",
        "                    \"fpr@dr=0.95\": f95, \"thr@dr=0.95\": t95}\n",
        "        rows.append(_row(\"uncalibrated\", auc_unc, aupr_unc, fpr90_unc, thr90_unc, fpr95_unc, thr95_unc))\n",
        "\n",
        "        for method in [\"temperature\", \"isotonic\"]:\n",
        "            prob_eval_cal, meta = calibrate_scores(prob_cal, y_cal_bin, prob_eval, method=method)\n",
        "            auc_c = float(roc_auc_score(y_eval_bin, prob_eval_cal))\n",
        "            aupr_c = float(average_precision_score(y_eval_bin, prob_eval_cal))\n",
        "            fpr90_c, thr90_c = fpr_at_dr(y_eval_bin, prob_eval_cal, target_dr=0.90)\n",
        "            fpr95_c, thr95_c = fpr_at_dr(y_eval_bin, prob_eval_cal, target_dr=0.95)\n",
        "            eval_binary(y_eval_bin, prob_eval_cal, f\"CIC_IoMT__tiny_benign_slice__Calibrated({method})\", outdir)\n",
        "            with open(os.path.join(outdir, f\"CIC_IoMT__tiny_benign_slice__Calibrated({method})__meta.json\"), \"w\") as f:\n",
        "                json.dump(meta, f, indent=2)\n",
        "            rows.append(_row(f\"Calibrated({method})\", auc_c, aupr_c, fpr90_c, thr90_c, fpr95_c, thr95_c))\n",
        "\n",
        "        Xt_tr_std = pipe_b.named_steps[\"scaler\"].transform(\n",
        "            pipe_b.named_steps[\"varth\"].transform(\n",
        "                pipe_b.named_steps[\"imputer\"].transform(\n",
        "                    pipe_b.named_steps[\"clean\"].transform(X_train))))\n",
        "        Xt_eval_std = pipe_b.named_steps[\"scaler\"].transform(\n",
        "            pipe_b.named_steps[\"varth\"].transform(\n",
        "                pipe_b.named_steps[\"imputer\"].transform(\n",
        "                    pipe_b.named_steps[\"clean\"].transform(X_eval))))\n",
        "        Xmin, Xmax = Xt_tr_std.min(axis=0), Xt_tr_std.max(axis=0)\n",
        "\n",
        "        if Xt_eval_std.shape[0] > 200000:\n",
        "            rs2 = np.random.RandomState(123)\n",
        "            idx = rs2.choice(Xt_eval_std.shape[0], size=200000, replace=False)\n",
        "            Xt_eval_std = Xt_eval_std[idx]; y_eval_small = y_eval_bin[idx]\n",
        "        else:\n",
        "            y_eval_small = y_eval_bin\n",
        "        lr = pipe_b.named_steps[\"lr\"]\n",
        "        for eps in CFG[\"robust\"][\"eps\"]:\n",
        "            X_fgsm = fgsm(Xt_eval_std, y_eval_small, lr, eps)\n",
        "            X_fgsm = clip_to_train_range(X_fgsm, pipe_b.named_steps[\"scaler\"], Xmin, Xmax)\n",
        "            z_fgsm = lr.decision_function(X_fgsm).reshape(-1,1)\n",
        "            prob_fgsm = mlp_b.predict_proba(z_fgsm)[:,1] if mlp_b is not None else 1.0/(1.0+np.exp(-z_fgsm)).ravel()\n",
        "            eval_binary(y_eval_small, prob_fgsm, f\"CIC_IoMT__tiny_benign_slice__FGSM_eps={eps}\", outdir)\n",
        "\n",
        "            X_pgd = pgd(Xt_eval_std, y_eval_small, lr, eps, CFG['robust']['pgd_alpha'], CFG['robust']['pgd_steps'])\n",
        "            X_pgd = clip_to_train_range(X_pgd, pipe_b.named_steps[\"scaler\"], Xmin, Xmax)\n",
        "            z_pgd = lr.decision_function(X_pgd).reshape(-1,1)\n",
        "            prob_pgd = mlp_b.predict_proba(z_pgd)[:,1] if mlp_b is not None else 1.0/(1.0+np.exp(-z_pgd)).ravel()\n",
        "            eval_binary(y_eval_small, prob_pgd, f\"CIC_IoMT__tiny_benign_slice__PGD_eps={eps}\", outdir)\n",
        "\n",
        "        pd.DataFrame(rows).to_csv(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__summary.csv\"), index=False)\n",
        "\n",
        "        with open(os.path.join(RUN_DIR, \"metrics_log.csv\"), \"a\") as f:\n",
        "            f.write(f\"CIC_tiny_slice_uncalibrated,{auc_unc},{aupr_unc},{fpr90_unc},{fpr95_unc}\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__ERROR.txt\"), \"w\") as f:\n",
        "            f.write(\"Exception occurred during tiny-slice run:\\n\")\n",
        "            f.write(str(e) + \"\\n\\n\" + traceback.format_exc())"
      ],
      "metadata": {
        "id": "jZVuVaORqpxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------------------------------\n",
        "# CIC Option A (Publication-safe): strict Train/Validation/Test split with validation-only calibration\n",
        "# -----------------------------------------------------------------------------------------------------\n",
        "def _split_three_way(X, y, train_frac=0.60, val_frac=0.20, test_frac=0.20, seed=42):\n",
        "    total = float(train_frac + val_frac + test_frac)\n",
        "    if abs(total - 1.0) > 1e-6:\n",
        "        raise ValueError(f\"train_frac+val_frac+test_frac must sum to 1.0 (got {total})\")\n",
        "    # First split: Train vs Temp\n",
        "    X_tr, X_tmp, y_tr, y_tmp = train_test_split(\n",
        "        X, y, test_size=(1.0 - train_frac), stratify=y, random_state=seed\n",
        "    )\n",
        "    # Second split: Val vs Test from Temp\n",
        "    test_share_of_tmp = test_frac / (val_frac + test_frac)\n",
        "    X_val, X_te, y_val, y_te = train_test_split(\n",
        "        X_tmp, y_tmp, test_size=test_share_of_tmp, stratify=y_tmp, random_state=seed\n",
        "    )\n",
        "    return X_tr, y_tr, X_val, y_val, X_te, y_te\n",
        "\n",
        "def _split_val_for_selection_and_calibration(X_val, y_val, val_cal_frac=0.50, seed=42):\n",
        "    if not (0.0 < val_cal_frac < 1.0):\n",
        "        raise ValueError(\"val_cal_frac must be in (0,1)\")\n",
        "    X_sel, X_cal, y_sel, y_cal = train_test_split(\n",
        "        X_val, y_val, test_size=val_cal_frac, stratify=y_val, random_state=seed\n",
        "    )\n",
        "    return X_sel, y_sel, X_cal, y_cal\n",
        "\n",
        "def _train_hybrid_lr_mlp(X_train, y_train, seed, C=1.0, hidden_units=64, scaler_name=\"standard\"):\n",
        "    pipe = get_lr_pipeline(CFG[\"train\"][\"use_smote\"], seed, scaler_name=scaler_name, C=C)\n",
        "    pipe.fit(X_train, y_train)\n",
        "    try:\n",
        "        Z_tr = pipe.decision_function(X_train).reshape(-1, 1)\n",
        "    except Exception:\n",
        "        p_tr = np.clip(pipe.predict_proba(X_train)[:, 1], 1e-7, 1-1e-7)\n",
        "        Z_tr = np.log(p_tr / (1.0 - p_tr)).reshape(-1, 1)\n",
        "\n",
        "    mlp = MLPClassifier(\n",
        "        hidden_layer_sizes=(hidden_units,),\n",
        "        alpha=1e-4,\n",
        "        batch_size=CFG[\"train\"][\"batch_size\"],\n",
        "        learning_rate_init=1e-3,\n",
        "        max_iter=CFG[\"train\"][\"max_epochs\"],\n",
        "        random_state=seed,\n",
        "        early_stopping=True,\n",
        "        n_iter_no_change=5,\n",
        "        validation_fraction=0.1\n",
        "    )\n",
        "    mlp.fit(Z_tr, y_train)\n",
        "    return pipe, mlp\n",
        "\n",
        "def _predict_hybrid(pipe, mlp, X):\n",
        "    try:\n",
        "        Z = pipe.decision_function(X).reshape(-1, 1)\n",
        "        return mlp.predict_proba(Z)[:, 1]\n",
        "    except Exception:\n",
        "        # Fallback: use LR probability if decision_function is unavailable\n",
        "        return pipe.predict_proba(X)[:, 1]\n",
        "\n",
        "def run_cic_optionA_threeway(cic_tr_df, cic_tr_feats, cic_te_df, cic_te_feats, outdir,\n",
        "                             calib_methods=(\"temperature\", \"isotonic\"),\n",
        "                             seed=42):\n",
        "    \"\"\"\n",
        "    Option A protocol (reviewer-safe):\n",
        "      1) Combine CIC train+test into a single pool (original dataset).\n",
        "      2) Strict three-way split: Train/Val/Test (default 60/20/20), stratified by binary label.\n",
        "      3) Split Val into Val-selection and Val-calibration (disjoint).\n",
        "      4) Hyperparam selection uses Val-selection only.\n",
        "      5) Final model refit on Train + Val-selection; calibration fit on Val-calibration.\n",
        "      6) Evaluate ONCE on Test with frozen model + frozen calibrator(s).\n",
        "    \"\"\"\n",
        "    RUN_DIR = get_run_dir(outdir)\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "    # Use only shared numeric features to avoid column drift.\n",
        "    common = list(sorted(set(cic_tr_feats).intersection(set(cic_te_feats))))\n",
        "    if len(common) == 0:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__OptionA__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(\"Skipped: no shared numeric features between CIC train/test files.\\n\")\n",
        "        return\n",
        "\n",
        "    df_all = pd.concat([cic_tr_df, cic_te_df], ignore_index=True, sort=False)\n",
        "    mc_col = detect_label_column(df_all, CFG[\"label_columns\"][\"multiclass_candidates\"])\n",
        "    bin_col = detect_label_column(df_all, CFG[\"label_columns\"][\"binary_candidates\"])\n",
        "    if (mc_col is None) and (bin_col is None):\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__OptionA__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(\"Skipped: no label column (binary or multiclass) found in CIC.\\n\")\n",
        "        return\n",
        "\n",
        "    y = build_binary_labels(df_all, bin_col, mc_col).astype(int)\n",
        "    X = df_all[common].values\n",
        "\n",
        "    # 60/20/20 split\n",
        "    cf = CFG[\"cic_optionA\"]\n",
        "    X_tr, y_tr, X_val, y_val, X_te, y_te = _split_three_way(\n",
        "        X, y,\n",
        "        train_frac=cf[\"train_frac\"],\n",
        "        val_frac=cf[\"val_frac\"],\n",
        "        test_frac=cf[\"test_frac\"],\n",
        "        seed=seed\n",
        "    )\n",
        "    # Validation â†’ selection + calibration\n",
        "    X_val_sel, y_val_sel, X_val_cal, y_val_cal = _split_val_for_selection_and_calibration(\n",
        "        X_val, y_val, val_cal_frac=cf[\"val_cal_frac\"], seed=seed\n",
        "    )\n",
        "\n",
        "    # Hyperparameter selection (Val-selection only)\n",
        "    best = {\"auc\": -np.inf, \"C\": None, \"hidden\": None, \"pipe\": None, \"mlp\": None}\n",
        "    for C in cf.get(\"grid_C\", [1.0]):\n",
        "        for hidden in cf.get(\"grid_hidden\", [CFG[\"train\"][\"mlp_hidden_units\"]]):\n",
        "            if len(np.unique(y_tr)) < 2:\n",
        "                continue\n",
        "            pipe, mlp = _train_hybrid_lr_mlp(X_tr, y_tr, seed=seed, C=C, hidden_units=hidden)\n",
        "            p_sel = _predict_hybrid(pipe, mlp, X_val_sel)\n",
        "            try:\n",
        "                auc = roc_auc_score(y_val_sel, p_sel)\n",
        "            except Exception:\n",
        "                auc = -np.inf\n",
        "            if auc > best[\"auc\"]:\n",
        "                best.update({\"auc\": float(auc), \"C\": float(C), \"hidden\": int(hidden), \"pipe\": pipe, \"mlp\": mlp})\n",
        "\n",
        "    if best[\"pipe\"] is None:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__OptionA__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(\"Skipped: hyperparameter selection failed (insufficient class variety).\\n\")\n",
        "        return\n",
        "\n",
        "    # Refit final model on Train + Val-selection (never touch Val-calibration or Test)\n",
        "    X_fit = np.vstack([X_tr, X_val_sel])\n",
        "    y_fit = np.concatenate([y_tr, y_val_sel])\n",
        "    pipe_final, mlp_final = _train_hybrid_lr_mlp(\n",
        "        X_fit, y_fit, seed=seed, C=best[\"C\"], hidden_units=best[\"hidden\"]\n",
        "    )\n",
        "\n",
        "    save_artifact(pipe_final, os.path.join(RUN_DIR, \"CIC_OptionA_pipe.joblib\"))\n",
        "    save_artifact(mlp_final,  os.path.join(RUN_DIR, \"CIC_OptionA_mlp.joblib\"))\n",
        "    with open(os.path.join(outdir, \"CIC_IoMT__OptionA__selected_hparams.json\"), \"w\") as f:\n",
        "        json.dump({\"C\": best[\"C\"], \"hidden_units\": best[\"hidden\"], \"val_sel_AUROC\": best[\"auc\"]}, f, indent=2)\n",
        "\n",
        "    # Uncalibrated test evaluation\n",
        "    p_test = _predict_hybrid(pipe_final, mlp_final, X_te)\n",
        "    eval_binary(y_te, p_test, \"CIC_IoMT__OptionA__uncalibrated\", outdir)\n",
        "\n",
        "    # Calibration probabilities from Val-calibration (never test)\n",
        "    p_val_cal = _predict_hybrid(pipe_final, mlp_final, X_val_cal)\n",
        "\n",
        "    rows = []\n",
        "    def _row(kind, prob):\n",
        "        auc = float(roc_auc_score(y_te, prob))\n",
        "        aupr = float(average_precision_score(y_te, prob))\n",
        "        f90, t90 = fpr_at_dr(y_te, prob, target_dr=0.90)\n",
        "        f95, t95 = fpr_at_dr(y_te, prob, target_dr=0.95)\n",
        "        return {\"scenario\": f\"CIC_OptionA__{kind}\",\n",
        "                \"roc_auc\": auc, \"aupr\": aupr,\n",
        "                \"fpr@dr=0.90\": float(f90) if f90==f90 else None, \"thr@dr=0.90\": float(t90) if t90 is not None else None,\n",
        "                \"fpr@dr=0.95\": float(f95) if f95==f95 else None, \"thr@dr=0.95\": float(t95) if t95 is not None else None,\n",
        "                \"n_test\": int(len(y_te)), \"n_train\": int(len(y_fit)),\n",
        "                \"n_val_sel\": int(len(y_val_sel)), \"n_val_cal\": int(len(y_val_cal))}\n",
        "\n",
        "    rows.append(_row(\"uncalibrated\", p_test))\n",
        "\n",
        "    for method in calib_methods:\n",
        "        p_test_cal, meta = calibrate_scores(p_val_cal, y_val_cal.astype(int), p_test, method=method)\n",
        "        eval_binary(y_te, p_test_cal, f\"CIC_IoMT__OptionA__Calibrated({method})\", outdir)\n",
        "        with open(os.path.join(outdir, f\"CIC_IoMT__OptionA__Calibrated({method})__meta.json\"), \"w\") as f:\n",
        "            json.dump(meta, f, indent=2)\n",
        "        rows.append(_row(f\"Calibrated({method})\", p_test_cal))\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(os.path.join(outdir, \"CIC_IoMT__OptionA__summary.csv\"), index=False)\n",
        "\n",
        "    # Append a compact log entry\n",
        "    with open(os.path.join(RUN_DIR, \"metrics_log.csv\"), \"a\") as f:\n",
        "        f.write(f\"CIC_OptionA_uncalibrated,{rows[0]['roc_auc']},{rows[0]['aupr']},{rows[0]['fpr@dr=0.90']},{rows[0]['fpr@dr=0.95']}\\n\")"
      ],
      "metadata": {
        "id": "AtB9LH12qpuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "#      Collapsed-binary\n",
        "# -----------------------------\n",
        "def run_in_domain_cic_collapsed(cic_tr_df, cic_tr_feats, cic_tr_mc_col,\n",
        "                                cic_te_df, cic_te_feats, cic_te_mc_col, outdir, calib_method=\"temperature\"):\n",
        "    common = list(sorted(set(cic_tr_feats).intersection(set(cic_te_feats))))\n",
        "    if len(common) == 0:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__train_to_test__binary_from_mc__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(\"Skipped: no shared numeric features between CIC_train and CIC_test.\\n\")\n",
        "        return\n",
        "    Xtr = cic_tr_df[common].values\n",
        "    Xte_full = cic_te_df[common].values\n",
        "    ym_tr = cic_tr_df[cic_tr_mc_col].astype(int).values if cic_tr_mc_col else None\n",
        "    ym_te_full = cic_te_df[cic_te_mc_col].astype(int).values if cic_te_mc_col else None\n",
        "    if ym_tr is None or ym_te_full is None or len(np.unique(ym_tr)) < 2:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__train_to_test__binary_from_mc__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(\"Skipped: multiclass labels missing or single-class in CIC_train/CIC_test.\\n\")\n",
        "        return\n",
        "\n",
        "    pipe_m = SkPipeline([\n",
        "    (\"clean\", SafeNaNDropper()),\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=2000, n_jobs=-1))\n",
        "    ])\n",
        "    pipe_m.fit(Xtr, ym_tr)\n",
        "\n",
        "    X_cal, X_eval, y_cal, y_eval = train_test_split(Xte_full, ym_te_full, test_size=1.0-CFG[\"calibration\"][\"cic_calib_frac\"],\n",
        "                                                    stratify=ym_te_full, random_state=CFG[\"train\"][\"random_state\"])\n",
        "    probas_cal = pipe_m.predict_proba(X_cal)\n",
        "    probas_eval = pipe_m.predict_proba(X_eval)\n",
        "    ben_mask_cal = (y_cal == 0)\n",
        "    if ben_mask_cal.sum() == 0:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__train_to_test__binary_from_mc__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(\"Skipped: no benign in CIC_test calibration split; cannot align benign column.\\n\")\n",
        "        return\n",
        "    mean_probs_on_ben = probas_cal[ben_mask_cal].mean(axis=0)\n",
        "    benign_idx_aligned = int(np.argmax(mean_probs_on_ben))\n",
        "    if mean_probs_on_ben[benign_idx_aligned] < 0.25:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__train_to_test__binary_from_mc__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(f\"Skipped: aligned 'benign' column probability on benign-cal < 0.25 ({mean_probs_on_ben[benign_idx_aligned]:.3f}).\\n\")\n",
        "        return\n",
        "    s_attack_cal  = 1.0 - np.clip(probas_cal[:,  benign_idx_aligned], 1e-6, 1-1e-6)\n",
        "    s_attack_eval = 1.0 - np.clip(probas_eval[:, benign_idx_aligned], 1e-6, 1-1e-6)\n",
        "    auc_cal = roc_auc_score((y_cal != 0).astype(int), s_attack_cal)\n",
        "    if auc_cal < 0.5:\n",
        "        s_attack_cal  = 1.0 - s_attack_cal\n",
        "        s_attack_eval = 1.0 - s_attack_eval\n",
        "    eval_binary((y_eval != 0).astype(int), s_attack_eval, \"CIC_IoMT__train_to_test__binary_from_mc\", outdir)\n",
        "    s_eval_cal, meta = calibrate_scores(s_attack_cal, (y_cal != 0).astype(int), s_attack_eval, method=calib_method)\n",
        "    eval_binary((y_eval != 0).astype(int), s_eval_cal, f\"CIC_IoMT__train_to_test__binary_from_mc__Calibrated({calib_method})\", outdir)\n",
        "    with open(os.path.join(outdir, f\"CIC_IoMT__train_to_test__binary_from_mc__Calibrated({calib_method})__meta.json\"), \"w\") as f:\n",
        "        json.dump({\"benign_alignment\": {\"column_index\": benign_idx_aligned,\n",
        "                                        \"mean_prob_on_benign_cal\": float(mean_probs_on_ben[benign_idx_aligned])},\n",
        "                   **meta}, f, indent=2)"
      ],
      "metadata": {
        "id": "aOS2K0lhq-kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------\n",
        "#      Cross-domain\n",
        "# -----------------------\n",
        "def run_cross_domain(nf_df, nf_feats, nf_bin_col, nf_mc_col,\n",
        "                     cic_tr_df, cic_tr_feats, cic_tr_bin_col, cic_tr_mc_col,\n",
        "                     cic_te_df, cic_te_feats, cic_te_bin_col, cic_te_mc_col,\n",
        "                     outdir, automap_min=5):\n",
        "    RUN_DIR = get_run_dir(outdir)\n",
        "\n",
        "    nf_df2, cic_te_df2, common_nf_cic, audit1 = apply_automap_and_rename(nf_df, nf_feats, cic_te_df, cic_te_feats, outdir, \"NF_to_CIC\")\n",
        "    if len(common_nf_cic) < automap_min:\n",
        "        with open(os.path.join(outdir, \"NF_to_CIC__xfer__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(f\"Skipped: shared features {len(common_nf_cic)} < {automap_min}\\n\")\n",
        "    else:\n",
        "        Xs = nf_df2[common_nf_cic].values\n",
        "        Xt = cic_te_df2[common_nf_cic].values\n",
        "        ys = build_binary_labels(nf_df2, nf_bin_col, nf_mc_col)\n",
        "        yt = build_binary_labels(cic_te_df2, cic_te_bin_col, cic_te_mc_col)\n",
        "        pipe, mlp = fit_lr_then_mlp(Xs, ys, Xt, np.zeros(len(Xt)),\n",
        "                                    CFG[\"train\"][\"use_smote\"], CFG[\"train\"][\"random_state\"],\n",
        "                                    CFG[\"train\"][\"max_epochs\"], CFG[\"train\"][\"batch_size\"],\n",
        "                                    CFG[\"train\"][\"mlp_hidden_units\"])\n",
        "        if pipe is not None and mlp is not None:\n",
        "            save_artifact(pipe, os.path.join(RUN_DIR, \"XFER_NF_to_CIC_pipe.joblib\"))\n",
        "            save_artifact(mlp,  os.path.join(RUN_DIR, \"XFER_NF_to_CIC_mlp.joblib\"))\n",
        "        prob_pos = None\n",
        "        if pipe is not None:\n",
        "            try:\n",
        "                Zt = pipe.decision_function(Xt).reshape(-1,1)\n",
        "            except Exception:\n",
        "                Zt = np.log(np.clip(pipe.predict_proba(Xt), 1e-7, 1-1e-7)).reshape(-1,1)\n",
        "            prob_pos = mlp.predict_proba(Zt)[:,1] if mlp is not None else pipe.predict_proba(Xt)[:,1]\n",
        "        eval_binary(yt, prob_pos, \"NF_ToN_IoT__to__CIC_IoMT_test__binary_xfer\", outdir)\n",
        "        if pipe is not None:\n",
        "            Xt_std = pipe.named_steps[\"scaler\"].transform(\n",
        "                pipe.named_steps[\"varth\"].transform(\n",
        "                    pipe.named_steps[\"imputer\"].transform(\n",
        "                        pipe.named_steps[\"clean\"].transform(Xt))))\n",
        "            Xs_std = pipe.named_steps[\"scaler\"].transform(\n",
        "                pipe.named_steps[\"varth\"].transform(\n",
        "                    pipe.named_steps[\"imputer\"].transform(\n",
        "                        pipe.named_steps[\"clean\"].transform(Xs))))\n",
        "            Xmin, Xmax = Xs_std.min(axis=0), Xs_std.max(axis=0)\n",
        "            lr = pipe.named_steps[\"lr\"]\n",
        "            for eps in CFG[\"robust\"][\"eps\"]:\n",
        "                Xt_fgsm = fgsm(Xt_std, yt, lr, eps)\n",
        "                Xt_fgsm = clip_to_train_range(Xt_fgsm, pipe.named_steps[\"scaler\"], Xmin, Xmax)\n",
        "                z_fgsm = lr.decision_function(Xt_fgsm).reshape(-1,1)\n",
        "                prob_fgsm = mlp.predict_proba(z_fgsm)[:,1] if mlp is not None else 1.0/(1.0+np.exp(-z_fgsm)).ravel()\n",
        "                eval_binary(yt, prob_fgsm, f\"NF_ToN_IoT__to__CIC_IoMT_test__FGSM_eps={eps}\", outdir)\n",
        "\n",
        "                Xt_pgd = pgd(Xt_std, yt, lr, eps, CFG[\"robust\"][\"pgd_alpha\"], CFG[\"robust\"][\"pgd_steps\"])\n",
        "                Xt_pgd = clip_to_train_range(Xt_pgd, pipe.named_steps[\"scaler\"], Xmin, Xmax)\n",
        "                z_pgd = lr.decision_function(Xt_pgd).reshape(-1,1)\n",
        "                prob_pgd = mlp.predict_proba(z_pgd)[:,1] if mlp is not None else 1.0/(1.0+np.exp(-z_pgd)).ravel()\n",
        "                eval_binary(yt, prob_pgd, f\"NF_ToN_IoT__to__CIC_IoMT_test__PGD_eps={eps}\", outdir)\n",
        "\n",
        "    cic_tr_df2, nf_df2b, common_cic_nf, audit2 = apply_automap_and_rename(cic_tr_df, cic_tr_feats, nf_df, nf_feats, outdir, \"CIC_to_NF\")\n",
        "    if len(common_cic_nf) < automap_min:\n",
        "        with open(os.path.join(outdir, \"CIC_to_NF__xfer__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(f\"Skipped: shared features {len(common_cic_nf)} < {automap_min}\\n\")\n",
        "    else:\n",
        "        Xs2 = cic_tr_df2[common_cic_nf].values\n",
        "        Xt2 = nf_df2b[common_cic_nf].values\n",
        "        ys2 = build_binary_labels(cic_tr_df2, cic_tr_bin_col, cic_tr_mc_col)\n",
        "        yt2 = build_binary_labels(nf_df2b, nf_bin_col, nf_mc_col)\n",
        "        pipe2, mlp2 = fit_lr_then_mlp(Xs2, ys2, Xt2, np.zeros(len(Xt2)),\n",
        "                                      CFG[\"train\"][\"use_smote\"], CFG[\"train\"][\"random_state\"],\n",
        "                                      CFG[\"train\"][\"max_epochs\"], CFG[\"train\"][\"batch_size\"],\n",
        "                                      CFG[\"train\"][\"mlp_hidden_units\"])\n",
        "        if pipe2 is not None and mlp2 is not None:\n",
        "            save_artifact(pipe2, os.path.join(RUN_DIR, \"XFER_CIC_to_NF_pipe.joblib\"))\n",
        "            save_artifact(mlp2,  os.path.join(RUN_DIR, \"XFER_CIC_to_NF_mlp.joblib\"))\n",
        "        prob_pos2=None\n",
        "        if pipe2 is not None:\n",
        "            try:\n",
        "                Zt2 = pipe2.decision_function(Xt2).reshape(-1,1)\n",
        "            except Exception:\n",
        "                Zt2 = np.log(np.clip(pipe2.predict_proba(Xt2), 1e-7, 1-1e-7)).reshape(-1,1)\n",
        "            prob_pos2 = mlp2.predict_proba(Zt2)[:,1] if mlp2 is not None else pipe2.predict_proba(Xt2)[:,1]\n",
        "        eval_binary(yt2, prob_pos2, \"CIC_IoMT_train__to__NF_ToN_IoT__binary_xfer\", outdir)"
      ],
      "metadata": {
        "id": "zqn3EoGNrCG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================================\n",
        "# ========= CLEAN ABLATION (LR, MLP, LRâ†’MLP uncal./Temp/Isot.), SEED-AVERAGED) =========\n",
        "# ======================================================================================\n",
        "SEEDS_FOR_ABLATION = [0,1,2,3,4]\n",
        "\n",
        "def _train_lr(Xtr, ytr, seed):\n",
        "    return LogisticRegression(C=1.0, max_iter=2000, solver=\"lbfgs\",\n",
        "                              class_weight=\"balanced\", n_jobs=-1,\n",
        "                              random_state=seed).fit(Xtr, ytr)\n",
        "\n",
        "def _train_mlp(Xtr, ytr, seed, hidden=CFG[\"train\"][\"mlp_hidden_units\"], max_epochs=CFG[\"train\"][\"max_epochs\"], batch=CFG[\"train\"][\"batch_size\"]):\n",
        "    return MLPClassifier(hidden_layer_sizes=(hidden,), activation=\"relu\",\n",
        "                         learning_rate_init=1e-3, alpha=1e-4,\n",
        "                         batch_size=batch, max_iter=max_epochs,\n",
        "                         early_stopping=True, n_iter_no_change=5,\n",
        "                         validation_fraction=0.1, random_state=seed).fit(Xtr, ytr)\n",
        "\n",
        "def _hybrid_lr_mlp_preds(Xtr, ytr, Xte, seed):\n",
        "    lr = _train_lr(Xtr, ytr, seed)\n",
        "    try:\n",
        "        z_tr = lr.decision_function(Xtr).reshape(-1,1)\n",
        "        z_te = lr.decision_function(Xte).reshape(-1,1)\n",
        "    except Exception:\n",
        "        p_tr = np.clip(lr.predict_proba(Xtr), 1e-7, 1-1e-7)\n",
        "        p_te = np.clip(lr.predict_proba(Xte), 1e-7, 1-1e-7)\n",
        "        z_tr = np.log(p_tr[:,1] / p_tr[:,0]).reshape(-1,1)\n",
        "        z_te = np.log(p_te[:,1] / p_te[:,0]).reshape(-1,1)\n",
        "    mlp = _train_mlp(z_tr, ytr, seed)\n",
        "    prob_uncal = mlp.predict_proba(z_te)[:,1]\n",
        "    return lr, mlp, z_tr, z_te, prob_uncal\n",
        "\n",
        "def _metrics_binary(y_true, prob, n_bins=15):\n",
        "    auroc = roc_auc_score(y_true, prob)\n",
        "    aupr  = average_precision_score(y_true, prob)\n",
        "    fpr95, _ = fpr_at_dr(y_true, prob, target_dr=0.95)\n",
        "    prob2 = np.vstack([1-prob, prob]).T\n",
        "    ece = expected_calibration_error(y_true.astype(int), prob2, n_bins=n_bins)\n",
        "    nll = log_loss(y_true, np.clip(prob2, 1e-12, 1-1e-12), labels=[0,1])\n",
        "    return dict(AUROC=auroc, AUPR=aupr, FPR95=fpr95, ECE=ece, NLL=nll)\n",
        "\n",
        "def _eval_variant_set(dataset_name, X, y, seeds):\n",
        "    rows = []\n",
        "    for seed in seeds:\n",
        "        Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=seed)\n",
        "        sc = StandardScaler().fit(Xtr)\n",
        "        Xtrs, Xtes = sc.transform(Xtr), sc.transform(Xte)\n",
        "\n",
        "        # LR\n",
        "        lr = _train_lr(Xtrs, ytr, seed)\n",
        "        plr = lr.predict_proba(Xtes)[:,1]\n",
        "        rows.append(dict(Dataset=dataset_name, Model=\"LR\", Seed=seed, **_metrics_binary(yte, plr)))\n",
        "\n",
        "        # MLP\n",
        "        mlp = _train_mlp(Xtrs, ytr, seed)\n",
        "        pmlp = mlp.predict_proba(Xtes)[:,1]\n",
        "        rows.append(dict(Dataset=dataset_name, Model=\"MLP\", Seed=seed, **_metrics_binary(yte, pmlp)))\n",
        "\n",
        "        # Hybrid LRâ†’MLP (uncal.)\n",
        "        lr_h, mlp_h, z_tr, z_te, p_uncal = _hybrid_lr_mlp_preds(Xtrs, ytr, Xtes, seed)\n",
        "        rows.append(dict(Dataset=dataset_name, Model=\"LRâ†’MLP (uncal.)\", Seed=seed, **_metrics_binary(yte, p_uncal)))\n",
        "\n",
        "        # Calibration split from TRAIN (10%)\n",
        "        Xtr0, Xcal, ytr0, ycal = train_test_split(Xtrs, ytr, test_size=0.10, stratify=ytr, random_state=seed)\n",
        "        lr_h2, mlp_h2, z_tr0, z_te2, p_uncal2 = _hybrid_lr_mlp_preds(Xtr0, ytr0, Xtes, seed)\n",
        "        # Cal logits->prob on CAL\n",
        "        try:\n",
        "            z_cal = lr_h2.decision_function(Xcal).reshape(-1,1)\n",
        "            p_cal = mlp_h2.predict_proba(z_cal)[:,1]\n",
        "        except Exception:\n",
        "            p_cal = mlp_h2.predict_proba(Xcal)[:,1]\n",
        "\n",
        "        # Temp\n",
        "        p_temp, _ = calibrate_scores(p_cal, (ycal==1).astype(int), p_uncal2, method=\"temperature\")\n",
        "        rows.append(dict(Dataset=dataset_name, Model=\"LRâ†’MLP (Temp)\", Seed=seed, **_metrics_binary(yte, p_temp)))\n",
        "        # Isot.\n",
        "        p_iso, _  = calibrate_scores(p_cal, (ycal==1).astype(int), p_uncal2, method=\"isotonic\")\n",
        "        rows.append(dict(Dataset=dataset_name, Model=\"LRâ†’MLP (Isot.)\", Seed=seed, **_metrics_binary(yte, p_iso)))\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def build_clean_ablation_tables(nf_df, nf_feats, nf_bin_col,\n",
        "                                cic_tr_df, cic_tr_feats, cic_te_df, cic_te_feats,\n",
        "                                outdir):\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    # NF binary\n",
        "    y_nf = build_binary_labels(nf_df, nf_bin_col, None)\n",
        "    X_nf = nf_df[nf_feats].values\n",
        "    df_nf = _eval_variant_set(\"NF-ToN-IoT\", X_nf, y_nf, SEEDS_FOR_ABLATION)\n",
        "\n",
        "    # CIC binary from native multiclass (combined pool; consistent with Option A)\n",
        "    common = sorted(set(cic_tr_feats).intersection(set(cic_te_feats)))\n",
        "    df_cic_all = pd.concat([cic_tr_df, cic_te_df], ignore_index=True, sort=False)\n",
        "    mc = detect_label_column(df_cic_all, CFG[\"label_columns\"][\"multiclass_candidates\"])\n",
        "    if mc is None:\n",
        "        raise ValueError(\"CIC multiclass label column not found for ablation table.\")\n",
        "    X_cic = df_cic_all[common].values\n",
        "    y_cic = (df_cic_all[mc].astype(int).values != 0).astype(int)\n",
        "    df_cic = _eval_variant_set(\"CIC-IoMT (WiFi--MQTT)\", X_cic, y_cic, SEEDS_FOR_ABLATION)\n",
        "\n",
        "    df_all = pd.concat([df_nf, df_cic], ignore_index=True)\n",
        "\n",
        "    abl = (df_all.groupby([\"Dataset\",\"Model\"])\n",
        "                 .agg(AUROC=(\"AUROC\",\"mean\"),\n",
        "                      AUPR=(\"AUPR\",\"mean\"),\n",
        "                      FPR95=(\"FPR95\",\"mean\"),\n",
        "                      ECE=(\"ECE\",\"mean\"),\n",
        "                      NLL=(\"NLL\",\"mean\"))\n",
        "                 .reset_index())\n",
        "\n",
        "    for c in [\"AUROC\",\"AUPR\",\"FPR95\",\"ECE\",\"NLL\"]:\n",
        "        abl[c] = abl[c].round(2)\n",
        "\n",
        "    order = [\"LR\",\"MLP\",\"LRâ†’MLP (uncal.)\",\"LRâ†’MLP (Temp)\",\"LRâ†’MLP (Isot.)\"]\n",
        "    abl[\"rank\"] = abl[\"Model\"].apply(lambda m: order.index(m) if m in order else 999)\n",
        "    abl = abl.sort_values([\"Dataset\",\"rank\"]).drop(columns=[\"rank\"])\n",
        "\n",
        "    csv_path = os.path.join(outdir, \"clean_ablation_seedavg.csv\")\n",
        "    abl.to_csv(csv_path, index=False)\n",
        "\n",
        "    lines = [f\"{r.Dataset} & {r.Model} & {r.AUROC:.2f} & {r.AUPR:.2f} & {r.FPR95:.2f} & {r.ECE:.2f} & {r.NLL:.2f} \\\\\\\\\"\n",
        "             for r in abl.itertuples()]\n",
        "    latex = r\"\"\"\\begin{table}[!t]\n",
        "\\centering\n",
        "\\caption{Clean-condition ablation (seed-averaged). LR and MLP alone vs the hybrid LR$\\rightarrow$MLP with/without calibration.}\n",
        "\\label{tab:ablation-clean}\n",
        "\\begin{tabular}{lcccccc}\n",
        "\\toprule\n",
        "Dataset & Model & AUROC $\\uparrow$ & AUPR (macro) $\\uparrow$ & FPR@95\\%DR $\\downarrow$ & ECE $\\downarrow$ & NLL $\\downarrow$ \\\\\n",
        "\\midrule\n",
        "\"\"\" + \"\\n\".join(lines) + r\"\"\"\n",
        "\\bottomrule\n",
        "\\end{tabular}\n",
        "\\end{table}\n",
        "\"\"\"\n",
        "    tex_path = os.path.join(outdir, \"clean_ablation_seedavg.tex\")\n",
        "    with open(tex_path, \"w\") as f:\n",
        "        f.write(latex)\n",
        "    print(latex)"
      ],
      "metadata": {
        "id": "cEnZJPcRrFzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------\n",
        "#    ZIP helper\n",
        "# -----------------\n",
        "def zip_outputs(outdir, zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'w', compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root, _, files in os.walk(outdir):\n",
        "            for f in files:\n",
        "                fp = os.path.join(root, f)\n",
        "                arc = os.path.relpath(fp, start=outdir)\n",
        "                zf.write(fp, arc)\n",
        "    return zip_path"
      ],
      "metadata": {
        "id": "Mtp4vxQQrMb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------\n",
        "#       Main\n",
        "# -----------------\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--grid\", action=\"store_true\", help=\"(unused here)\")\n",
        "    parser.add_argument(\"--adv-train-eps\", type=float, default=0.0)\n",
        "    parser.add_argument(\"--adv-train-frac\", type=float, default=0.3)\n",
        "    parser.add_argument(\"--cic-calib\", type=str, choices=[\"temperature\",\"isotonic\"], default=\"temperature\")\n",
        "    parser.add_argument(\"--automap-min\", type=int, default=5, help=\"Minimum shared features for cross-domain metrics\")\n",
        "    parser.add_argument(\"--cic-protocol\", type=str, choices=[\"optionA\",\"legacy\",\"both\"], default=\"optionA\",\n",
        "                        help=\"CIC evaluation protocol: 'optionA' is publication-safe (strict Train/Val/Test + val-only calibration).\")\n",
        "    parser.add_argument(\"--legacy-cic-collapsed\", action=\"store_true\",\n",
        "                        help=\"Run legacy CIC train->test collapsed-binary experiment (uses CIC_test for calibration; not publication-safe).\")\n",
        "    parser.add_argument(\"--legacy-cic-tiny-slice\", action=\"store_true\",\n",
        "                        help=\"Run legacy CIC tiny-slice experiment (uses CIC_test flows for training/calibration; not publication-safe).\")\n",
        "    parser.add_argument(\"--no-cic-tiny-slice\", action=\"store_true\", help=\"Disable the CIC tiny benign slice experiment (enabled by default).\")\n",
        "    parser.add_argument(\"--cic-slice-frac\", type=float, default=0.015, help=\"Fraction of CIC_test benign to use for training+calibration (default 1.5%).\")\n",
        "    parser.add_argument(\"--cic-slice-seed\", type=int, default=42, help=\"Random seed for benign-slice sampling.\")\n",
        "    parser.add_argument(\"--zip\", action=\"store_true\", help=\"Also compress outputs to a ZIP bundle.\")\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    outdir = CFG[\"paths\"][\"outdir\"]\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    os.makedirs(get_run_dir(outdir), exist_ok=True)\n",
        "\n",
        "    nf_df, nf_feats, nf_bin_col, nf_mc_col = load_dataset(CFG[\"paths\"][\"nf_csv\"])\n",
        "    cic_tr_df, cic_tr_feats, cic_tr_bin_col, cic_tr_mc_col = load_dataset(CFG[\"paths\"][\"cic_train_csv\"])\n",
        "    cic_te_df, cic_te_feats, cic_te_bin_col, cic_te_mc_col = load_dataset(CFG[\"paths\"][\"cic_test_csv\"])\n",
        "\n",
        "    with open(os.path.join(outdir, \"hyperparams.json\"), \"w\") as f:\n",
        "        json.dump({\n",
        "            \"random_state\": CFG[\"train\"][\"random_state\"],\n",
        "            \"use_smote\": CFG[\"train\"][\"use_smote\"],\n",
        "            \"mlp_hidden_units\": CFG[\"train\"][\"mlp_hidden_units\"],\n",
        "            \"max_epochs\": CFG[\"train\"][\"max_epochs\"],\n",
        "            \"batch_size\": CFG[\"train\"][\"batch_size\"],\n",
        "            \"target_drs\": CFG[\"metrics\"][\"target_drs\"],\n",
        "            \"robust_eps\": CFG[\"robust\"][\"eps\"],\n",
        "            \"pgd_steps\": CFG[\"robust\"][\"pgd_steps\"],\n",
        "            \"pgd_alpha\": CFG[\"robust\"][\"pgd_alpha\"],\n",
        "            \"cic_calib_frac\": CFG[\"calibration\"][\"cic_calib_frac\"],\n",
        "            \"cic_calib_method\": args.cic_calib,\n",
        "            \"automap_min\": args.automap_min,\n",
        "            \"automap_threshold\": CFG[\"automap\"][\"similarity_threshold\"],\n",
        "            \"automap_max_pairs\": CFG[\"automap\"][\"max_pairs\"],\n",
        "            \"cic_slice_frac\": args.cic_slice_frac,\n",
        "            \"cic_slice_seed\": args.cic_slice_seed\n",
        "        }, f, indent=2)\n",
        "\n",
        "    # Existing evaluations\n",
        "    run_in_domain_nf(nf_df, nf_feats, nf_bin_col, nf_mc_col, outdir)\n",
        "\n",
        "    # -----------------------------\n",
        "    #      CIC evaluations\n",
        "    # -----------------------------\n",
        "    if args.cic_protocol in [\"optionA\", \"both\"]:\n",
        "        # Publication-safe protocol: strict Train/Val/Test + validation-only calibration\n",
        "        run_cic_optionA_threeway(\n",
        "            cic_tr_df, cic_tr_feats,\n",
        "            cic_te_df, cic_te_feats,\n",
        "            outdir,\n",
        "            calib_methods=(\"temperature\", \"isotonic\"),\n",
        "            seed=CFG[\"train\"][\"random_state\"]\n",
        "        )\n",
        "\n",
        "    if args.cic_protocol in [\"legacy\", \"both\"]:\n",
        "        # Legacy/diagnostic protocols (NOT publication-safe if they touch CIC_test for calibration/training)\n",
        "        if cic_tr_mc_col and cic_te_mc_col:\n",
        "            run_in_domain_cic_native_mc(\n",
        "                cic_tr_df, cic_tr_feats, cic_tr_mc_col,\n",
        "                cic_te_df, cic_te_feats, cic_te_mc_col, outdir\n",
        "            )\n",
        "            if args.legacy_cic_collapsed:\n",
        "                run_in_domain_cic_collapsed(\n",
        "                    cic_tr_df, cic_tr_feats, cic_tr_mc_col,\n",
        "                    cic_te_df, cic_te_feats, cic_te_mc_col,\n",
        "                    outdir, calib_method=args.cic_calib\n",
        "                )\n",
        "\n",
        "        if args.legacy_cic_tiny_slice:\n",
        "            run_cic_with_tiny_benign_slice(\n",
        "                cic_tr_df, cic_tr_feats, cic_tr_bin_col, cic_tr_mc_col,\n",
        "                cic_te_df, cic_te_feats, cic_te_bin_col, cic_te_mc_col,\n",
        "                outdir, slice_frac=args.cic_slice_frac, seed=args.cic_slice_seed\n",
        "            )\n",
        "\n",
        "\n",
        "    run_cross_domain(nf_df, nf_feats, nf_bin_col, nf_mc_col,\n",
        "                     cic_tr_df, cic_tr_feats, cic_tr_bin_col, cic_tr_mc_col,\n",
        "                     cic_te_df, cic_te_feats, cic_te_bin_col, cic_te_mc_col,\n",
        "                     outdir, automap_min=args.automap_min)\n",
        "\n",
        "    # >>> NEW: Seed-averaged CLEAN ablation table (LR, MLP, LRâ†’MLP uncal./Temp/Isot.)\n",
        "    build_clean_ablation_tables(\n",
        "        nf_df, nf_feats, nf_bin_col,\n",
        "        cic_tr_df, cic_tr_feats, cic_te_df, cic_te_feats,\n",
        "        outdir=os.path.join(CFG[\"paths\"][\"outdir\"], \"paper_exports\")\n",
        "    )\n",
        "\n",
        "    if args.zip:\n",
        "        zip_path = os.path.join(Path(outdir).parent, \"outputs_bundle.zip\")\n",
        "        zip_outputs(outdir, zip_path)\n",
        "        print(f\"[OK] Wrote ZIP bundle â†’ {zip_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "gVG2W0aDrOWQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}