{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOe0XHvoGIhYhBFzXkpOJbd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankeawthong/Project-1-Lita-Chatbot/blob/main/%5B20251209%5D%20IoMT%20Pj_Clean-condition%20ablation%3A%20LR%20/%20MLP%20/%20RF%20/%20XGB%20/%20LR%E2%86%92MLP%20(Temp/Isotonic).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[20251030] Train_all_in_one — Full revision with derived features (2025-10-01)\n",
        "\n",
        "This script trains a calibrated LR→MLP IDS on NF-ToN-IoT and CIC_IoMT_2024_WiFi_MQTT\n",
        "with:\n",
        "    - Protocol-aware preprocessing & derived flow features\n",
        "    - SMOTE-based imbalance handling\n",
        "    - Temperature scaling (default) and isotonic regression (ablation)\n",
        "    - Clean vs adversarial (FGSM/PGD, ℓ∞-bounded) evaluation\n",
        "    - Clean-condition ablation of LR, MLP, LR→MLP (uncal/Temp/Isotonic)\n",
        "    - PLUS classical baselines: Random Forest and XGBoost/GBDT-style ensemble\n",
        "      included in the clean ablation table.\n",
        "\n",
        "Outputs:\n",
        "    - Metrics JSONs for clean/adversarial runs\n",
        "    - clean_ablation_seedavg.csv for manuscript Table~\\ref{tab:ablation-clean}"
      ],
      "metadata": {
        "id": "TqHYsJ5gihII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Complete training/evaluation script for LR-MLP IDS:\n",
        "- NF-ToN-IoT in-domain\n",
        "- CIC_IoMT_2024 WiFi-MQTT in-domain (full and tiny-slice benign)\n",
        "- Cross-domain NF<->CIC with feature automap\n",
        "- Calibration (temperature / isotonic)\n",
        "- Adversarial evaluation (FGSM/PGD)\n",
        "- Resource profiling (CPU + Pi4 emulation)\n",
        "- Clean-condition ablation: LR / MLP / RF / XGB / LR→MLP (Temp/Isotonic)"
      ],
      "metadata": {
        "id": "CBzOB2JtzfFG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DO2hmtkidlB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import glob\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    confusion_matrix,\n",
        "    log_loss,\n",
        "    brier_score_loss,\n",
        ")\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    HAVE_XGB = True\n",
        "except Exception:\n",
        "    HAVE_XGB = False\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "# Global configuration\n",
        "# ----------------------\n",
        "CFG = {\n",
        "    \"paths\": {\n",
        "        \"nf\": \"/content/Dataset_NF-ToN-IoT.csv\",\n",
        "        \"cic_train\": \"/content/CIC_IoMT_2024_WiFi_MQTT_train.csv\",\n",
        "        \"cic_test\": \"/content/CIC_IoMT_2024_WiFi_MQTT_test.csv\",\n",
        "        \"outdir\": \"./outputs\",\n",
        "    },\n",
        "    \"columns\": {\n",
        "        \"nf_label_binary\": \"Label\",\n",
        "        \"nf_label_mc\": \"Class\",\n",
        "        \"cic_label_binary\": \"label\",\n",
        "        \"cic_label_mc\": \"Class\",\n",
        "    },\n",
        "    \"train\": {\n",
        "        \"test_size\": 0.2,\n",
        "        \"random_state\": 42,\n",
        "        \"use_smote\": True,\n",
        "        \"smote_kind\": \"smote_tomek\",  # \"smote\" or \"smote_tomek\"\n",
        "        \"mlp_hidden_units\": 64,\n",
        "        \"mlp_dropout\": 0.2,\n",
        "        \"batch_size\": 2048,\n",
        "        \"max_epochs\": 25,\n",
        "        \"early_stopping_patience\": 5,\n",
        "    },\n",
        "    \"adv\": {\n",
        "        \"eps_list\": [0.01, 0.02, 0.05, 0.10],\n",
        "        \"pgd_steps\": 10,\n",
        "        \"pgd_alpha_factor\": 0.02,\n",
        "    },\n",
        "    \"calibration\": {\n",
        "        \"method\": \"temperature\",  # \"temperature\" or \"isotonic\"\n",
        "        \"n_bins_ece\": 15,\n",
        "        \"calib_frac\": 0.1,\n",
        "    },\n",
        "    \"tiny_slice\": {\n",
        "        \"enabled\": True,\n",
        "        \"benign_frac\": 0.015,\n",
        "        \"seed\": 42,\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "hXmg4VZdzkzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================\n",
        "# Utility helpers\n",
        "# ====================\n",
        "def ensure_outdir(path: str) -> str:\n",
        "    out = Path(path)\n",
        "    out.mkdir(parents=True, exist_ok=True)\n",
        "    return str(out)\n",
        "\n",
        "\n",
        "def get_run_dir(base_dir: str, tag: str) -> str:\n",
        "    ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    run_dir = os.path.join(base_dir, f\"{ts}__{tag}\")\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "    return run_dir\n",
        "\n",
        "\n",
        "def save_json(obj, path):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(obj, f, indent=2)\n",
        "\n",
        "\n",
        "def load_csv(path, **kwargs):\n",
        "    print(f\"[INFO] Loading CSV: {path}\")\n",
        "    return pd.read_csv(path, **kwargs)"
      ],
      "metadata": {
        "id": "LNfjV7oyzpys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# Dataset loading and preprocessing\n",
        "# =======================================================\n",
        "def load_nf_ton_iot(path: str) -> pd.DataFrame:\n",
        "    df = load_csv(path)\n",
        "    # Assume binary label column \"Label_binary\" and multi-class \"Label_multi\" already exist\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_cic_iomt_train_test(train_path: str, test_path: str) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    df_tr = load_csv(train_path)\n",
        "    df_te = load_csv(test_path)\n",
        "    return df_tr, df_te\n",
        "\n",
        "\n",
        "def build_feature_list(df: pd.DataFrame, drop_cols) -> list[str]:\n",
        "    return [c for c in df.columns if c not in drop_cols]\n",
        "\n",
        "\n",
        "def build_binary_labels(df: pd.DataFrame, bin_col: str, pos_label=None) -> np.ndarray:\n",
        "    y = df[bin_col].values\n",
        "    if y.dtype == object:  # Check if labels are strings\n",
        "        # Assuming any non-'Benign' string is an attack.\n",
        "        # If 'Benign' string exists, it will be mapped to 0.\n",
        "        # We also specifically check for 'Benign_test' for CIC_IoMT test set.\n",
        "        unique_labels = np.unique(y)\n",
        "        if 'Benign' in unique_labels or 'Benign_test' in unique_labels:\n",
        "            # Map 'Benign' or 'Benign_test' to 0, others to 1\n",
        "            y_mapped = np.where((y == 'Benign') | (y == 'Benign_test'), 0, 1)\n",
        "        else:\n",
        "            # If no benign string is found, assume all are attack types and map to 1.\n",
        "            y_mapped = np.ones_like(y, dtype=int)\n",
        "        return y_mapped\n",
        "    else:\n",
        "        # if label is already {0,1}, keep as is\n",
        "        return y.astype(int)"
      ],
      "metadata": {
        "id": "YCE5GzL3zyQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================\n",
        "# Metric helpers\n",
        "# ===================\n",
        "def fpr_at_dr(y_true, scores, target_dr=0.95):\n",
        "    \"\"\"\n",
        "    Compute FPR at a fixed detection rate (recall for the positive class).\n",
        "    Returns (fpr, threshold).\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    scores = np.asarray(scores)\n",
        "    pos_scores = scores[y_true == 1]\n",
        "    if len(pos_scores) == 0:\n",
        "        return np.nan, np.nan\n",
        "    thr = np.quantile(pos_scores, 1.0 - target_dr)\n",
        "    y_hat = (scores >= thr).astype(int)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_hat, labels=[0, 1]).ravel()\n",
        "    fpr = fp / (fp + tn + 1e-12)\n",
        "    return fpr, thr\n",
        "\n",
        "\n",
        "def expected_calibration_error(y_true, probas, n_bins=15):\n",
        "    \"\"\"\n",
        "    Multiclass/binary ECE. `probas` shape: (n_samples, n_classes).\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true)\n",
        "    probas = np.asarray(probas)\n",
        "    confidences = probas.max(axis=1)\n",
        "    predictions = probas.argmax(axis=1)\n",
        "\n",
        "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
        "    ece = 0.0\n",
        "    n = len(y_true)\n",
        "\n",
        "    for i in range(n_bins):\n",
        "        in_bin = (confidences > bins[i]) & (confidences <= bins[i + 1])\n",
        "        prop_in_bin = in_bin.mean()\n",
        "        if prop_in_bin > 0:\n",
        "            acc_in_bin = (y_true[in_bin] == predictions[in_bin]).mean()\n",
        "            avg_conf_in_bin = confidences[in_bin].mean()\n",
        "            ece += np.abs(acc_in_bin - avg_conf_in_bin) * prop_in_bin\n",
        "\n",
        "    return ece\n",
        "\n",
        "\n",
        "def plot_reliability_diagram(y_true, prob_pos, n_bins=15, title=\"\", out_path=None):\n",
        "    prob_true, prob_pred = calibration_curve(y_true, prob_pos, n_bins=n_bins, strategy=\"uniform\")\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.plot(prob_pred, prob_true, \"s-\", label=\"LR-MLP\")\n",
        "    plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfectly calibrated\")\n",
        "    plt.xlabel(\"Predicted probability\")\n",
        "    plt.ylabel(\"Empirical accuracy\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "    if out_path is not None:\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(out_path, dpi=300)\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "jhJQIrucz1nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# Adversarial generation (FGSM / PGD in feature space)\n",
        "# =======================================================\n",
        "def fgsm_attack(x, y, model, eps, clip_min, clip_max):\n",
        "    \"\"\"\n",
        "    Perform FGSM in normalized feature space.\n",
        "    Here `model` is expected to expose a gradient; in practice, we approximate\n",
        "    via the LR-MLP surrogate as per Section 3.7.\n",
        "    \"\"\"\n",
        "    # Placeholder: in the current workflow we use the trained LR-MLP and autograd\n",
        "    # from TF/Keras in the notebook; this script focuses on evaluation of\n",
        "    # already prepared adversarial datasets. If you later integrate TF here,\n",
        "    # you would compute ∂L/∂x and apply sign(eps * grad).\n",
        "    raise NotImplementedError(\"FGSM attack is implemented in the notebook pipeline.\")\n",
        "\n",
        "\n",
        "def pgd_attack(x, y, model, eps, alpha, steps, clip_min, clip_max):\n",
        "    \"\"\"\n",
        "    PGD in normalized feature space.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"PGD attack is implemented in the notebook pipeline.\")"
      ],
      "metadata": {
        "id": "B0ZIIC_tz5ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# LR-MLP hybrid training\n",
        "# ===========================\n",
        "def make_smote(kind=\"smote_tomek\", random_state=42):\n",
        "    if kind == \"smote\":\n",
        "        return SMOTE(random_state=random_state)\n",
        "    elif kind == \"smote_tomek\":\n",
        "        return SMOTETomek(random_state=random_state)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def fit_lr_then_mlp(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    X_eval,\n",
        "    y_eval,\n",
        "    use_smote=True,\n",
        "    seed=42,\n",
        "    max_epochs=25,\n",
        "    batch_size=2048,\n",
        "    hidden_units=64,\n",
        "):\n",
        "    \"\"\"\n",
        "    Fit logistic-regression front end + MLP head. Returns (pipe, mlp_model).\n",
        "    Here we keep it in sklearn MLP for simplicity; in your notebook you may have\n",
        "    a TF/Keras variant for adversarial training.\n",
        "    \"\"\"\n",
        "    # Standardize first\n",
        "    scaler = StandardScaler()\n",
        "    X_train_s = scaler.fit_transform(X_train)\n",
        "    X_eval_s = scaler.transform(X_eval)\n",
        "\n",
        "    if use_smote:\n",
        "        if len(np.unique(y_train)) > 1:\n",
        "            sampler = make_smote(CFG[\"train\"][\"smote_kind\"], random_state=seed)\n",
        "            X_train_s, y_train = sampler.fit_resample(X_train_s, y_train)\n",
        "        else:\n",
        "            print(f\"[WARN] SMOTE requested but target has {len(np.unique(y_train))} class(es). Skipping SMOTE.\")\n",
        "\n",
        "    # Logistic regression front end\n",
        "    lr = LogisticRegression(\n",
        "        penalty=\"l2\",\n",
        "        C=1.0,\n",
        "        solver=\"lbfgs\",\n",
        "        max_iter=1000,\n",
        "        class_weight=\"balanced\",\n",
        "        n_jobs=-1,\n",
        "        random_state=seed,\n",
        "    )\n",
        "\n",
        "    # Workaround: If y_train has only one class, LogisticRegression will fail.\n",
        "    # For CIC_IoMT_2024, the training data for binary classification appears to be all attacks (class 1).\n",
        "    # We add a synthetic benign sample (class 0) to allow LR to fit.\n",
        "    synthetic_sample_added = False\n",
        "    if len(np.unique(y_train)) < 2:\n",
        "        if np.unique(y_train)[0] == 1:  # If y_train consists only of attack samples\n",
        "            print(\"[WARN] Training data (y_train) contains only one class (attack). Adding a synthetic benign sample to allow LogisticRegression to fit.\")\n",
        "            # Create a synthetic benign sample: mean of X_train_s features, label 0\n",
        "            synthetic_x = X_train_s.mean(axis=0).reshape(1, -1)\n",
        "            synthetic_y = np.array([0])\n",
        "            X_train_s = np.vstack([X_train_s, synthetic_x])\n",
        "            y_train = np.append(y_train, synthetic_y)\n",
        "            synthetic_sample_added = True\n",
        "        else:\n",
        "            # If y_train consists only of benign samples, it would still cause issues\n",
        "            # but based on problem context, it's expected to be all attacks if single-class.\n",
        "            print(f\"[WARN] Training data (y_train) contains only one class ({np.unique(y_train)[0]}). LogisticRegression might not train meaningfully for binary classification.\")\n",
        "\n",
        "    lr.fit(X_train_s, y_train)\n",
        "\n",
        "    # Transform training / eval logits\n",
        "    z_train = lr.decision_function(X_train_s).reshape(-1, 1)\n",
        "    z_eval = lr.decision_function(X_eval_s).reshape(-1, 1)\n",
        "\n",
        "    # MLP classifier on top of LR logits\n",
        "    mlp = MLPClassifier(\n",
        "        hidden_layer_sizes=(hidden_units,),\n",
        "        activation=\"relu\",\n",
        "        solver=\"adam\",\n",
        "        alpha=0.0,\n",
        "        batch_size=batch_size,\n",
        "        learning_rate_init=1e-3,\n",
        "        max_iter=max_epochs,\n",
        "        early_stopping=not synthetic_sample_added, # Disable early stopping if synthetic sample was added\n",
        "        n_iter_no_change=CFG[\"train\"][\"early_stopping_patience\"], # Always provide an int, ignored if early_stopping=False\n",
        "        validation_fraction=0.1 if not synthetic_sample_added else 0.0, # Disable validation fraction if synthetic sample was added\n",
        "        random_state=seed,\n",
        "    )\n",
        "\n",
        "    mlp.fit(z_train, y_train)\n",
        "\n",
        "    class Pipe:\n",
        "        def __init__(self, scaler, lr):\n",
        "            self.scaler = scaler\n",
        "            self.lr = lr\n",
        "\n",
        "        def transform(self, X):\n",
        "            Xs = self.scaler.transform(X)\n",
        "            return self.lr.decision_function(Xs).reshape(-1, 1)\n",
        "\n",
        "    pipe = Pipe(scaler, lr)\n",
        "    return pipe, mlp"
      ],
      "metadata": {
        "id": "21fkSg7az7WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# In-domain NF-ToN-IoT\n",
        "# =========================\n",
        "def run_in_domain_nf(df: pd.DataFrame, outdir: str):\n",
        "    print(\"[NF] In-domain binary + multi-class evaluation ...\")\n",
        "    # Binary\n",
        "    bin_col = CFG[\"columns\"][\"nf_label_binary\"]\n",
        "    mc_col = CFG[\"columns\"][\"nf_label_mc\"]\n",
        "\n",
        "    # Feature list: drop labels and any non-feature columns\n",
        "    drop_cols = [bin_col, mc_col, \"Attack\"] # Added 'Attack' to drop_cols\n",
        "    feats = build_feature_list(df, drop_cols)\n",
        "\n",
        "    X = df[feats].values\n",
        "    y_bin = build_binary_labels(df, bin_col, None)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X,\n",
        "        y_bin,\n",
        "        test_size=CFG[\"train\"][\"test_size\"],\n",
        "        random_state=CFG[\"train\"][\"random_state\"],\n",
        "        stratify=y_bin,\n",
        "    )\n",
        "\n",
        "    pipe, mlp = fit_lr_then_mlp(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        X_test,\n",
        "        y_test,\n",
        "        use_smote=CFG[\"train\"][\"use_smote\"],\n",
        "        seed=CFG[\"train\"][\"random_state\"],\n",
        "        max_epochs=CFG[\"train\"][\"max_epochs\"],\n",
        "        batch_size=CFG[\"train\"][\"batch_size\"],\n",
        "        hidden_units=CFG[\"train\"][\"mlp_hidden_units\"],\n",
        "    )\n",
        "\n",
        "    z_test = pipe.transform(X_test)\n",
        "    p_test = mlp.predict_proba(z_test)[:, 1]\n",
        "\n",
        "    auroc = roc_auc_score(y_test, p_test)\n",
        "    aupr = average_precision_score(y_test, p_test)\n",
        "    fpr95, thr95 = fpr_at_dr(y_test, p_test, target_dr=0.95)\n",
        "    nll = log_loss(y_test, p_test)\n",
        "    brier = brier_score_loss(y_test, p_test)\n",
        "\n",
        "    print(f\"[NF] AUROC={auroc:.4f} AUPR={aupr:.4f} FPR@95%DR={fpr95:.4f} thr={thr95:.4f}\")\n",
        "    print(f\"[NF] NLL={nll:.4f} Brier={brier:.4f}\")\n",
        "\n",
        "    metrics = {\n",
        "        \"AUROC\": auroc,\n",
        "        \"AUPR\": aupr,\n",
        "        \"FPR@95%DR\": fpr95,\n",
        "        \"thr95\": thr95,\n",
        "        \"NLL\": nll,\n",
        "        \"Brier\": brier,\n",
        "    }\n",
        "    save_json(metrics, os.path.join(outdir, \"NF_in_domain_binary_metrics.json\"))\n",
        "\n",
        "    # Multi-class evaluation (confusion matrix, report)\n",
        "    y_mc = df[mc_col].values\n",
        "    X_train_mc, X_test_mc, y_train_mc, y_test_mc = train_test_split(\n",
        "        X,\n",
        "        y_mc,\n",
        "        test_size=CFG[\"train\"][\"test_size\"],\n",
        "        random_state=CFG[\"train\"][\"random_state\"],\n",
        "        stratify=y_mc,\n",
        "    )\n",
        "\n",
        "    # For simplicity, reuse MLP on raw standardized features for multi-class\n",
        "    scaler = StandardScaler()\n",
        "    X_train_mc_s = scaler.fit_transform(X_train_mc)\n",
        "    X_test_mc_s = scaler.transform(X_test_mc)\n",
        "\n",
        "    mlp_mc = MLPClassifier(\n",
        "        hidden_layer_sizes=(CFG[\"train\"][\"mlp_hidden_units\"],),\n",
        "        activation=\"relu\",\n",
        "        solver=\"adam\",\n",
        "        alpha=0.0,\n",
        "        batch_size=CFG[\"train\"][\"batch_size\"],\n",
        "        learning_rate_init=1e-3,\n",
        "        max_iter=CFG[\"train\"][\"max_epochs\"],\n",
        "        early_stopping=True,\n",
        "        n_iter_no_change=CFG[\"train\"][\"early_stopping_patience\"],\n",
        "        validation_fraction=0.1,\n",
        "        random_state=CFG[\"train\"][\"random_state\"],\n",
        "    )\n",
        "    mlp_mc.fit(X_train_mc_s, y_train_mc)\n",
        "    y_pred_mc = mlp_mc.predict(X_test_mc_s)\n",
        "\n",
        "    report = classification_report(y_test_mc, y_pred_mc, output_dict=True)\n",
        "    save_json(report, os.path.join(outdir, \"NF_in_domain_multiclass_report.json\"))\n",
        "\n",
        "    return feats, bin_col, mc_col"
      ],
      "metadata": {
        "id": "ne_cU1KG0AsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# CIC_IoMT_2024 WiFi-MQTT in-domain (full + tiny-slice)\n",
        "# =======================================================\n",
        "def run_in_domain_cic(\n",
        "    df_tr: pd.DataFrame,\n",
        "    df_te: pd.DataFrame,\n",
        "    outdir: str,\n",
        "    calib_method: str = \"temperature\",\n",
        "    tiny_slice_cfg: dict | None = None,\n",
        "):\n",
        "    print(\"[CIC] In-domain WiFi-MQTT (train→test) ...\")\n",
        "    bin_col = CFG[\"columns\"][\"cic_label_binary\"]\n",
        "    mc_col = CFG[\"columns\"][\"cic_label_mc\"]\n",
        "\n",
        "    drop_cols = [bin_col, mc_col]\n",
        "    feats_tr = build_feature_list(df_tr, drop_cols)\n",
        "    feats_te = build_feature_list(df_te, drop_cols)\n",
        "\n",
        "    # Align columns between train and test\n",
        "    feats = [f for f in feats_tr if f in feats_te]\n",
        "    X_train = df_tr[feats].values\n",
        "    X_test = df_te[feats].values\n",
        "\n",
        "    y_train = build_binary_labels(df_tr, bin_col, None)\n",
        "    y_test = build_binary_labels(df_te, bin_col, None)\n",
        "\n",
        "    pipe, mlp = fit_lr_then_mlp(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        X_test,\n",
        "        y_test,\n",
        "        use_smote=False, # Set to False for CIC as it only has attack labels\n",
        "        seed=CFG[\"train\"][\"random_state\"],\n",
        "        max_epochs=CFG[\"train\"][\"max_epochs\"],\n",
        "        batch_size=CFG[\"train\"][\"batch_size\"],\n",
        "        hidden_units=CFG[\"train\"][\"mlp_hidden_units\"],\n",
        "    )\n",
        "\n",
        "    z_test = pipe.transform(X_test)\n",
        "    p_test_uncal = mlp.predict_proba(z_test)[:, 1]\n",
        "\n",
        "    # Calibration split from training (10% by default)\n",
        "    n = len(X_train)\n",
        "    idx = np.arange(n)\n",
        "    rng = np.random.default_rng(CFG[\"train\"][\"random_state\"])\n",
        "    rng.shuffle(idx)\n",
        "    split = int((1.0 - CFG[\"calibration\"][\"calib_frac\"]) * n)\n",
        "    train_idx, calib_idx = idx[:split], idx[split:]\n",
        "\n",
        "    X_cal = X_train[calib_idx]\n",
        "    y_cal = y_train[calib_idx]\n",
        "\n",
        "    z_cal = pipe.transform(X_cal)\n",
        "    p_cal = mlp.predict_proba(z_cal)[:, 1]\n",
        "\n",
        "    if calib_method == \"temperature\":\n",
        "        # Temperature scaling on logits\n",
        "        logits_cal = np.log(np.clip(p_cal, 1e-8, 1 - 1e-8)) - np.log(1 - np.clip(p_cal, 1e-8, 1 - 1e-8))\n",
        "\n",
        "        def _nll_temp(temp):\n",
        "            temp = float(temp)\n",
        "            zt = logits_cal / temp\n",
        "            pt = 1.0 / (1.0 + np.exp(-zt))\n",
        "            return log_loss(y_cal, pt, labels=[0, 1])\n",
        "\n",
        "        best_temp = 1.0\n",
        "        best_nll = _nll_temp(1.0)\n",
        "        for t in [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]:\n",
        "            nll_t = _nll_temp(t)\n",
        "            if nll_t < best_nll:\n",
        "                best_nll = nll_t\n",
        "                best_temp = t\n",
        "\n",
        "        logits_test = np.log(np.clip(p_test_uncal, 1e-8, 1 - 1e-8)) - np.log(\n",
        "            1 - np.clip(p_test_uncal, 1e-8, 1 - 1e-8)\n",
        "        )\n",
        "        zt = logits_test / best_temp\n",
        "        p_test = 1.0 / (1.0 + np.exp(-zt))\n",
        "        calib_info = {\"method\": \"temperature\", \"T\": best_temp, \"NLL_cal\": best_nll}\n",
        "    else:\n",
        "        # Isotonic regression on probabilities\n",
        "        from sklearn.isotonic import IsotonicRegression\n",
        "\n",
        "        ir = IsotonicRegression(out_of_bounds=\"clip\")\n",
        "        ir.fit(p_cal, y_cal)\n",
        "        p_test = ir.transform(p_test_uncal)\n",
        "        calib_info = {\"method\": \"isotonic\"}\n",
        "\n",
        "    auroc = roc_auc_score(y_test, p_test)\n",
        "    aupr = average_precision_score(y_test, p_test)\n",
        "    fpr95, thr95 = fpr_at_dr(y_test, p_test, target_dr=0.95)\n",
        "    nll = log_loss(y_test, p_test, labels=[0, 1])\n",
        "    brier = brier_score_loss(y_test, p_test)\n",
        "\n",
        "    print(f\"[CIC] AUROC={auroc:.4f} AUPR={aupr:.4f} FPR@95%DR={fpr95:.4f} thr={thr95:.4f}\")\n",
        "    print(f\"[CIC] NLL={nll:.4f} Brier={brier:.4f}\")\n",
        "\n",
        "    metrics = {\n",
        "        \"AUROC\": auroc,\n",
        "        \"AUPR\": aupr,\n",
        "        \"FPR@95%DR\": fpr95,\n",
        "        \"thr95\": thr95,\n",
        "        \"NLL\": nll,\n",
        "        \"Brier\": brier,\n",
        "        \"calibration\": calib_info,\n",
        "    }\n",
        "    save_json(metrics, os.path.join(outdir, \"CIC_IoMT_train_to_test__binary_metrics.json\"))\n",
        "\n",
        "    # Tiny-slice benign experiment\n",
        "    if tiny_slice_cfg and tiny_slice_cfg.get(\"enabled\", True):\n",
        "        print(\"[CIC] Tiny-slice benign calibration experiment ...\")\n",
        "        frac = tiny_slice_cfg.get(\"benign_frac\", 0.015)\n",
        "        seed = tiny_slice_cfg.get(\"seed\", 42)\n",
        "\n",
        "        # Use y_test to correctly identify benign samples (mapped to 0)\n",
        "        # as df_te contains raw string labels.\n",
        "        df_te_benign = df_te[y_test == 0].copy()\n",
        "        n_benign = len(df_te_benign)\n",
        "        n_slice = max(1, int(frac * n_benign))\n",
        "\n",
        "        rng = np.random.default_rng(seed)\n",
        "        idx_slice = rng.choice(df_te_benign.index.values, size=n_slice, replace=False)\n",
        "        df_slice = df_te.loc[idx_slice].copy()\n",
        "\n",
        "        # Remaining test set excludes slice\n",
        "        df_rest = df_te.drop(idx_slice).copy()\n",
        "\n",
        "        feats_slice = [f for f in feats if f in df_slice.columns]\n",
        "        feats_rest = [f for f in feats if f in df_rest.columns]\n",
        "\n",
        "        X_slice = df_slice[feats_slice].values\n",
        "        y_slice = build_binary_labels(df_slice, bin_col, None)\n",
        "\n",
        "        X_rest = df_rest[feats_rest].values\n",
        "        y_rest = build_binary_labels(df_rest, bin_col, None)\n",
        "\n",
        "        # Combine benign slice with original training data (which is all attacks)\n",
        "        X_train_tiny = np.vstack([X_train, X_slice])\n",
        "        y_train_tiny = np.concatenate([y_train, y_slice])\n",
        "\n",
        "        pipe_tiny, mlp_tiny = fit_lr_then_mlp(\n",
        "            X_train_tiny,\n",
        "            y_train_tiny,\n",
        "            X_rest,\n",
        "            y_rest,\n",
        "            use_smote=False,\n",
        "            seed=seed,\n",
        "            max_epochs=CFG[\"train\"][\"max_epochs\"],\n",
        "            batch_size=CFG[\"train\"][\"batch_size\"],\n",
        "            hidden_units=CFG[\"train\"][\"mlp_hidden_units\"],\n",
        "        )\n",
        "\n",
        "        z_rest = pipe_tiny.transform(X_rest)\n",
        "        p_rest_uncal = mlp_tiny.predict_proba(z_rest)[:, 1]\n",
        "\n",
        "        # Temperature scaling on slice\n",
        "        logits_slice = np.log(np.clip(p_rest_uncal, 1e-8, 1 - 1e-8)) - np.log(\n",
        "            1 - np.clip(p_rest_uncal, 1e-8, 1 - 1e-8)\n",
        "        )\n",
        "\n",
        "        def _nll_temp_slice(temp):\n",
        "            temp = float(temp)\n",
        "            zt = logits_slice / temp\n",
        "            pt = 1.0 / (1.0 + np.exp(-zt))\n",
        "            return log_loss(y_rest, pt, labels=[0, 1])\n",
        "\n",
        "        best_temp_slice = 1.0\n",
        "        best_nll_slice = _nll_temp_slice(1.0)\n",
        "        for t in [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]:\n",
        "            nll_t = _nll_temp_slice(t)\n",
        "            if nll_t < best_nll_slice:\n",
        "                best_nll_slice = nll_t\n",
        "                best_temp_slice = t\n",
        "\n",
        "        logits_rest = logits_slice\n",
        "        zt_rest = logits_rest / best_temp_slice\n",
        "        p_rest = 1.0 / (1.0 + np.exp(-zt_rest))\n",
        "\n",
        "        auroc_rest = roc_auc_score(y_rest, p_rest)\n",
        "        aupr_rest = average_precision_score(y_rest, p_rest)\n",
        "        fpr95_rest, thr95_rest = fpr_at_dr(y_rest, p_rest, target_dr=0.95)\n",
        "\n",
        "        metrics_tiny = {\n",
        "            \"AUROC\": auroc_rest,\n",
        "            \"AUPR\": aupr_rest,\n",
        "            \"FPR@95%DR\": fpr95_rest,\n",
        "            \"thr95\": thr95_rest,\n",
        "            \"slice_frac\": frac,\n",
        "            \"slice_seed\": seed,\n",
        "        }\n",
        "        save_json(metrics_tiny, os.path.join(outdir, \"CIC_IoMT_tiny_benign_slice__binary_metrics.json\"))\n",
        "\n",
        "    return feats, bin_col, mc_col"
      ],
      "metadata": {
        "id": "xxJIjyAj0Aki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# Cross-domain with feature automap\n",
        "# =====================================\n",
        "def build_feature_automap(src_feats, tgt_feats, automap_min=5):\n",
        "    common = sorted(set(src_feats).intersection(set(tgt_feats)))\n",
        "    if len(common) < automap_min:\n",
        "        print(f\"[WARN] Only {len(common)} common features (< {automap_min}); cross-domain may be unstable.\")\n",
        "    return common\n",
        "\n",
        "\n",
        "def run_cross_domain(\n",
        "    nf_df,\n",
        "    nf_feats,\n",
        "    nf_bin_col,\n",
        "    nf_mc_col,\n",
        "    cic_tr_df,\n",
        "    cic_tr_feats,\n",
        "    cic_tr_bin_col,\n",
        "    cic_tr_mc_col,\n",
        "    cic_te_df,\n",
        "    cic_te_feats,\n",
        "    cic_te_bin_col,\n",
        "    cic_te_mc_col,\n",
        "    outdir: str,\n",
        "    automap_min: int = 5,\n",
        "):\n",
        "    print(\"[XFER] Cross-domain evaluation NF↔CIC using feature automap ...\")\n",
        "    # NF -> CIC\n",
        "    feats_nf_to_cic = build_feature_automap(nf_feats, cic_te_feats, automap_min=automap_min)\n",
        "\n",
        "    if len(feats_nf_to_cic) > 0:\n",
        "        X_nf = nf_df[feats_nf_to_cic].values\n",
        "        y_nf = build_binary_labels(nf_df, nf_bin_col, None)\n",
        "\n",
        "        X_cic_te = cic_te_df[feats_nf_to_cic].values\n",
        "        y_cic_te = build_binary_labels(cic_te_df, cic_te_bin_col, None)\n",
        "\n",
        "        pipe_nf, mlp_nf = fit_lr_then_mlp(\n",
        "            X_nf,\n",
        "            y_nf,\n",
        "            X_cic_te,\n",
        "            y_cic_te,\n",
        "            use_smote=CFG[\"train\"][\"use_smote\"],\n",
        "            seed=CFG[\"train\"][\"random_state\"],\n",
        "            max_epochs=CFG[\"train\"][\"max_epochs\"],\n",
        "            batch_size=CFG[\"train\"][\"batch_size\"],\n",
        "            hidden_units=CFG[\"train\"][\"mlp_hidden_units\"],\n",
        "        )\n",
        "\n",
        "        z_cic_te = pipe_nf.transform(X_cic_te)\n",
        "        p_cic_te = mlp_nf.predict_proba(z_cic_te)[:, 1]\n",
        "\n",
        "        auroc_xfer = roc_auc_score(y_cic_te, p_cic_te)\n",
        "        aupr_xfer = average_precision_score(y_cic_te, p_cic_te)\n",
        "        fpr95_xfer, thr95_xfer = fpr_at_dr(y_cic_te, p_cic_te, target_dr=0.95)\n",
        "\n",
        "        metrics_nf_to_cic = {\n",
        "            \"AUROC\": auroc_xfer,\n",
        "            \"AUPR\": aupr_xfer,\n",
        "            \"FPR@95%DR\": fpr95_xfer,\n",
        "            \"thr95\": thr95_xfer,\n",
        "            \"n_common_feats\": len(feats_nf_to_cic),\n",
        "        }\n",
        "        save_json(metrics_nf_to_cic, os.path.join(outdir, \"NF_ToN_IoT__to__CIC_IoMT__binary_xfer__metrics.json\"))\n",
        "    else:\n",
        "        print(\"[WARN] Skipping NF -> CIC evaluation (0 common features).\")\n",
        "\n",
        "    # CIC -> NF\n",
        "    feats_cic_to_nf = build_feature_automap(cic_tr_feats, nf_feats, automap_min=automap_min)\n",
        "\n",
        "    if len(feats_cic_to_nf) > 0:\n",
        "        X_cic_tr = cic_tr_df[feats_cic_to_nf].values\n",
        "        y_cic_tr = build_binary_labels(cic_tr_df, cic_tr_bin_col, None)\n",
        "\n",
        "        X_nf_te = nf_df[feats_cic_to_nf].values\n",
        "        y_nf_te = build_binary_labels(nf_df, nf_bin_col, None)\n",
        "\n",
        "        pipe_cic, mlp_cic = fit_lr_then_mlp(\n",
        "            X_cic_tr,\n",
        "            y_cic_tr,\n",
        "            X_nf_te,\n",
        "            y_nf_te,\n",
        "            use_smote=False, # CIC has only attacks, so SMOTE would fail\n",
        "            seed=CFG[\"train\"][\"random_state\"],\n",
        "            max_epochs=CFG[\"train\"][\"max_epochs\"],\n",
        "            batch_size=CFG[\"train\"][\"batch_size\"],\n",
        "            hidden_units=CFG[\"train\"][\"mlp_hidden_units\"],\n",
        "        )\n",
        "\n",
        "        z_nf_te = pipe_cic.transform(X_nf_te)\n",
        "        p_nf_te = mlp_cic.predict_proba(z_nf_te)[:, 1]\n",
        "\n",
        "        auroc_xfer2 = roc_auc_score(y_nf_te, p_nf_te)\n",
        "        aupr_xfer2 = average_precision_score(y_nf_te, p_nf_te)\n",
        "        fpr95_xfer2, thr95_xfer2 = fpr_at_dr(y_nf_te, p_nf_te, target_dr=0.95)\n",
        "\n",
        "        metrics_cic_to_nf = {\n",
        "            \"AUROC\": auroc_xfer2,\n",
        "            \"AUPR\": aupr_xfer2,\n",
        "            \"FPR@95%DR\": fpr95_xfer2,\n",
        "            \"thr95\": thr95_xfer2,\n",
        "            \"n_common_feats\": len(feats_cic_to_nf),\n",
        "        }\n",
        "        save_json(metrics_cic_to_nf, os.path.join(outdir, \"CIC_IoMT__to__NF_ToN_IoT__binary_xfer__metrics.json\"))\n",
        "    else:\n",
        "        print(\"[WARN] Skipping CIC -> NF evaluation (0 common features).\")"
      ],
      "metadata": {
        "id": "dMUKGvNU0LGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================================================\n",
        "# ========= CLEAN ABLATION: LR / MLP / RF / XGB / LR→MLP (Temp / Isotonic) =========\n",
        "# ==================================================================================\n",
        "\n",
        "SEEDS_FOR_ABLATION = [0, 1, 2, 3, 4]\n",
        "\n",
        "\n",
        "def _train_lr(Xtr, ytr, seed):\n",
        "    \"\"\"Plain logistic-regression baseline.\"\"\"\n",
        "    if len(np.unique(ytr)) < 2:\n",
        "        synthetic_x = Xtr.mean(axis=0).reshape(1, -1)\n",
        "        synthetic_y = np.array([0])\n",
        "        Xtr = np.vstack([Xtr, synthetic_x])\n",
        "        ytr = np.append(ytr, synthetic_y)\n",
        "\n",
        "    clf = LogisticRegression(\n",
        "        penalty=\"l2\",\n",
        "        C=1.0,\n",
        "        solver=\"lbfgs\",\n",
        "        max_iter=1000,\n",
        "        class_weight=\"balanced\",\n",
        "        n_jobs=-1,\n",
        "        random_state=seed,\n",
        "    )\n",
        "    return clf.fit(Xtr, ytr)\n",
        "\n",
        "\n",
        "def _train_mlp(Xtr, ytr, seed, hidden=64, dropout=0.2):\n",
        "    \"\"\"Plain MLP baseline (same head as hybrid, but without LR front-end).\"\"\"\n",
        "    synthetic_sample_added = False\n",
        "    if len(np.unique(ytr)) < 2:\n",
        "        synthetic_x = Xtr.mean(axis=0).reshape(1, -1)\n",
        "        synthetic_y = np.array([0])\n",
        "        Xtr = np.vstack([Xtr, synthetic_x])\n",
        "        ytr = np.append(ytr, synthetic_y)\n",
        "        synthetic_sample_added = True\n",
        "\n",
        "    mlp = MLPClassifier(\n",
        "        hidden_layer_sizes=(hidden,),\n",
        "        activation=\"relu\",\n",
        "        solver=\"adam\",\n",
        "        alpha=0.0,\n",
        "        batch_size=2048,\n",
        "        learning_rate_init=1e-3,\n",
        "        max_iter=50,\n",
        "        early_stopping=not synthetic_sample_added,\n",
        "        n_iter_no_change=5,\n",
        "        validation_fraction=0.1 if not synthetic_sample_added else 0.0,\n",
        "        random_state=seed,\n",
        "    )\n",
        "    return mlp.fit(Xtr, ytr)\n",
        "\n",
        "\n",
        "def _train_rf(Xtr, ytr, seed):\n",
        "    \"\"\"Random Forest baseline for tabular IDS flows.\"\"\"\n",
        "    if len(np.unique(ytr)) < 2:\n",
        "        synthetic_x = Xtr.mean(axis=0).reshape(1, -1)\n",
        "        synthetic_y = np.array([0])\n",
        "        Xtr = np.vstack([Xtr, synthetic_x])\n",
        "        ytr = np.append(ytr, synthetic_y)\n",
        "\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=200,\n",
        "        max_depth=None,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        n_jobs=-1,\n",
        "        class_weight=\"balanced_subsample\",\n",
        "        random_state=seed,\n",
        "    )\n",
        "    return rf.fit(Xtr, ytr)\n",
        "\n",
        "\n",
        "def _train_xgb(Xtr, ytr, seed):\n",
        "    \"\"\"XGBoost baseline; returns None if xgboost is not installed.\"\"\"\n",
        "    if \"HAVE_XGB\" not in globals() or not HAVE_XGB:\n",
        "        return None\n",
        "\n",
        "    if len(np.unique(ytr)) < 2:\n",
        "        synthetic_x = Xtr.mean(axis=0).reshape(1, -1)\n",
        "        synthetic_y = np.array([0])\n",
        "        Xtr = np.vstack([Xtr, synthetic_x])\n",
        "        ytr = np.append(ytr, synthetic_y)\n",
        "\n",
        "    xgb = XGBClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=\"logloss\",\n",
        "        tree_method=\"hist\",\n",
        "        n_jobs=-1,\n",
        "        random_state=seed,\n",
        "    )\n",
        "    return xgb.fit(Xtr, ytr)\n",
        "\n",
        "\n",
        "def _hybrid_lr_then_mlp_preds(Xtr, ytr, Xte, seed, use_isotonic=True):\n",
        "    \"\"\"Fit LR→MLP hybrid and return (uncalibrated, temp, isotonic) prob arrays.\"\"\"\n",
        "    pipe, mlp = fit_lr_then_mlp(\n",
        "        Xtr,\n",
        "        ytr,\n",
        "        Xte,\n",
        "        np.zeros(len(Xte)),\n",
        "        CFG[\"train\"][\"use_smote\"],\n",
        "        seed,\n",
        "        CFG[\"train\"][\"max_epochs\"],\n",
        "        CFG[\"train\"][\"batch_size\"],\n",
        "        CFG[\"train\"][\"mlp_hidden_units\"],\n",
        "    )\n",
        "    if pipe is None or mlp is None:\n",
        "        return None, None, None\n",
        "\n",
        "    # Uncalibrated LR→MLP probabilities\n",
        "    z_te = pipe.transform(Xte)\n",
        "    p_uncal = mlp.predict_proba(z_te)[:, 1]\n",
        "\n",
        "    # Calibration split from training data (simple 90/10 split)\n",
        "    n = len(Xtr)\n",
        "    idx = np.arange(n)\n",
        "    rng = np.random.default_rng(seed)\n",
        "    rng.shuffle(idx)\n",
        "    split = int(0.9 * n)\n",
        "    train_idx, calib_idx = idx[:split], idx[split:]\n",
        "\n",
        "    X_cal = Xtr[calib_idx]\n",
        "    y_cal = ytr[calib_idx]\n",
        "\n",
        "    z_cal = pipe.transform(X_cal)\n",
        "    p_cal = mlp.predict_proba(z_cal)[:, 1]\n",
        "\n",
        "    # Temperature scaling on logits\n",
        "    logits_cal = np.log(np.clip(p_cal, 1e-8, 1 - 1e-8)) - np.log(1 - np.clip(p_cal, 1e-8, 1 - 1e-8))\n",
        "\n",
        "    def _nll_temp(temp):\n",
        "        temp = float(temp)\n",
        "        zt = logits_cal / temp\n",
        "        pt = 1.0 / (1.0 + np.exp(-zt))\n",
        "        return log_loss(y_cal, pt, labels=[0, 1])\n",
        "\n",
        "    best_temp = 1.0\n",
        "    best_nll = _nll_temp(1.0)\n",
        "    for t in [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]:\n",
        "        nll_t = _nll_temp(t)\n",
        "        if nll_t < best_nll:\n",
        "            best_nll = nll_t\n",
        "            best_temp = t\n",
        "\n",
        "    logits_uncal = np.log(np.clip(p_uncal, 1e-8, 1 - 1e-8)) - np.log(1 - np.clip(p_uncal, 1e-8, 1 - 1e-8))\n",
        "    z_temp = logits_uncal / best_temp\n",
        "    p_temp = 1.0 / (1.0 + np.exp(-z_temp))\n",
        "\n",
        "    # Optional isotonic regression on top of uncalibrated probabilities\n",
        "    if use_isotonic:\n",
        "        from sklearn.isotonic import IsotonicRegression\n",
        "\n",
        "        ir = IsotonicRegression(out_of_bounds=\"clip\")\n",
        "        ir.fit(p_cal, y_cal)\n",
        "        p_iso = ir.transform(p_uncal)\n",
        "    else:\n",
        "        p_iso = None\n",
        "\n",
        "    return p_uncal, p_temp, p_iso\n",
        "\n",
        "\n",
        "def _metrics_binary(y_true, prob_pos, target_dr=0.95):\n",
        "    \"\"\"Compute AUROC, AUPR, FPR@DR, and ECE/NLL for a binary problem.\"\"\"\n",
        "    auroc = roc_auc_score(y_true, prob_pos)\n",
        "    aupr = average_precision_score(y_true, prob_pos)\n",
        "    fpr95, _ = fpr_at_dr(y_true, prob_pos, target_dr=target_dr)\n",
        "    # For ECE we use two-column probabilities [P(y=0), P(y=1)]\n",
        "    prob_two = np.column_stack([1.0 - prob_pos, prob_pos])\n",
        "    ece = expected_calibration_error(y_true, prob_two, n_bins=15)\n",
        "    nll = log_loss(y_true, prob_pos, labels=[0, 1])\n",
        "    return dict(AUROC=auroc, AUPR=aupr, FPR95=fpr95, ECE=ece, NLL=nll)\n",
        "\n",
        "\n",
        "def _eval_variant_set(dataset_name, Xtr, ytr, Xte, yte):\n",
        "    \"\"\"Evaluate LR / MLP / RF / XGB / LR→MLP variants for a given dataset.\"\"\"\n",
        "    rows = []\n",
        "    for seed in SEEDS_FOR_ABLATION:\n",
        "        # Standardize once per seed\n",
        "        scaler = StandardScaler()\n",
        "        Xtrs = scaler.fit_transform(Xtr)\n",
        "        Xtes = scaler.transform(Xte)\n",
        "\n",
        "        # LR baseline\n",
        "        lr = _train_lr(Xtrs, ytr, seed)\n",
        "        plr = lr.predict_proba(Xtes)[:, 1]\n",
        "        rows.append(dict(Dataset=dataset_name, Model=\"LR\", Seed=seed, **_metrics_binary(yte, plr)))\n",
        "\n",
        "        # MLP baseline\n",
        "        mlp = _train_mlp(Xtrs, ytr, seed)\n",
        "        pmlp = mlp.predict_proba(Xtes)[:, 1]\n",
        "        rows.append(dict(Dataset=dataset_name, Model=\"MLP\", Seed=seed, **_metrics_binary(yte, pmlp)))\n",
        "\n",
        "        # RF baseline\n",
        "        rf = _train_rf(Xtrs, ytr, seed)\n",
        "        prf = rf.predict_proba(Xtes)[:, 1]\n",
        "        rows.append(dict(Dataset=dataset_name, Model=\"RF\", Seed=seed, **_metrics_binary(yte, prf)))\n",
        "\n",
        "        # XGBoost baseline (if available)\n",
        "        xgb = _train_xgb(Xtrs, ytr, seed)\n",
        "        if xgb is not None:\n",
        "            pxgb = xgb.predict_proba(Xtes)[:, 1]\n",
        "            rows.append(dict(Dataset=dataset_name, Model=\"XGBoost\", Seed=seed, **_metrics_binary(yte, pxgb)))\n",
        "\n",
        "        # Hybrid LR→MLP (uncalibrated + calibrated)\n",
        "        p_uncal, p_temp, p_iso = _hybrid_lr_then_mlp_preds(Xtrs, ytr, Xtes, seed, use_isotonic=True)\n",
        "        if p_uncal is None:\n",
        "            continue\n",
        "\n",
        "        rows.append(\n",
        "            dict(Dataset=dataset_name, Model=\"LR→MLP (uncal.)\", Seed=seed, **_metrics_binary(yte, p_uncal))\n",
        "        )\n",
        "        rows.append(\n",
        "            dict(Dataset=dataset_name, Model=\"LR→MLP (Temp)\", Seed=seed, **_metrics_binary(yte, p_temp))\n",
        "        )\n",
        "        if p_iso is not None:\n",
        "            rows.append(\n",
        "                dict(Dataset=dataset_name, Model=\"LR→MLP (Isot.)\", Seed=seed, **_metrics_binary(yte, p_iso))\n",
        "            )\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "def build_clean_ablation_tables(\n",
        "    nf_df,\n",
        "    nf_feats,\n",
        "    nf_bin_col,\n",
        "    cic_tr_df,\n",
        "    cic_tr_feats,\n",
        "    cic_te_df,\n",
        "    cic_te_feats,\n",
        "    outdir,\n",
        "):\n",
        "    \"\"\"Run clean-condition ablation and write CSV + LaTeX table.\"\"\"\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "    # NF-ToN-IoT (train→test = full df for now)\n",
        "    Xtr_nf = nf_df[nf_feats].values\n",
        "    ytr_nf = build_binary_labels(nf_df, nf_bin_col, None)\n",
        "    Xte_nf = Xtr_nf\n",
        "    yte_nf = ytr_nf\n",
        "    df_nf = _eval_variant_set(\"NF-ToN-IoT\", Xtr_nf, ytr_nf, Xte_nf, yte_nf)\n",
        "\n",
        "    # CIC_IoMT_2024 WiFi-MQTT (train→test)\n",
        "    bin_col = CFG[\"columns\"][\"cic_label_binary\"]\n",
        "    Xtr_cic = cic_tr_df[cic_tr_feats].values\n",
        "    ytr_cic = build_binary_labels(cic_tr_df, bin_col, None)\n",
        "    Xte_cic = cic_te_df[cic_te_feats].values\n",
        "    yte_cic = build_binary_labels(cic_te_df, bin_col, None)\n",
        "    df_cic = _eval_variant_set(\"CIC_IoMT_2024_WiFi_MQTT\", Xtr_cic, ytr_cic, Xte_cic, yte_cic)\n",
        "\n",
        "    df_all = pd.concat([df_nf, df_cic], ignore_index=True)\n",
        "    csv_path = os.path.join(outdir, \"clean_ablation_seedavg.csv\")\n",
        "    df_all.to_csv(csv_path, index=False)\n",
        "    print(f\"[OK] Wrote clean ablation CSV → {csv_path}\")\n",
        "\n",
        "    # Seed averages for LaTeX\n",
        "    agg = (\n",
        "        df_all.groupby([\"Dataset\", \"Model\"])\n",
        "        .agg(\n",
        "            AUROC_mean=(\"AUROC\", \"mean\"),\n",
        "            AUPR_mean=(\"AUPR\", \"mean\"),\n",
        "            FPR95_mean=(\"FPR95\", \"mean\"),\n",
        "            ECE_mean=(\"ECE\", \"mean\"),\n",
        "        )\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    # Order rows for presentation\n",
        "    order = [\n",
        "        \"LR\",\n",
        "        \"MLP\",\n",
        "        \"RF\",\n",
        "        \"XGBoost\",\n",
        "        \"LR→MLP (uncal.)\",\n",
        "        \"LR→MLP (Temp)\",\n",
        "        \"LR→MLP (Isot.)\",\n",
        "    ]\n",
        "    agg[\"Model_order\"] = agg[\"Model\"].apply(lambda m: order.index(m) if m in order else len(order))\n",
        "    agg = agg.sort_values([\"Dataset\", \"Model_order\"]).drop(columns=[\"Model_order\"])\n",
        "\n",
        "    tex_lines = []\n",
        "    tex_lines.append(\"\\\\begin{table}[!t]\")\n",
        "    tex_lines.append(\"\\\\centering\")\n",
        "    tex_lines.append(\n",
        "        \"\\\\caption{Seed-averaged clean-condition performance ablation of classical baselines (LR, MLP, RF, XGBoost) \"\n",
        "        \"and the hybrid LR$\\\\\\rightarrow$MLP with/without calibration on CIC\\\\_IoMT\\\\_2024\\\\_WiFi\\\\_MQTT \"\n",
        "        \"(train$\\\\\\rightarrow$test) and NF-ToN-IoT.}\"\n",
        "    )\n",
        "    tex_lines.append(\"\\\\label{tab:ablation-clean}\")\n",
        "    tex_lines.append(\"\\\\small\")\n",
        "    tex_lines.append(\"\\\\begin{tabular}{l l c c c c}\")\n",
        "    tex_lines.append(\"\\\\toprule\")\n",
        "    tex_lines.append(\n",
        "        \"Dataset & Model & AUROC $\\\\\\\\uparrow$ & AUPR $\\\\\\\\uparrow$ & FPR@95\\\\%DR $\\\\\\\\downarrow$ & ECE $\\\\\\\\downarrow$\\\\\\\\\\\\\"\n",
        "    )\n",
        "    tex_lines.append(\"\\\\midrule\")\n",
        "\n",
        "    for _, row in agg.iterrows():\n",
        "        dataset = row[\"Dataset\"]\n",
        "        model = row[\"Model\"]\n",
        "        tex_lines.append(\n",
        "            f\"{dataset} & {model} & {row[\"AUROC_mean\"]:.3f} & {row[\"AUPR_mean\"]:.3f} & \"\n",
        "            f\"{row[\"FPR95_mean\"]:.3f} & {row[\"ECE_mean\"]:.3f}\\\\\"\n",
        "        )\n",
        "\n",
        "    tex_lines.append(\"\\\\bottomrule\")\n",
        "    tex_lines.append(\"\\\\end{tabular}\")\n",
        "    tex_lines.append(\"\\\\end{table}\")\n",
        "\n",
        "    tex_path = os.path.join(outdir, \"ablation_clean_seedavg_filled.tex\")\n",
        "    with open(tex_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join(tex_lines))"
      ],
      "metadata": {
        "id": "WYZD2-bg0QGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------\n",
        "# ZIP helper\n",
        "# -----------------\n",
        "def zip_outputs(outdir: str, zip_path: str):\n",
        "    with ZipFile(zip_path, \"w\") as zf:\n",
        "        for root, _, files in os.walk(outdir):\n",
        "            for fn in files:\n",
        "                fpath = os.path.join(root, fn)\n",
        "                arcname = os.path.relpath(fpath, outdir)\n",
        "                zf.write(fpath, arcname)"
      ],
      "metadata": {
        "id": "eM606e_q0bFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------\n",
        "# Main\n",
        "# ----------\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--grid\", action=\"store_true\", help=\"(unused here)\")\n",
        "    parser.add_argument(\"--adv-train-eps\", type=float, default=0.0)\n",
        "    parser.add_argument(\"--adv-train-frac\", type=float, default=0.3)\n",
        "    parser.add_argument(\"--cic-calib\", type=str, choices=[\"temperature\", \"isotonic\"], default=\"temperature\")\n",
        "    parser.add_argument(\"--automap-min\", type=int, default=5, help=\"Minimum shared features for cross-domain metrics\")\n",
        "    parser.add_argument(\n",
        "        \"--no-cic-tiny-slice\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Disable the CIC tiny benign slice experiment (enabled by default).\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--cic-slice-frac\",\n",
        "        type=float,\n",
        "        default=0.015,\n",
        "        help=\"Fraction of CIC_test benign to use for training+calibration (default 1.5%).\",\n",
        "    )\n",
        "    parser.add_argument(\"--cic-slice-seed\", type=int, default=42, help=\"Random seed for benign-slice sampling.\")\n",
        "    parser.add_argument(\"--zip\", action=\"store_true\", help=\"Also compress outputs to a ZIP bundle.\")\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    outdir = ensure_outdir(CFG[\"paths\"][\"outdir\"])\n",
        "\n",
        "    # Load datasets\n",
        "    nf_df = load_nf_ton_iot(CFG[\"paths\"][\"nf\"])\n",
        "    cic_tr_df, cic_te_df = load_cic_iomt_train_test(CFG[\"paths\"][\"cic_train\"], CFG[\"paths\"][\"cic_test\"])\n",
        "\n",
        "    # NF in-domain\n",
        "    nf_feats, nf_bin_col, nf_mc_col = run_in_domain_nf(nf_df, outdir)\n",
        "\n",
        "    # CIC in-domain + tiny-slice\n",
        "    tiny_cfg = {\n",
        "        \"enabled\": not args.no_cic_tiny_slice,\n",
        "        \"benign_frac\": args.cic_slice_frac,\n",
        "        \"seed\": args.cic_slice_seed,\n",
        "    }\n",
        "    cic_feats, cic_bin_col, cic_mc_col = run_in_domain_cic(\n",
        "        cic_tr_df,\n",
        "        cic_te_df,\n",
        "        outdir,\n",
        "        calib_method=args.cic_calib,\n",
        "        tiny_slice_cfg=tiny_cfg,\n",
        "    )\n",
        "\n",
        "    # Cross-domain NF↔CIC with feature automap\n",
        "    run_cross_domain(\n",
        "        nf_df,\n",
        "        nf_feats,\n",
        "        nf_bin_col,\n",
        "        nf_mc_col,\n",
        "        cic_tr_df,\n",
        "        cic_feats,\n",
        "        cic_bin_col,\n",
        "        cic_mc_col,\n",
        "        cic_te_df,\n",
        "        cic_feats,\n",
        "        cic_bin_col,\n",
        "        cic_mc_col,\n",
        "        outdir,\n",
        "        automap_min=args.automap_min,\n",
        "    )\n",
        "\n",
        "    # Clean-condition ablation for classical baselines vs LR→MLP\n",
        "    build_clean_ablation_tables(\n",
        "        nf_df,\n",
        "        nf_feats,\n",
        "        nf_bin_col,\n",
        "        cic_tr_df,\n",
        "        cic_feats,\n",
        "        cic_te_df,\n",
        "        cic_feats,\n",
        "        outdir=os.path.join(CFG[\"paths\"][\"outdir\"], \"paper_exports\"),\n",
        "    )\n",
        "\n",
        "    if args.zip:\n",
        "        zip_path = os.path.join(Path(outdir).parent, \"outputs_bundle.zip\")\n",
        "        zip_outputs(outdir, zip_path)\n",
        "        print(f\"[OK] Wrote ZIP bundle → {zip_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "dXUGprOn0c4F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}