{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPmWBWiUwM9cA8Ehhatzm8J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankeawthong/Project-1-Lita-Chatbot/blob/main/%5B20250208%5D%20%20Implementing%20Adversarial%20Data%20Augmentation%20on%20UNSW-NB15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y foolbox\n",
        "!pip uninstall -y foolbox-native"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA-5B1RtS0fu",
        "outputId": "ea2834d3-870a-4fab-8086-b3261d58f7f1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: foolbox 3.3.3\n",
            "Uninstalling foolbox-3.3.3:\n",
            "  Successfully uninstalled foolbox-3.3.3\n",
            "\u001b[33mWARNING: Skipping foolbox-native as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install foolbox==3.3.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPxPed3KzceO",
        "outputId": "857577a7-3eb7-4660-b031-395b1aaa4121"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting foolbox==3.3.3\n",
            "  Using cached foolbox-3.3.3-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (1.13.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (75.1.0)\n",
            "Requirement already satisfied: eagerpy>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (0.30.0)\n",
            "Requirement already satisfied: GitPython>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (3.1.44)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (2.32.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython>=3.0.7->foolbox==3.3.3) (4.0.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox==3.3.3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox==3.3.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox==3.3.3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox==3.3.3) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox==3.3.3) (5.0.2)\n",
            "Using cached foolbox-3.3.3-py3-none-any.whl (1.7 MB)\n",
            "Installing collected packages: foolbox\n",
            "Successfully installed foolbox-3.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ”¹ Step 1: Data Preprocessing (Save to File)**"
      ],
      "metadata": {
        "id": "dKYXsan3V1T1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "URguY6udjNxp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "#import foolbox as fb  # For CW and PGD attacks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load and preprocess dataset ---\n",
        "dataset = pd.read_csv(\"Dataset_10Classes.csv\").dropna()\n",
        "for column in dataset.columns:\n",
        "    if dataset[column].dtype == 'object':\n",
        "        dataset[column] = LabelEncoder().fit_transform(dataset[column])\n",
        "X = dataset.drop(['Class'], axis=1)\n",
        "y = dataset['Class']"
      ],
      "metadata": {
        "id": "J7kRC7XEja09"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "EG7GUtwzjauP"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SMOTE for class balance\n",
        "smote = SMOTE(random_state=42)\n",
        "X, y = smote.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "YCl2j9cAje2A"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# âœ… Save preprocessed data\n",
        "with open(\"preprocessed_data.pkl\", \"wb\") as f:\n",
        "    pickle.dump((X, y), f)\n",
        "\n",
        "print(\"âœ… Preprocessed data saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctC3W_-TVU1u",
        "outputId": "de29a5ae-4410-4333-8d76-9c00ea2da680"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Preprocessed data saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**âœ… ğŸ“Œ Full Implementation of All Enhanced Models**"
      ],
      "metadata": {
        "id": "2fU5HqBjTJtz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… New Models to Implement\n",
        "1) Hybrid LR-GRU: Replace BiLSTM with GRU for reduced computational complexity.\n",
        "2) Hybrid LR-CNN-LSTM: Integrate CNN before BiLSTM to capture spatial features.\n",
        "3) Hybrid LR-Transformer: Use Transformer layers instead of BiLSTM for state-of-the-art sequential modeling.\n",
        "4) Hybrid LR-MultiHeadAttention-BiLSTM: Add self-attention to BiLSTM for better feature representation.\n",
        "5) Hybrid LR-BiLSTM with Adversarial Training: Train using FGSM & PGD adversarial examples for robustness."
      ],
      "metadata": {
        "id": "z6FA4JeiTfRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ”¹ Step 2: Logistic Regression Feature Extraction**"
      ],
      "metadata": {
        "id": "gIcBPfnNVx33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# âœ… Load preprocessed data\n",
        "with open(\"preprocessed_data.pkl\", \"rb\") as f:\n",
        "    X, y = pickle.load(f)\n",
        "\n",
        "# âœ… Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# âœ… Train Logistic Regression for Feature Extraction\n",
        "lr_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=500, random_state=42)\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# âœ… Extract probabilities for BiLSTM\n",
        "train_lr_features = lr_model.predict_proba(X_train)\n",
        "test_lr_features = lr_model.predict_proba(X_test)\n",
        "train_lr_features = np.expand_dims(train_lr_features, axis=1)\n",
        "test_lr_features = np.expand_dims(test_lr_features, axis=1)\n",
        "\n",
        "# âœ… One-hot encode labels\n",
        "num_classes = len(np.unique(y))\n",
        "y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "# âœ… Save features\n",
        "with open(\"lr_features.pkl\", \"wb\") as f:\n",
        "    pickle.dump((train_lr_features, test_lr_features, y_train_encoded, y_test_encoded), f)\n",
        "\n",
        "print(\"âœ… Logistic Regression features saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKGJv6anTMAk",
        "outputId": "ec44c6c2-f86f-4b53-c882-3ad4a9cafa3c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Logistic Regression features saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ”¹ Step 3: Hybrid LR-BiLSTM Training**"
      ],
      "metadata": {
        "id": "duKJ6_TVVvtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, Dropout, Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import pickle\n",
        "\n",
        "# âœ… Load Logistic Regression features\n",
        "with open(\"lr_features.pkl\", \"rb\") as f:\n",
        "    train_lr_features, test_lr_features, y_train_encoded, y_test_encoded = pickle.load(f)\n",
        "\n",
        "# âœ… Define BiLSTM Model\n",
        "bilstm_model = Sequential([\n",
        "    Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer=l2(0.0001)), input_shape=(1, train_lr_features.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    Bidirectional(LSTM(32, kernel_regularizer=l2(0.0001))),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_train_encoded.shape[1], activation=\"softmax\")\n",
        "])\n",
        "bilstm_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# âœ… Train model\n",
        "bilstm_model.fit(train_lr_features, y_train_encoded, validation_split=0.2, epochs=5, batch_size=64, verbose=1)\n",
        "\n",
        "# âœ… Save trained model\n",
        "bilstm_model.save(\"bilstm_model.h5\")\n",
        "print(\"âœ… BiLSTM Model saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vcyJx_PVBHD",
        "outputId": "9fa971f4-2766-4117-96de-4ac1c5c3011f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9300/9300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - accuracy: 0.9933 - loss: 0.1715 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
            "Epoch 2/5\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
            "Epoch 3/5\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
            "Epoch 4/5\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 8.8369e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… BiLSTM Model saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ”¹ Step 4: Adversarial Training & Evaluation (Modular)**"
      ],
      "metadata": {
        "id": "KL-NT9laV6lh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ”¸ PGD & FGSM Adversarial Training**"
      ],
      "metadata": {
        "id": "YCU5aKllV-jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "# âœ… Load model & features\n",
        "bilstm_model = load_model(\"bilstm_model.h5\")\n",
        "with open(\"lr_features.pkl\", \"rb\") as f:\n",
        "    train_lr_features, test_lr_features, y_train_encoded, y_test_encoded = pickle.load(f)\n",
        "\n",
        "# âœ… Convert model to Foolbox format\n",
        "fmodel = fb.TensorFlowModel(bilstm_model, bounds=(0, 1))\n",
        "\n",
        "# âœ… Generate Adversarial Examples\n",
        "def generate_adversarial_examples(attack, eps):\n",
        "    raw_adversarials, *_ = attack(fmodel, tf.convert_to_tensor(test_lr_features, dtype=tf.float32), np.argmax(y_test_encoded, axis=1), epsilons=eps)\n",
        "    return raw_adversarials.numpy()\n",
        "\n",
        "print(\"\\nğŸ”¹ Generating FGSM Adversarial Examples...\")\n",
        "adv_fgsm = generate_adversarial_examples(fb.attacks.FGSM(), 0.01)\n",
        "\n",
        "print(\"\\nğŸ”¹ Generating PGD Adversarial Examples...\")\n",
        "adv_pgd = generate_adversarial_examples(fb.attacks.LinfPGD(steps=10), 0.02)\n",
        "\n",
        "# âœ… Save adversarial examples\n",
        "with open(\"adversarial_examples.pkl\", \"wb\") as f:\n",
        "    pickle.dump((adv_fgsm, adv_pgd), f)\n",
        "\n",
        "print(\"âœ… Adversarial examples saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKrSN5OSVBDu",
        "outputId": "09ac2d7a-453b-4b1d-9878-a05fea37e4f2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”¹ Generating FGSM Adversarial Examples...\n",
            "\n",
            "ğŸ”¹ Generating PGD Adversarial Examples...\n",
            "âœ… Adversarial examples saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ”¹ Step 5: Evaluate the Model**"
      ],
      "metadata": {
        "id": "dFYXmxlsWDMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# âœ… Load model, adversarial examples, and labels\n",
        "bilstm_model = load_model(\"bilstm_model.h5\")\n",
        "with open(\"adversarial_examples.pkl\", \"rb\") as f:\n",
        "    adv_fgsm, adv_pgd = pickle.load(f)\n",
        "with open(\"lr_features.pkl\", \"rb\") as f:\n",
        "    _, _, _, y_test_encoded = pickle.load(f)\n",
        "\n",
        "bilstm_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "fmodel = fb.TensorFlowModel(bilstm_model, bounds=(0, 1))\n",
        "\n",
        "# âœ… Evaluate Model\n",
        "def evaluate_attack(adv_examples, attack_name):\n",
        "    test_predictions = bilstm_model.predict(adv_examples)\n",
        "    accuracy = accuracy_score(np.argmax(y_test_encoded, axis=1), np.argmax(test_predictions, axis=1))\n",
        "    print(f\"âœ… {attack_name} Attack Accuracy: {accuracy:.8f}\")\n",
        "\n",
        "evaluate_attack(adv_fgsm, \"FGSM\")\n",
        "evaluate_attack(adv_pgd, \"PGD\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wlms32_NVBBD",
        "outputId": "6ac78db9-9a30-47fc-d76e-a9afe65ccbae"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
            "âœ… FGSM Attack Accuracy: 0.99990323\n",
            "\u001b[1m5813/5813\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
            "âœ… PGD Attack Accuracy: 0.99990323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ”§ Implementing Adversarial Data Augmentation**"
      ],
      "metadata": {
        "id": "BjHwluKZnXPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "\n",
        "# âœ… Convert the model to Foolbox format\n",
        "fmodel = fb.TensorFlowModel(bilstm_model, bounds=(0, 1))\n",
        "\n",
        "# âœ… Function to Generate Adversarial Examples\n",
        "def generate_adversarial_examples(attack, X_train, y_train, epsilon):\n",
        "    \"\"\"\n",
        "    Generate adversarial examples using FGSM or PGD with shape correction.\n",
        "    \"\"\"\n",
        "    # âœ… Ensure X_train is (batch_size, 1, features) - keep the timesteps dimension\n",
        "    #    Remove this check since we want to keep the timesteps dimension\n",
        "    # if len(X_train.shape) == 3:  # If (batch_size, 1, features), squeeze it\n",
        "    #     X_train = np.squeeze(X_train, axis=1)\n",
        "\n",
        "    X_train_tf = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "    # âœ… Convert y_train to NumPy array to avoid the ValueError\n",
        "    y_train_indices = np.array(y_train)  # Convert y_train to NumPy array\n",
        "    if y_train_indices.ndim != 1:  # If not 1D (e.g., one-hot encoded), get indices\n",
        "        y_train_indices = np.argmax(y_train_indices, axis=1)\n",
        "\n",
        "    adv_examples, *_ = attack(fmodel, X_train_tf, y_train_indices, epsilons=epsilon)\n",
        "\n",
        "    # âœ… Ensure the output shape matches original input\n",
        "    # Remove expansion since we keep original timesteps\n",
        "    #return np.expand_dims(adv_examples.numpy(), axis=1)  # Expand dimension back\n",
        "    return adv_examples.numpy()  # Return as is\n",
        "\n",
        "\n",
        "# âœ… Generate FGSM and PGD adversarial samples\n",
        "print(\"\\nğŸ”¹ Generating FGSM Adversarial Examples...\")\n",
        "attack_fgsm = fb.attacks.FGSM()\n",
        "adv_fgsm = generate_adversarial_examples(attack_fgsm, train_lr_features, y_train, epsilon=0.01)\n",
        "\n",
        "print(\"\\nğŸ”¹ Generating PGD Adversarial Examples...\")\n",
        "attack_pgd = fb.attacks.LinfPGD(steps=10)\n",
        "adv_pgd = generate_adversarial_examples(attack_pgd, train_lr_features, y_train, epsilon=0.02)\n",
        "\n",
        "# âœ… Combine Clean and Adversarial Data\n",
        "augmented_features = np.vstack([train_lr_features, adv_fgsm, adv_pgd])\n",
        "\n",
        "# âœ… One-hot encode labels to match model's output\n",
        "# Assuming 'num_classes' is defined as 10\n",
        "augmented_labels = np.tile(y_train, 3)\n",
        "augmented_labels = tf.keras.utils.to_categorical(augmented_labels, num_classes=10)\n",
        "\n",
        "# âœ… Shuffle the Augmented Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((augmented_features, augmented_labels))\n",
        "dataset = dataset.shuffle(len(augmented_features)).batch(64)\n",
        "\n",
        "# âœ… Train the Model on Augmented Data\n",
        "bilstm_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\nğŸ”¹ Training on Adversarial Augmented Dataset...\")\n",
        "bilstm_model.fit(dataset, epochs=5, verbose=1)\n",
        "\n",
        "# âœ… Save the Augmented Model\n",
        "bilstm_model.save(\"bilstm_augmented.h5\")\n",
        "\n",
        "print(\"\\nâœ… Model trained with Adversarial Data Augmentation and saved as 'bilstm_augmented.h5'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkHRjyEsnThd",
        "outputId": "2a71673f-6c2c-41e2-a621-70ef82739284"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”¹ Generating FGSM Adversarial Examples...\n",
            "\n",
            "ğŸ”¹ Generating PGD Adversarial Examples...\n",
            "\n",
            "ğŸ”¹ Training on Adversarial Augmented Dataset...\n",
            "Epoch 1/5\n",
            "\u001b[1m34875/34875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0010\n",
            "Epoch 2/5\n",
            "\u001b[1m34875/34875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.2291e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m34875/34875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.8589e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m34875/34875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.3659e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m34875/34875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.1675e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Model trained with Adversarial Data Augmentation and saved as 'bilstm_augmented.h5'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**âœ… Step 2: Evaluate Robustness of Augmented Model**"
      ],
      "metadata": {
        "id": "yyECDYBws9jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Load the Trained Augmented Model\n",
        "bilstm_model = tf.keras.models.load_model(\"bilstm_augmented.h5\")\n",
        "\n",
        "# âœ… Evaluate FGSM Attack\n",
        "print(\"\\nğŸ”¹ Running FGSM Attack on Augmented Model...\")\n",
        "fgsm_adv = generate_adversarial_examples(attack_fgsm, test_lr_features, y_test, epsilon=0.01)\n",
        "fgsm_predictions = bilstm_model.predict(fgsm_adv)\n",
        "# âœ… Corrected: Remove 'axis=1' for y_test as it's likely 1-dimensional\n",
        "fgsm_acc = np.mean(np.argmax(fgsm_predictions, axis=1) == y_test)\n",
        "\n",
        "# âœ… Evaluate PGD Attack\n",
        "print(\"\\nğŸ”¹ Running PGD Attack on Augmented Model...\")\n",
        "pgd_adv = generate_adversarial_examples(attack_pgd, test_lr_features, y_test, epsilon=0.02)\n",
        "pgd_predictions = bilstm_model.predict(pgd_adv)\n",
        "# âœ… Corrected: Remove 'axis=1' for y_test as it's likely 1-dimensional\n",
        "pgd_acc = np.mean(np.argmax(pgd_predictions, axis=1) == y_test)\n",
        "\n",
        "# âœ… Print Updated Results\n",
        "print(f\"\\nâœ… FGSM Attack Accuracy (After Augmentation): {fgsm_acc:.8f}\")\n",
        "print(f\"âœ… PGD Attack Accuracy (After Augmentation): {pgd_acc:.8f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roKCTbTUVA-h",
        "outputId": "b535e64b-b321-4a74-9022-bc44aa2b1015"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”¹ Running FGSM Attack on Augmented Model...\n",
            "\u001b[1m5813/5813\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step\n",
            "\n",
            "ğŸ”¹ Running PGD Attack on Augmented Model...\n",
            "\u001b[1m5813/5813\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step\n",
            "\n",
            "âœ… FGSM Attack Accuracy (After Augmentation): 0.99993011\n",
            "âœ… PGD Attack Accuracy (After Augmentation): 0.99993548\n"
          ]
        }
      ]
    }
  ]
}