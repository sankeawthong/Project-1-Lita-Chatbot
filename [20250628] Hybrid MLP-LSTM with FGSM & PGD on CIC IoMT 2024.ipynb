{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankeawthong/Project-1-Lita-Chatbot/blob/main/%5B20250628%5D%20Hybrid%20MLP-LSTM%20with%20FGSM%20%26%20PGD%20on%20CIC%20IoMT%202024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hybrid MLP-LSTM with FGSM & PGD on CIC IoMT 2024 Dataset**"
      ],
      "metadata": {
        "id": "TQWKv5ZzFyHQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjBtU-KMQIDX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSVs\n",
        "train_df = pd.read_csv('CIC_IoMT_2024_WiFi_MQTT_train.csv')\n",
        "test_df = pd.read_csv('CIC_IoMT_2024_WiFi_MQTT_test.csv')\n",
        "\n",
        "# Combine them\n",
        "full_df = pd.concat([train_df, test_df], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBcB5y7D_nGx"
      },
      "outputs": [],
      "source": [
        "full_df['Label_Binary'] = full_df['label'].apply(lambda x: 0 if 'Benign' in x else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wueqdgL7_wnd"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "full_df['Label_Multiclass'] = le.fit_transform(full_df['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_82bydKLHVF",
        "outputId": "be4a3eb7-d835-4706-d8bf-4a82493b0328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping foolbox as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping foolbox-native as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting foolbox==3.3.3\n",
            "  Downloading foolbox-3.3.3-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (1.15.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (75.2.0)\n",
            "Collecting eagerpy>=0.30.0 (from foolbox==3.3.3)\n",
            "  Downloading eagerpy-0.30.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: GitPython>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (3.1.44)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (4.14.0)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (2.32.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython>=3.0.7->foolbox==3.3.3) (4.0.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox==3.3.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox==3.3.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox==3.3.3) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox==3.3.3) (2025.6.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox==3.3.3) (5.0.2)\n",
            "Downloading foolbox-3.3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eagerpy-0.30.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: eagerpy, foolbox\n",
            "Successfully installed eagerpy-0.30.0 foolbox-3.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y foolbox\n",
        "!pip uninstall -y foolbox-native\n",
        "!pip install foolbox==3.3.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TL_Rm4SNLKi6"
      },
      "outputs": [],
      "source": [
        "# Step 1: Data Preprocessing for CIC IoMT 2024 Dataset\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7aerm4kLKgT",
        "outputId": "4c8cdb63-bfef-4731-c165-18f0b5598bfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”¹ Loading CIC IoMT 2024 WiFi MQTT Dataset...\n"
          ]
        }
      ],
      "source": [
        "# Load and combine the CIC IoMT 2024 datasets\n",
        "print(\"ğŸ”¹ Loading CIC IoMT 2024 WiFi MQTT Dataset...\")\n",
        "train_df = pd.read_csv('CIC_IoMT_2024_WiFi_MQTT_train.csv')\n",
        "test_df = pd.read_csv('CIC_IoMT_2024_WiFi_MQTT_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guVXlW3lLKdR",
        "outputId": "58a3e876-edf4-4c9e-d22a-a8c434917782"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined dataset shape: (8775013, 46)\n"
          ]
        }
      ],
      "source": [
        "# Combine datasets\n",
        "full_df = pd.concat([train_df, test_df], ignore_index=True)\n",
        "print(f\"Combined dataset shape: {full_df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCov9_htLKas",
        "outputId": "966d21c5-3340-428b-f3f9-e54cfab75895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape after removing NaN: (8775013, 46)\n"
          ]
        }
      ],
      "source": [
        "# Handle missing values\n",
        "full_df = full_df.dropna()\n",
        "print(f\"Dataset shape after removing NaN: {full_df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9cBetxcLKYa"
      },
      "outputs": [],
      "source": [
        "# Label encoding for both binary and multiclass\n",
        "# Binary Classification (0: Benign, 1: Attack)\n",
        "full_df['Label_Binary'] = full_df['label'].apply(lambda x: 0 if 'Benign' in x else 1)\n",
        "\n",
        "# Multiclass Classification\n",
        "le = LabelEncoder()\n",
        "full_df['Label_Multiclass'] = le.fit_transform(full_df['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39m2Q-aTLKTu",
        "outputId": "e878d846-fc5f-4cd8-e924-338ea2931d45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Original Class Distribution:\n",
            "label\n",
            "TCP_IP-DDoS-UDP2_train      207295\n",
            "TCP_IP-DDoS-UDP3_train      206604\n",
            "TCP_IP-DDoS-UDP4_train      206343\n",
            "TCP_IP-DDoS-UDP1_train      206170\n",
            "TCP_IP-DDoS-UDP1_test       205654\n",
            "                             ...  \n",
            "MQTT-Malformed_Data_test      1747\n",
            "ARP_Spoofing_test             1744\n",
            "Recon-VulScan_test            1034\n",
            "Recon-Ping_Sweep_train         740\n",
            "Recon-Ping_Sweep_test          186\n",
            "Name: count, Length: 72, dtype: int64\n",
            "\n",
            "Binary Class Distribution:\n",
            "Label_Binary\n",
            "1    8544674\n",
            "0     230339\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Multiclass Class Distribution:\n",
            "Label_Multiclass\n",
            "45    207295\n",
            "46    206604\n",
            "47    206343\n",
            "43    206170\n",
            "42    205654\n",
            "       ...  \n",
            "12      1747\n",
            "0       1744\n",
            "20      1034\n",
            "17       740\n",
            "16       186\n",
            "Name: count, Length: 72, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Display class distributions\n",
        "print(\"\\nOriginal Class Distribution:\")\n",
        "print(full_df['label'].value_counts())\n",
        "print(\"\\nBinary Class Distribution:\")\n",
        "print(full_df['Label_Binary'].value_counts())\n",
        "print(\"\\nMulticlass Class Distribution:\")\n",
        "print(full_df['Label_Multiclass'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CElmKE1XMUZc",
        "outputId": "21b6f64f-e3f4-4fbe-d011-735659b60543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”¹ Using Binary Classification (Normal vs Attack)\n",
            "ğŸ”¹ Processing categorical variables...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-13-3040351682.py:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[column] = le_temp.fit_transform(X[column].astype(str))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature matrix shape: (8775013, 46)\n",
            "Target vector shape: (8775013,)\n",
            "Original target distribution: [ 230339 8544674]\n"
          ]
        }
      ],
      "source": [
        "# Choose classification approach (Binary or Multiclass)\n",
        "# For manuscript revision, start with Binary classification as recommended\n",
        "CLASSIFICATION_TYPE = 'binary'  # Change to 'multiclass' if needed\n",
        "\n",
        "if CLASSIFICATION_TYPE == 'binary':\n",
        "    target_column = 'Label_Binary'\n",
        "    print(\"ğŸ”¹ Using Binary Classification (Normal vs Attack)\")\n",
        "else:\n",
        "    target_column = 'Label_Multiclass'\n",
        "    print(\"ğŸ”¹ Using Multiclass Classification\")\n",
        "\n",
        "# Prepare features and target\n",
        "feature_columns = [col for col in full_df.columns if col not in ['Class', 'Label_Binary', 'Label_Multiclass']]\n",
        "X = full_df[feature_columns]\n",
        "y = full_df[target_column]\n",
        "\n",
        "# Handle categorical variables in features\n",
        "print(\"ğŸ”¹ Processing categorical variables...\")\n",
        "categorical_columns = X.select_dtypes(include=['object']).columns\n",
        "for column in categorical_columns:\n",
        "    le_temp = LabelEncoder()\n",
        "    X[column] = le_temp.fit_transform(X[column].astype(str))\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X = X.values\n",
        "y = y.values\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "print(f\"Target vector shape: {y.shape}\")\n",
        "print(f\"Original target distribution: {np.bincount(y)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYmKUBsYMUVw",
        "outputId": "46c67f83-2838-4509-afb3-c71e2854ea46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”¹ Standardizing features...\n",
            "ğŸ”¹ Performing stratified train-test split...\n",
            "Training set shape: (7020010, 46)\n",
            "Testing set shape: (1755003, 46)\n",
            "Training target distribution: [ 184271 6835739]\n",
            "Testing target distribution: [  46068 1708935]\n"
          ]
        }
      ],
      "source": [
        "# Standardize features\n",
        "print(\"ğŸ”¹ Standardizing features...\")\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Stratified train-test split to ensure both classes in training and testing\n",
        "print(\"ğŸ”¹ Performing stratified train-test split...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Testing set shape: {X_test.shape}\")\n",
        "print(f\"Training target distribution: {np.bincount(y_train)}\")\n",
        "print(f\"Testing target distribution: {np.bincount(y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_52WikHWMUSr",
        "outputId": "260ca448-c410-4fee-d818-eb729f4d7d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”¹ Applying SMOTE for class balance...\n",
            "Balanced training set shape: (13671478, 46)\n",
            "Balanced training target distribution: [6835739 6835739]\n"
          ]
        }
      ],
      "source": [
        "# Apply SMOTE for class balance (only on training data)\n",
        "print(\"ğŸ”¹ Applying SMOTE for class balance...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"Balanced training set shape: {X_train_balanced.shape}\")\n",
        "print(f\"Balanced training target distribution: {np.bincount(y_train_balanced)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-1ZWdiSMT9n",
        "outputId": "b811f711-6ac4-41c7-d80c-0b3c7321b500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Preprocessed CIC IoMT 2024 data saved!\n",
            "\n",
            "ğŸ”¹ Step 2: Logistic Regression Feature Extraction\n"
          ]
        }
      ],
      "source": [
        "# Save preprocessed data\n",
        "preprocessed_data = {\n",
        "    'X_train': X_train_balanced,\n",
        "    'y_train': y_train_balanced,\n",
        "    'X_test': X_test,\n",
        "    'y_test': y_test,\n",
        "    'scaler': scaler,\n",
        "    'label_encoder': le,\n",
        "    'feature_columns': feature_columns\n",
        "}\n",
        "\n",
        "with open(\"preprocessed_data_ciciomt.pkl\", \"wb\") as f:\n",
        "    pickle.dump(preprocessed_data, f)\n",
        "\n",
        "print(\"âœ… Preprocessed CIC IoMT 2024 data saved!\")\n",
        "\n",
        "# Step 2: Logistic Regression Feature Extraction\n",
        "print(\"\\nğŸ”¹ Step 2: Logistic Regression Feature Extraction\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkknCjNZNPij",
        "outputId": "63df318b-b34c-47aa-fba3-1408f7c8cd1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”¹ Training Logistic Regression for feature extraction...\n",
            "LR feature shape: (13671478, 1, 2)\n",
            "Number of classes: 2\n",
            "âœ… Logistic Regression features saved!\n",
            "\n",
            "ğŸ”¹ Step 3: Hybrid LR-BiLSTM Training\n"
          ]
        }
      ],
      "source": [
        "# Load preprocessed data\n",
        "with open(\"preprocessed_data_ciciomt.pkl\", \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "X_train = data['X_train']\n",
        "y_train = data['y_train']\n",
        "X_test = data['X_test']\n",
        "y_test = data['y_test']\n",
        "\n",
        "# Train Logistic Regression for Feature Extraction\n",
        "print(\"ğŸ”¹ Training Logistic Regression for feature extraction...\")\n",
        "if CLASSIFICATION_TYPE == 'binary':\n",
        "    lr_model = LogisticRegression(\n",
        "        random_state=42,\n",
        "        max_iter=1000,\n",
        "        solver='liblinear'  # Better for binary classification\n",
        "    )\n",
        "else:\n",
        "    lr_model = LogisticRegression(\n",
        "        multi_class='multinomial',\n",
        "        solver='lbfgs',\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Extract probabilities for BiLSTM\n",
        "train_lr_features = lr_model.predict_proba(X_train)\n",
        "test_lr_features = lr_model.predict_proba(X_test)\n",
        "\n",
        "# Reshape for LSTM input (add time dimension)\n",
        "train_lr_features = np.expand_dims(train_lr_features, axis=1)\n",
        "test_lr_features = np.expand_dims(test_lr_features, axis=1)\n",
        "\n",
        "# One-hot encode labels for neural network\n",
        "if CLASSIFICATION_TYPE == 'binary':\n",
        "    num_classes = 2\n",
        "else:\n",
        "    num_classes = len(np.unique(np.concatenate([y_train, y_test])))\n",
        "\n",
        "y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "print(f\"LR feature shape: {train_lr_features.shape}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# Save features\n",
        "feature_data = {\n",
        "    'train_lr_features': train_lr_features,\n",
        "    'test_lr_features': test_lr_features,\n",
        "    'y_train_encoded': y_train_encoded,\n",
        "    'y_test_encoded': y_test_encoded,\n",
        "    'lr_model': lr_model,\n",
        "    'num_classes': num_classes\n",
        "}\n",
        "\n",
        "with open(\"lr_features_ciciomt.pkl\", \"wb\") as f:\n",
        "    pickle.dump(feature_data, f)\n",
        "\n",
        "print(\"âœ… Logistic Regression features saved!\")\n",
        "\n",
        "# Step 3: Hybrid LR-BiLSTM Training\n",
        "print(\"\\nğŸ”¹ Step 3: Hybrid LR-BiLSTM Training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "id": "p-hngOYQNqLg",
        "outputId": "7896b6a5-f855-4257-adc9-54eabb4e0df2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape for BiLSTM: (13671478, 1, 2)\n",
            "Output classes: 2\n",
            "ğŸ”¹ Building BiLSTM model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”¹ Model Architecture:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">34,304</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â”‚        \u001b[38;5;34m34,304\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m41,216\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              â”‚           \u001b[38;5;34m130\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">75,650</span> (295.51 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m75,650\u001b[0m (295.51 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">75,650</span> (295.51 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m75,650\u001b[0m (295.51 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”¹ Training BiLSTM model...\n",
            "Epoch 1/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1612s\u001b[0m 9ms/step - accuracy: 0.9979 - loss: 0.0136 - val_accuracy: 0.9993 - val_loss: 0.0056\n",
            "Epoch 2/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1632s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0108 - val_accuracy: 0.9995 - val_loss: 0.0034\n",
            "Epoch 3/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1625s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0106 - val_accuracy: 0.9993 - val_loss: 0.0069\n",
            "Epoch 4/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1632s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0106 - val_accuracy: 0.9993 - val_loss: 0.0045\n",
            "Epoch 5/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1643s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0106 - val_accuracy: 0.9993 - val_loss: 0.0052\n",
            "Epoch 6/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1648s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0105 - val_accuracy: 0.9992 - val_loss: 0.0076\n",
            "Epoch 7/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1726s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0107 - val_accuracy: 0.9993 - val_loss: 0.0059\n",
            "Epoch 8/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1773s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0107 - val_accuracy: 0.9993 - val_loss: 0.0045\n",
            "Epoch 9/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1725s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0107 - val_accuracy: 0.9992 - val_loss: 0.0055\n",
            "Epoch 10/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1737s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0107 - val_accuracy: 0.9994 - val_loss: 0.0044\n",
            "Epoch 11/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1674s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0107 - val_accuracy: 0.9991 - val_loss: 0.0088\n",
            "Epoch 12/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1667s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0106 - val_accuracy: 0.9994 - val_loss: 0.0042\n",
            "Epoch 13/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1653s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0105 - val_accuracy: 0.9995 - val_loss: 0.0045\n",
            "Epoch 14/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1647s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0107 - val_accuracy: 0.9992 - val_loss: 0.0064\n",
            "Epoch 15/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1647s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0106 - val_accuracy: 0.9995 - val_loss: 0.0044\n",
            "Epoch 16/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1705s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0106 - val_accuracy: 0.9994 - val_loss: 0.0041\n",
            "Epoch 17/50\n",
            "\u001b[1m170894/170894\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1883s\u001b[0m 11ms/step - accuracy: 0.9983 - loss: 0.0106 - val_accuracy: 0.9992 - val_loss: 0.0072\n",
            "Epoch 18/50\n",
            "\u001b[1m 16750/170894\u001b[0m \u001b[32mâ”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m25:30\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0106"
          ]
        }
      ],
      "source": [
        "# Load Logistic Regression features\n",
        "with open(\"lr_features_ciciomt.pkl\", \"rb\") as f:\n",
        "    feature_data = pickle.load(f)\n",
        "\n",
        "train_lr_features = feature_data['train_lr_features']\n",
        "test_lr_features = feature_data['test_lr_features']\n",
        "y_train_encoded = feature_data['y_train_encoded']\n",
        "y_test_encoded = feature_data['y_test_encoded']\n",
        "num_classes = feature_data['num_classes']\n",
        "\n",
        "print(f\"Input shape for BiLSTM: {train_lr_features.shape}\")\n",
        "print(f\"Output classes: {num_classes}\")\n",
        "\n",
        "# Define BiLSTM Model\n",
        "print(\"ğŸ”¹ Building BiLSTM model...\")\n",
        "bilstm_model = Sequential([\n",
        "    Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer=l2(0.0001)),\n",
        "                  input_shape=(1, train_lr_features.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    Bidirectional(LSTM(32, kernel_regularizer=l2(0.0001))),\n",
        "    Dropout(0.2),\n",
        "    Dense(num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "bilstm_model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Model summary\n",
        "print(\"ğŸ”¹ Model Architecture:\")\n",
        "bilstm_model.summary()\n",
        "\n",
        "# Train model\n",
        "print(\"ğŸ”¹ Training BiLSTM model...\")\n",
        "history = bilstm_model.fit(\n",
        "    train_lr_features, y_train_encoded,\n",
        "    validation_split=0.2,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"ğŸ”¹ Evaluating on test set...\")\n",
        "test_loss, test_accuracy = bilstm_model.evaluate(test_lr_features, y_test_encoded, verbose=0)\n",
        "print(f\"Test Accuracy: {test_accuracy:.10f}\")\n",
        "print(f\"Test Loss: {test_loss:.10f}\")\n",
        "\n",
        "# Generate predictions for detailed metrics\n",
        "y_pred_proba = bilstm_model.predict(test_lr_features)\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "y_true = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# Calculate detailed metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(f\"\\nğŸ”¹ Detailed Performance Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.10f}\")\n",
        "print(f\"Precision: {precision:.10f}\")\n",
        "print(f\"Recall: {recall:.10f}\")\n",
        "print(f\"F1-Score: {f1:.10f}\")\n",
        "print(f\"Detection Rate: {recall:.10f}\")\n",
        "\n",
        "# Save trained model\n",
        "bilstm_model.save(\"bilstm_model_ciciomt.h5\")\n",
        "print(\"âœ… BiLSTM Model saved!\")\n",
        "\n",
        "# Step 4: Visualization\n",
        "print(\"\\nğŸ”¹ Step 4: Training Visualization\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHWyb10INwKb"
      },
      "outputs": [],
      "source": [
        "# Plot Training & Validation Accuracy\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label=\"Training Accuracy\", color=\"blue\")\n",
        "plt.plot(history.history['val_accuracy'], label=\"Validation Accuracy\", color=\"red\", linestyle=\"dashed\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training & Validation Accuracy Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label=\"Training Loss\", color=\"blue\")\n",
        "plt.plot(history.history['val_loss'], label=\"Validation Loss\", color=\"red\", linestyle=\"dashed\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training & Validation Loss Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nğŸ”¹ Classification Report:\")\n",
        "if CLASSIFICATION_TYPE == 'binary':\n",
        "    target_names = ['Benign', 'Attack']\n",
        "else:\n",
        "    target_names = [f'Class_{i}' for i in range(num_classes)]\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "import seaborn as sns\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=target_names, yticklabels=target_names)\n",
        "plt.title('Confusion Matrix - Clean Test Data')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ… Basic model training and evaluation completed!\")\n",
        "\n",
        "# Step 5: Adversarial Training with FGSM and PGD\n",
        "print(\"\\nğŸ”¹ Step 5: Adversarial Attack Evaluation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9VRPXYJN590"
      },
      "outputs": [],
      "source": [
        "import foolbox as fb\n",
        "\n",
        "# Load the trained model\n",
        "bilstm_model = tf.keras.models.load_model(\"bilstm_model_ciciomt.h5\")\n",
        "\n",
        "# Convert model to Foolbox format\n",
        "fmodel = fb.TensorFlowModel(bilstm_model, bounds=(0, 1))\n",
        "\n",
        "# Define attacks\n",
        "attack_fgsm = fb.attacks.FGSM()\n",
        "attack_pgd = fb.attacks.LinfPGD(steps=20)\n",
        "\n",
        "# Function to generate adversarial examples\n",
        "def generate_adversarial_examples(attack, X_test, y_test, eps=0.02, batch_size=1024):\n",
        "    num_samples = X_test.shape[0]\n",
        "    adv_examples = []\n",
        "\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        batch_X = X_test[i:i + batch_size]\n",
        "        batch_y = np.argmax(y_test[i:i + batch_size], axis=1)\n",
        "        batch_X_tf = tf.convert_to_tensor(batch_X, dtype=tf.float32)\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        adv_batch, *_ = attack(fmodel, batch_X_tf, batch_y, epsilons=eps)\n",
        "        adv_examples.append(adv_batch.numpy())\n",
        "\n",
        "    return np.vstack(adv_examples)\n",
        "\n",
        "# Generate adversarial examples\n",
        "print(\"ğŸ”¹ Generating FGSM Adversarial Examples...\")\n",
        "adv_fgsm_test = generate_adversarial_examples(attack_fgsm, test_lr_features, y_test_encoded, eps=0.01)\n",
        "\n",
        "print(\"ğŸ”¹ Generating PGD Adversarial Examples...\")\n",
        "adv_pgd_test = generate_adversarial_examples(attack_pgd, test_lr_features, y_test_encoded, eps=0.02)\n",
        "\n",
        "# Evaluate attacks\n",
        "def evaluate_attack(adv_examples, attack_name):\n",
        "    adv_predictions = bilstm_model.predict(adv_examples)\n",
        "    adv_predictions_labels = np.argmax(adv_predictions, axis=1)\n",
        "    true_labels = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, adv_predictions_labels)\n",
        "    precision = precision_score(true_labels, adv_predictions_labels, average='weighted')\n",
        "    recall = recall_score(true_labels, adv_predictions_labels, average='weighted')\n",
        "    f1 = f1_score(true_labels, adv_predictions_labels, average='weighted')\n",
        "\n",
        "    print(f\"\\nâœ… {attack_name} Attack Performance Metrics:\")\n",
        "    print(f\"âœ… Accuracy: {accuracy:.10f}\")\n",
        "    print(f\"âœ… Precision: {precision:.10f}\")\n",
        "    print(f\"âœ… Recall: {recall:.10f}\")\n",
        "    print(f\"âœ… F1-Score: {f1:.10f}\")\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate both attacks\n",
        "fgsm_metrics = evaluate_attack(adv_fgsm_test, \"FGSM\")\n",
        "pgd_metrics = evaluate_attack(adv_pgd_test, \"PGD\")\n",
        "\n",
        "# Confusion matrices for adversarial attacks\n",
        "def plot_confusion_matrix_adv(y_true, y_pred, title=\"Confusion Matrix\"):\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Reds',\n",
        "                xticklabels=target_names, yticklabels=target_names)\n",
        "    plt.xlabel(\"Predicted Labels\")\n",
        "    plt.ylabel(\"True Labels\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nğŸ”¹ Confusion Matrix for FGSM Adversarial Examples\")\n",
        "plot_confusion_matrix_adv(np.argmax(y_test_encoded, axis=1),\n",
        "                         np.argmax(bilstm_model.predict(adv_fgsm_test), axis=1),\n",
        "                         \"FGSM Attack Confusion Matrix\")\n",
        "\n",
        "print(\"\\nğŸ”¹ Confusion Matrix for PGD Adversarial Examples\")\n",
        "plot_confusion_matrix_adv(np.argmax(y_test_encoded, axis=1),\n",
        "                         np.argmax(bilstm_model.predict(adv_pgd_test), axis=1),\n",
        "                         \"PGD Attack Confusion Matrix\")\n",
        "\n",
        "print(\"âœ… Complete CIC IoMT 2024 analysis finished!\")\n",
        "\n",
        "# Step 6: Feature Importance Analysis (Addressing Reviewer Concerns)\n",
        "print(\"\\nğŸ”¹ Step 6: Feature Importance Analysis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npCfoPlOLDMy"
      },
      "outputs": [],
      "source": [
        "# Get feature importance from Logistic Regression\n",
        "lr_model = feature_data['lr_model']\n",
        "feature_importance = np.abs(lr_model.coef_[0]) if CLASSIFICATION_TYPE == 'binary' else np.mean(np.abs(lr_model.coef_), axis=0)\n",
        "\n",
        "# Create feature importance DataFrame\n",
        "feature_names = data['feature_columns']\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importance\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "# Plot top 20 most important features\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_features = importance_df.head(20)\n",
        "plt.barh(range(len(top_features)), top_features['Importance'])\n",
        "plt.yticks(range(len(top_features)), top_features['Feature'])\n",
        "plt.xlabel('Feature Importance (Absolute Coefficient Value)')\n",
        "plt.title('Top 20 Most Important Features for IoMT Intrusion Detection')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Top 10 Most Important Features:\")\n",
        "print(importance_df.head(10))\n",
        "\n",
        "print(\"\\nâœ… All analysis completed successfully!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMneDFyy84fbSQcTrDfsVY0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}