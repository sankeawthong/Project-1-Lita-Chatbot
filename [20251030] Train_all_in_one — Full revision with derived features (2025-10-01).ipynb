{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankeawthong/Project-1-Lita-Chatbot/blob/main/%5B20251030%5D%20Train_all_in_one%20%E2%80%94%20Full%20revision%20with%20derived%20features%20(2025-10-01).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qiXQYQwQ2Na"
      },
      "source": [
        "train_all_in_one — Full revision with derived features (2025-10-01)\n",
        "\n",
        "Adds (vs 2025-09-30 full_rev.py):\n",
        "1) IoMT robustness on the tiny-slice held-out set (FGSM/PGD at ε∈{0.05, 0.10}) — reports AUROC/AUPR & FPR@90/95%DR.\n",
        "2) Automap enrichment:\n",
        "   - broader aliases + vowel-stripping keys\n",
        "   - NEW: canonical derived flow features (duration/packets/bytes/rates/avg len/ports/TCP-UDP flags) computed on ALL datasets,\n",
        "     so NF↔CIC share ≥5 columns even when raw schemas differ.\n",
        "3) Temperature as default calibration; Isotonic as ablation.\n",
        "4) Auto-zip all outputs at the end for easy download."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7Hpkzt0WLTR"
      },
      "source": [
        "train_all_in_one — NaN-safe + artifact caching (2025-10-02)\n",
        "\n",
        "Fixes:\n",
        "- Robust preprocessing: drop all-NaN columns BEFORE imputation; replace inf with NaN; median imputation with indicators.\n",
        "- Eliminates LogisticRegression NaN errors and imputer warnings about features with no observed values.\n",
        "- Keeps previous features/robustness/automap behavior.\n",
        "- Adds lightweight artifact caching for scikit-learn LR→MLP (per phase) into RUN_DIR.\n",
        "\n",
        "Notes:\n",
        "- RUN_DIR defaults to CFG[\"paths\"][\"outdir\"]/artifacts; you can point it to Drive for persistence.\n",
        "- Artifacts saved: NF in-domain (pipe+mlp), CIC tiny-slice (binary pipe+mlp), NF→CIC xfer (pipe+mlp), CIC→NF xfer (pipe+mlp)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DzFUP4DCQmrC"
      },
      "outputs": [],
      "source": [
        "import os, json, argparse, re, difflib, traceback, zipfile, time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline as SkPipeline\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import (accuracy_score, f1_score, classification_report,\n",
        "                             average_precision_score, roc_auc_score, precision_recall_curve,\n",
        "                             confusion_matrix, ConfusionMatrixDisplay)\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from joblib import dump, load\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RREUoDUJQ16t"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "CFG = {\n",
        "    \"paths\": {\n",
        "        \"nf_csv\": \"/content/Dataset_NF-ToN-IoT.csv\",\n",
        "        \"cic_train_csv\": \"/content/CIC_IoMT_2024_WiFi_MQTT_train.csv\",\n",
        "        \"cic_test_csv\": \"/content/CIC_IoMT_2024_WiFi_MQTT_test.csv\",\n",
        "        \"outdir\": \"/mnt/data/iot_ids_refactor/outputs\", # Added missing comma here\n",
        "        # RUN_DIR for artifacts (default: under outdir)\n",
        "        \"run_dir\": None\n",
        "},\n",
        "    \"label_columns\": {\n",
        "        \"binary_candidates\": [\"Label\", \"label\", \"Binary\", \"binary\"],\n",
        "        \"multiclass_candidates\": [\"Class\", \"class\", \"Category\", \"category\"],\n",
        "        \"drop_non_feature_if_present\": [\"Attack\", \"attack\", \"Label\", \"label\", \"Class\", \"class\"]\n",
        "    },\n",
        "    \"train\": {\n",
        "        \"random_state\": 42,\n",
        "        \"test_size\": 0.2,\n",
        "        \"use_smote\": True,\n",
        "        \"mlp_hidden_units\": 64,\n",
        "        \"max_epochs\": 25,\n",
        "        \"batch_size\": 2048\n",
        "    },\n",
        "    \"metrics\": {\"target_drs\": [0.90, 0.95]},\n",
        "    \"calibration\": {\"cic_calib_frac\": 0.10},\n",
        "    \"robust\": {\"eps\": [0.05, 0.10], \"pgd_steps\": 10, \"pgd_alpha\": 0.02},\n",
        "    \"automap\": {\"similarity_threshold\": 0.75, \"max_pairs\": 256}\n",
        "}\n",
        "\n",
        "PERF = {\"adv_eval_max_rows\": 200_000, \"plot_max_rows\": 150_000}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sJJb9SbvQ13J"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Canonical feature aliases\n",
        "# -------------------------\n",
        "CANON = {\n",
        "    \"duration\": [\"dur\",\"flow_duration\",\"duration\",\"dur_ms\",\"flowdur\",\"flow_dur\",\"Flow Duration\"],\n",
        "    \"tot_fwd_pkts\": [\"Tot Fwd Pkts\",\"tot_fwd_pkts\",\"total_fwd_packets\",\"fwd_pkts_tot\",\"fwd_pkts_total\",\"fwd_packets_total\"],\n",
        "    \"tot_bwd_pkts\": [\"Tot Bwd Pkts\",\"tot_bwd_pkts\",\"total_bwd_packets\",\"bwd_pkts_tot\",\"bwd_pkts_total\",\"bwd_packets_total\"],\n",
        "    \"totlen_fwd_pkts\": [\"TotLen Fwd Pkts\",\"totlen_fwd_pkts\",\"total_length_of_fwd_packets\",\"fwd_pkts_len_tot\",\"fwd_bytes_total\",\"total_fwd_bytes\",\"Tot Fwd Bytes\",\"Fwd Bytes\"],\n",
        "    \"totlen_bwd_pkts\": [\"TotLen Bwd Pkts\",\"totlen_bwd_pkts\",\"total_length_of_bwd_packets\",\"bwd_pkts_len_tot\",\"bwd_bytes_total\",\"total_bwd_bytes\",\"Tot Bwd Bytes\",\"Bwd Bytes\"],\n",
        "    \"fwd_pkt_len_mean\": [\"Fwd Pkt Len Mean\",\"fwd_pkt_len_mean\",\"fwd_packet_length_mean\",\"fwd_pkt_length_mean\",\"Fwd Pkt Len Avg\"],\n",
        "    \"bwd_pkt_len_mean\": [\"Bwd Pkt Len Mean\",\"bwd_pkt_len_mean\",\"bwd_packet_length_mean\",\"bwd_pkt_length_mean\",\"Bwd Pkt Len Avg\"],\n",
        "    \"fwd_iat_mean\": [\"Fwd IAT Mean\",\"fwd_iat_mean\",\"fwd_interarrival_mean\",\"fwd_iat_avg\",\"Fwd IAT Avg\"],\n",
        "    \"bwd_iat_mean\": [\"Bwd IAT Mean\",\"bwd_iat_mean\",\"bwd_interarrival_mean\",\"bwd_iat_avg\",\"Bwd IAT Avg\"],\n",
        "    \"pkt_len_mean\": [\"Pkt Len Mean\",\"pkt_len_mean\",\"packet_length_mean\",\"pkt_length_mean\",\"Pkt Len Avg\",\"Average Packet Size\"],\n",
        "    \"pkt_len_std\": [\"Pkt Len Std\",\"pkt_len_std\",\"packet_length_std\",\"pkt_length_std\",\"Std Packet Len\",\"Pkt Len STD\"],\n",
        "    \"flow_pkts_s\": [\"Flow Pkts/s\",\"flow_pkts_s\",\"packets_per_second\",\"pkts_per_sec\",\"pkt_rate\",\"Packet Rate\",\"Pkts/s\"],\n",
        "    \"flow_byts_s\": [\"Flow Byts/s\",\"flow_byts_s\",\"bytes_per_second\",\"byte_rate\",\"bytes_per_sec\",\"throughput\",\"Bps\",\"Bytes/s\"],\n",
        "    \"protocol\": [\"Protocol\",\"proto\",\"protocol\",\"protocol_type\",\"l4_proto\",\"Protocol Type\"],\n",
        "    \"src_port\": [\"Src Port\",\"src_port\",\"sport\",\"source_port\",\"Source Port\"],\n",
        "    \"dst_port\": [\"Dst Port\",\"dst_port\",\"dport\",\"destination_port\",\"Destination Port\"],\n",
        "    \"flags\": [\"flags\",\"tcp_flags\",\"flag_count\",\"tcpflag\",\"flag_total\",\"TCP Flags\",\"Flags\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SFyVph3WQ10u"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Feature utilities\n",
        "# -----------------\n",
        "def build_rename_map(df_cols):\n",
        "    lower = {c.lower(): c for c in df_cols}\n",
        "    rename = {}\n",
        "    for canon, aliases in CANON.items():\n",
        "        for a in aliases:\n",
        "            key = a.lower()\n",
        "            if key in lower:\n",
        "                rename[lower[key]] = canon\n",
        "                break\n",
        "    return rename\n",
        "\n",
        "def normalize_features(df):\n",
        "    rename = build_rename_map(df.columns)\n",
        "    return df.rename(columns=rename)\n",
        "\n",
        "def add_derived_flow_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    d = df.copy()\n",
        "    dur_cols = [\"flow_duration\", \"Flow Duration\", \"duration\", \"dur\", \"dur_ms\", \"flow_dur\"]\n",
        "    dur = None\n",
        "    for c in dur_cols:\n",
        "        if c in d.columns:\n",
        "            dur = pd.to_numeric(d[c], errors=\"coerce\"); break\n",
        "    if dur is None:\n",
        "        d[\"flow_dur_s\"] = 1.0\n",
        "    else:\n",
        "        perc95 = np.nanquantile(dur, 0.95)\n",
        "        d[\"flow_dur_s\"] = np.where(perc95 > 100.0, dur / 1000.0, dur)\n",
        "    def find(colnames):\n",
        "        for c in colnames:\n",
        "            if c in d.columns: return pd.to_numeric(d[c], errors=\"coerce\")\n",
        "        return None\n",
        "    fwd_pkts = find([\"tot_fwd_pkts\",\"Tot Fwd Pkts\",\"total_fwd_packets\",\"fwd_pkts_total\",\"fwd_packets_total\"])\n",
        "    bwd_pkts = find([\"tot_bwd_pkts\",\"Tot Bwd Pkts\",\"total_bwd_packets\",\"bwd_pkts_total\",\"bwd_packets_total\"])\n",
        "    fwd_byts = find([\"totlen_fwd_pkts\",\"TotLen Fwd Pkts\",\"total_fwd_bytes\",\"Fwd Bytes\",\"Tot Fwd Bytes\"])\n",
        "    bwd_byts = find([\"totlen_bwd_pkts\",\"TotLen Bwd Pkts\",\"total_bwd_bytes\",\"Bwd Bytes\",\"Tot Bwd Bytes\"])\n",
        "    d[\"tot_pkts\"] = 0.0\n",
        "    if fwd_pkts is not None: d[\"tot_pkts\"] = d[\"tot_pkts\"] + fwd_pkts.fillna(0)\n",
        "    if bwd_pkts is not None: d[\"tot_pkts\"] = d[\"tot_pkts\"] + bwd_pkts.fillna(0)\n",
        "    d[\"tot_byts\"] = 0.0\n",
        "    if fwd_byts is not None: d[\"tot_byts\"] = d[\"tot_byts\"] + fwd_byts.fillna(0)\n",
        "    if bwd_byts is not None: d[\"tot_byts\"] = d[\"tot_byts\"] + bwd_byts.fillna(0)\n",
        "    safe_dur = np.maximum(d[\"flow_dur_s\"].replace(0, np.nan), 1e-3)\n",
        "    safe_pkts = np.maximum(d[\"tot_pkts\"].replace(0, np.nan), 1.0)\n",
        "    d[\"pkts_per_sec\"] = d[\"tot_pkts\"] / safe_dur\n",
        "    d[\"byts_per_sec\"] = d[\"tot_byts\"] / safe_dur\n",
        "    d[\"avg_pkt_len\"]  = d[\"tot_byts\"] / safe_pkts\n",
        "    for pcol, newcol in [(\"Src Port\",\"src_port\"),(\"src_port\",\"src_port\"),(\"sport\",\"src_port\"),\n",
        "                         (\"Dst Port\",\"dst_port\"),(\"dst_port\",\"dst_port\"),(\"dport\",\"dst_port\")]:\n",
        "        if pcol in d.columns:\n",
        "            d[newcol] = pd.to_numeric(d[pcol], errors=\"coerce\")\n",
        "    proto_col = None\n",
        "    for c in [\"protocol\",\"Protocol\",\"protocol_type\",\"l4_proto\"]:\n",
        "        if c in d.columns: proto_col = c; break\n",
        "    d[\"is_tcp\"] = 0.0; d[\"is_udp\"] = 0.0\n",
        "    if proto_col is not None:\n",
        "        pc = d[proto_col]\n",
        "        if np.issubdtype(pc.dtype, np.number):\n",
        "            d[\"is_tcp\"] = (pc == 6).astype(float)\n",
        "            d[\"is_udp\"] = (pc == 17).astype(float)\n",
        "        else:\n",
        "            pstr = pc.astype(str).str.lower()\n",
        "            d[\"is_tcp\"] = pstr.str.contains(\"tcp\").astype(float)\n",
        "            d[\"is_udp\"] = pstr.str.contains(\"udp\").astype(float)\n",
        "    return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ci1WAEgaQ1x4"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# I/O helpers\n",
        "# -----------------\n",
        "def detect_label_column(df, candidates):\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def pick_features(df, drop_cols):\n",
        "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    feat_cols = [c for c in num_cols if c not in set(drop_cols)]\n",
        "    return feat_cols\n",
        "\n",
        "def load_dataset(path):\n",
        "    df_raw = pd.read_csv(path)\n",
        "    df = normalize_features(df_raw)\n",
        "    df = add_derived_flow_features(df)\n",
        "    bin_col = detect_label_column(df, CFG[\"label_columns\"][\"binary_candidates\"])\n",
        "    mc_col  = detect_label_column(df, CFG[\"label_columns\"][\"multiclass_candidates\"])\n",
        "    feat_cols = pick_features(df, CFG[\"label_columns\"][\"drop_non_feature_if_present\"])\n",
        "    return df, feat_cols, bin_col, mc_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-Fdpo3nWQ1vb"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Labels\n",
        "# -----------------\n",
        "def map_label_string_to_family(s: str) -> str:\n",
        "    st = str(s).lower().strip()\n",
        "    if \"benign\" in st or \"normal\" in st: return \"Benign\"\n",
        "    return \"Attack\"\n",
        "\n",
        "def build_binary_labels(df, bin_col, mc_col):\n",
        "    if bin_col and bin_col in df.columns:\n",
        "        try:\n",
        "            y_bin = df[bin_col].astype(int).values\n",
        "        except ValueError:\n",
        "            y_bin = df[bin_col].apply(lambda x: 0 if map_label_string_to_family(str(x)) == \"Benign\" else 1).values\n",
        "    elif mc_col and mc_col in df.columns:\n",
        "        try:\n",
        "            y_bin = (df[mc_col].astype(int).values != 0).astype(int)\n",
        "        except ValueError:\n",
        "            y_bin = df[mc_col].apply(lambda x: 0 if map_label_string_to_family(str(x)) == \"Benign\" else 1).values\n",
        "    else:\n",
        "        raise ValueError(\"No binary or multiclass label column found.\")\n",
        "    return y_bin\n",
        "\n",
        "def make_one_hot(y, n_classes):\n",
        "    out = np.zeros((len(y), n_classes), dtype=int)\n",
        "    out[np.arange(len(y)), y] = 1\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OtFmWoUKQ1sv"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Calibration\n",
        "# -----------------\n",
        "def sigmoid(x): return 1.0/(1.0+np.exp(-x))\n",
        "\n",
        "def fit_temperature(z_val, y_val, n_iters=300, lr=0.05):\n",
        "    T = 1.0\n",
        "    for _ in range(n_iters):\n",
        "        p = sigmoid(z_val / T)\n",
        "        p = np.clip(p, 1e-7, 1-1e-7)\n",
        "        grad = np.mean((p - y_val) * (-z_val/(T*T)))\n",
        "        T -= lr * grad\n",
        "        T = float(np.clip(T, 0.05, 50.0))\n",
        "    return T\n",
        "\n",
        "def apply_temperature(z, T):\n",
        "    return sigmoid(z / T)\n",
        "\n",
        "def calibrate_scores(scores_cal, y_cal_bin, scores_eval, method=\"temperature\"):\n",
        "    s_cal = np.clip(scores_cal, 1e-6, 1-1e-6)\n",
        "    s_eval = np.clip(scores_eval, 1e-6, 1-1e-6)\n",
        "    if method == \"isotonic\":\n",
        "        iso = IsotonicRegression(out_of_bounds=\"clip\")\n",
        "        iso.fit(s_cal, y_cal_bin.astype(int))\n",
        "        s_eval_cal = iso.predict(s_eval)\n",
        "        return s_eval_cal, {\"method\": \"isotonic\"}\n",
        "    else:\n",
        "        z_cal = np.log(s_cal/(1-s_cal))\n",
        "        T = fit_temperature(z_cal, y_cal_bin.astype(int), n_iters=300, lr=0.05)\n",
        "        z_eval = np.log(s_eval/(1-s_eval))\n",
        "        s_eval_cal = apply_temperature(z_eval, T)\n",
        "        return s_eval_cal, {\"method\": \"temperature\", \"T\": float(T)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bEEkPbWqTM3C"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Metrics & plots\n",
        "# -----------------\n",
        "def fpr_at_dr(y_true, scores, target_dr=0.95, positive_label=1):\n",
        "    thresholds = np.unique(scores)\n",
        "    thresholds.sort()\n",
        "    best_fpr = None\n",
        "    best_thr = None\n",
        "    for thr in thresholds:\n",
        "        y_pred = (scores >= thr).astype(int)\n",
        "        pos = (y_true == positive_label)\n",
        "        neg = ~pos\n",
        "        tp = (pos & (y_pred == 1)).sum()\n",
        "        fn = (pos & (y_pred == 0)).sum()\n",
        "        dr = tp / max(tp + fn, 1)\n",
        "        if dr >= target_dr:\n",
        "            fp = (neg & (y_pred == 1)).sum()\n",
        "            fpr = fp / max(neg.sum(), 1)\n",
        "            if best_fpr is None or fpr < best_fpr:\n",
        "                best_fpr = fpr; best_thr = thr\n",
        "    return best_fpr if best_fpr is not None else np.nan, best_thr\n",
        "\n",
        "def expected_calibration_error(y_true, probas, n_bins=15):\n",
        "    confidences = probas.max(axis=1)\n",
        "    predictions = probas.argmax(axis=1)\n",
        "    correct = (predictions == y_true).astype(float)\n",
        "    bins = np.linspace(0.0, 1.0, n_bins+1)\n",
        "    ece = 0.0\n",
        "    for i in range(n_bins):\n",
        "        mask = (confidences > bins[i]) & (confidences <= bins[i+1])\n",
        "        if mask.sum() == 0: continue\n",
        "        acc = correct[mask].mean()\n",
        "        conf = confidences[mask].mean()\n",
        "        ece += (mask.mean()) * abs(acc - conf)\n",
        "    return ece\n",
        "\n",
        "def plot_pr_curves(y_onehot, probas, class_names, out_png):\n",
        "    if y_onehot.shape[0] > 150000:\n",
        "        idx = np.random.RandomState(42).choice(y_onehot.shape[0], size=150000, replace=False)\n",
        "        y_onehot = y_onehot[idx]; probas = probas[idx]\n",
        "    n_classes = y_onehot.shape[1]\n",
        "    plt.figure()\n",
        "    for c in range(n_classes):\n",
        "        precision, recall, _ = precision_recall_curve(y_onehot[:, c], probas[:, c])\n",
        "        ap = average_precision_score(y_onehot[:, c], probas[:, c])\n",
        "        plt.plot(recall, precision, label=f\"{class_names[c]} (AP={ap:.3f})\")\n",
        "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall Curves\")\n",
        "    plt.legend(); plt.tight_layout(); plt.savefig(out_png, dpi=180); plt.close()\n",
        "\n",
        "def plot_confusion(y_true, y_pred, class_names, out_png, normalize='true'):\n",
        "    if y_true.shape[0] > 150000:\n",
        "        idx = np.random.RandomState(42).choice(y_true.shape[0], size=150000, replace=False)\n",
        "        y_true = y_true[idx]; y_pred = y_pred[idx]\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)), normalize=normalize)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "    fig, ax = plt.subplots(); disp.plot(ax=ax, values_format=\".2f\", cmap=None, colorbar=False)\n",
        "    plt.title(\"Confusion Matrix\" + (f\" (normalized={normalize})\" if normalize else \"\"))\n",
        "    plt.tight_layout(); plt.savefig(out_png, dpi=180); plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UPyXsTrbW8s8"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Robust, NaN-safe preprocessing\n",
        "# -----------------\n",
        "class SafeNaNDropper(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        X = np.asarray(X, dtype=float)\n",
        "        X = np.where(np.isfinite(X), X, np.nan)\n",
        "        self.keep_mask_ = ~np.all(np.isnan(X), axis=0)\n",
        "        if not np.any(self.keep_mask_):\n",
        "            raise ValueError(\"All features are NaN after cleaning.\")\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        X = np.asarray(X, dtype=float)\n",
        "        X = np.where(np.isfinite(X), X, np.nan)\n",
        "        return X[:, self.keep_mask_]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3e8XIRv2TMqj"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Models\n",
        "# -----------------\n",
        "def build_scaler(name):\n",
        "    if name == \"standard\":\n",
        "        return StandardScaler()\n",
        "    elif name == \"robust\":\n",
        "        return RobustScaler(with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0))\n",
        "    elif name == \"quantile\":\n",
        "        return QuantileTransformer(output_distribution=\"normal\", subsample=200000, random_state=42)\n",
        "    else:\n",
        "        return StandardScaler()\n",
        "\n",
        "def get_lr_pipeline(use_smote, random_state, scaler_name='standard', C=1.0):\n",
        "    lr = LogisticRegression(C=C, max_iter=2000, solver=\"lbfgs\", class_weight=\"balanced\", n_jobs=-1)\n",
        "    steps = [\n",
        "        (\"clean\", SafeNaNDropper()),\n",
        "        (\"imputer\", SimpleImputer(strategy='median', add_indicator=True)),\n",
        "        (\"varth\", VarianceThreshold(threshold=0.0)),\n",
        "        (\"scaler\", build_scaler(scaler_name)),\n",
        "    ]\n",
        "    if use_smote:\n",
        "        steps.append((\"smote\", SMOTE(random_state=random_state)))\n",
        "    steps.append((\"lr\", lr))\n",
        "    pipe = ImbPipeline(steps=steps)\n",
        "    return pipe\n",
        "\n",
        "def fit_lr_then_mlp(X_train, y_train, X_val, y_val, use_smote, random_state, max_epochs, batch_size, hidden_units, alpha=1e-4, scaler_name='standard', C=1.0, early_stopping=True):\n",
        "    if X_train.shape[1] != X_val.shape[1]:\n",
        "        print(f\"[ERROR] Feature mismatch: X_train has {X_train.shape[1]} features, X_val has {X_val.shape[1]}.\")\n",
        "        return None, None\n",
        "    if len(np.unique(y_train)) < 2:\n",
        "        print(\"[WARN] Skipping LR pipeline (single-class training data).\")\n",
        "        return None, None\n",
        "    pipe = get_lr_pipeline(use_smote, random_state, scaler_name=scaler_name, C=C)\n",
        "    pipe.fit(X_train, y_train)\n",
        "    try:\n",
        "        Z_train = pipe.decision_function(X_train).reshape(-1, 1)\n",
        "        Z_val = pipe.decision_function(X_val).reshape(-1, 1)\n",
        "    except Exception:\n",
        "        Z_train = np.log(np.clip(pipe.predict_proba(X_train), 1e-7, 1-1e-7))\n",
        "        Z_val = np.log(np.clip(pipe.predict_proba(X_val), 1e-7, 1-1e-7))\n",
        "        if Z_train.ndim == 1: Z_train = Z_train.reshape(-1, 1)\n",
        "        if Z_val.ndim   == 1: Z_val   = Z_val.reshape(-1, 1)\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(hidden_units,), alpha=alpha,\n",
        "                        batch_size=batch_size, learning_rate_init=1e-3,\n",
        "                        max_iter=max_epochs, random_state=random_state,\n",
        "                        early_stopping=early_stopping, n_iter_no_change=5, validation_fraction=0.1)\n",
        "    mlp.fit(Z_train, y_train)\n",
        "    return pipe, mlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f2uXokXBTMm_"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Binary / Multiclass evaluation\n",
        "# ------------------------------\n",
        "def eval_binary(y_true, prob_pos, tag, outdir):\n",
        "    if prob_pos is None or len(prob_pos) == 0:\n",
        "        with open(os.path.join(outdir, f\"{tag}__binary_report.txt\"), \"w\") as f:\n",
        "            f.write(\"Binary evaluation skipped due to insufficient classes or probabilities.\\n\")\n",
        "        return\n",
        "    auc = roc_auc_score(y_true, prob_pos)\n",
        "    aupr = average_precision_score(y_true, prob_pos)\n",
        "    metrics = {\"roc_auc\": float(auc), \"aupr\": float(aupr)}\n",
        "    for dr in [0.90, 0.95]:\n",
        "        fpr, thr = fpr_at_dr(y_true, prob_pos, target_dr=dr)\n",
        "        metrics[f\"fpr@dr={dr}\"] = float(fpr) if fpr==fpr else None\n",
        "        metrics[f\"thr@dr={dr}\"] = float(thr) if thr is not None else None\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    with open(os.path.join(outdir, f\"{tag}__binary_metrics.json\"), \"w\") as f:\n",
        "        json.dump(metrics, f, indent=2)\n",
        "    best_thr = metrics.get(\"thr@dr=0.95\", 0.5)\n",
        "    y_pred = (prob_pos >= (best_thr if best_thr is not None else 0.5)).astype(int)\n",
        "    report = classification_report(y_true, y_pred, digits=4)\n",
        "    with open(os.path.join(outdir, f\"{tag}__binary_report.txt\"), \"w\") as f:\n",
        "        f.write(report)\n",
        "\n",
        "def eval_multiclass(y_true, probas, class_names, tag, outdir, train_classes=None):\n",
        "    if probas is None or probas.shape[0] == 0:\n",
        "        with open(os.path.join(outdir, f\"{tag}__multiclass_metrics.json\"), \"w\") as f:\n",
        "            json.dump({\"accuracy\": np.nan, \"f1_macro\": np.nan,\n",
        "                       \"aupr_micro\": np.nan, \"aupr_per_class\": {}, \"ece\": np.nan}, f, indent=2)\n",
        "        return\n",
        "    test_classes = sorted(np.unique(y_true))\n",
        "    if train_classes is None:\n",
        "        k = min(len(test_classes), probas.shape[1])\n",
        "        probas_aligned = np.zeros((probas.shape[0], len(test_classes)))\n",
        "        probas_aligned[:, :k] = probas[:, :k]\n",
        "        used_classes = test_classes\n",
        "    else:\n",
        "        used_classes = test_classes\n",
        "        probas_aligned = np.zeros((probas.shape[0], len(test_classes)))\n",
        "        for j, cls in enumerate(train_classes):\n",
        "            if cls in test_classes:\n",
        "                idx = test_classes.index(cls)\n",
        "                probas_aligned[:, idx] = probas[:, j]\n",
        "    y_pred = probas_aligned.argmax(axis=1)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1m = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    class_names_eval = [f\"C{c}\" for c in used_classes]\n",
        "    y_idx = np.array([used_classes.index(c) for c in y_true])\n",
        "    y_onehot = make_one_hot(y_idx, len(used_classes))\n",
        "    aupr_micro = average_precision_score(y_onehot, probas_aligned, average=\"micro\")\n",
        "    aupr_per = {class_names_eval[i]: float(average_precision_score(y_onehot[:, i], probas_aligned[:, i]))\n",
        "                for i in range(len(used_classes))}\n",
        "    ece = expected_calibration_error(y_idx, probas_aligned, n_bins=15)\n",
        "    with open(os.path.join(outdir, f\"{tag}__multiclass_metrics.json\"), \"w\") as f:\n",
        "        json.dump({\"accuracy\": float(acc), \"f1_macro\": float(f1m),\n",
        "                   \"aupr_micro\": float(aupr_micro),\n",
        "                   \"aupr_per_class\": aupr_per, \"ece\": float(ece)}, f, indent=2)\n",
        "    plot_pr_curves(y_onehot, probas_aligned, class_names_eval, os.path.join(outdir, f\"{tag}__pr_curves.png\"))\n",
        "    plot_confusion(y_idx, y_pred, class_names_eval, os.path.join(outdir, f\"{tag}__confusion.png\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IHQ6DBRcTMj6"
      },
      "outputs": [],
      "source": [
        "# --------------------------------------------------------\n",
        "# Adversarial utils\n",
        "# --------------------------------------------------------\n",
        "def fgsm(X_std, y, model, eps):\n",
        "    W = model.coef_.reshape(1, -1)\n",
        "    z = model.decision_function(X_std)\n",
        "    p = 1.0/(1.0+np.exp(-z))\n",
        "    grad = (p - y.reshape(-1))[:, None] * W\n",
        "    return X_std + eps * np.sign(grad)\n",
        "\n",
        "def pgd(X_std, y, model, eps, alpha, steps):\n",
        "    X_adv = X_std.copy()\n",
        "    for _ in range(steps):\n",
        "        X_adv = fgsm(X_adv, y, model, alpha)\n",
        "        delta = np.clip(X_adv - X_std, -eps, eps)\n",
        "        X_adv = X_std + delta\n",
        "    return X_adv\n",
        "\n",
        "def clip_to_train_range(X_std, scaler, X_train_std_min, X_train_std_max):\n",
        "    X_raw = X_std\n",
        "    X_raw = np.clip(X_raw, X_train_std_min, X_train_std_max)\n",
        "    return X_raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "innCJ5G7TMhA"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Automapper\n",
        "# -----------------\n",
        "_token_map = {\n",
        "    \"packets\":\"pkts\",\"packet\":\"pkt\",\"length\":\"len\",\"average\":\"mean\",\"stddev\":\"std\",\"std_dev\":\"std\",\n",
        "    \"backward\":\"bwd\",\"forward\":\"fwd\",\"persec\":\"persec\",\"per_second\":\"persec\",\"rate\":\"persec\",\n",
        "    \"bytes\":\"byts\",\"byte\":\"byt\",\"duration\":\"dur\",\"interarrival\":\"iat\",\"src\":\"src\",\"dst\":\"dst\",\n",
        "    \"throughput\":\"bytspersec\",\"bps\":\"bytspersec\",\"bpss\":\"bytspersec\"\n",
        "}\n",
        "def keyify(name: str) -> str:\n",
        "    s = re.sub(r'[^a-zA-Z0-9]+', '', name.lower())\n",
        "    for k,v in _token_map.items():\n",
        "        s = s.replace(k, v)\n",
        "    s = re.sub(r'[aeiou]', '', s)\n",
        "    return s\n",
        "\n",
        "def automap_features(dfA, featsA, dfB, featsB, threshold=0.86, max_pairs=64):\n",
        "    keysA = {f: keyify(f) for f in featsA}\n",
        "    keysB = {f: keyify(f) for f in featsB}\n",
        "    pairs = []\n",
        "    for a,ka in keysA.items():\n",
        "        best_b = None; best_sim = 0.0\n",
        "        for b,kb in keysB.items():\n",
        "            sim = difflib.SequenceMatcher(None, ka, kb).ratio()\n",
        "            if sim > best_sim: best_sim, best_b = sim, b\n",
        "        if best_sim >= threshold and np.issubdtype(dfA[a].dtype, np.number) and np.issubdtype(dfB[best_b].dtype, np.number):\n",
        "            pairs.append((a, best_b, float(best_sim)))\n",
        "    pairs.sort(key=lambda x: -x[2])\n",
        "    usedA, usedB, final = set(), set(), []\n",
        "    for a,b,sim in pairs:\n",
        "        if a in usedA or b in usedB: continue\n",
        "        final.append((a,b,sim))\n",
        "        usedA.add(a); usedB.add(b)\n",
        "        if len(final) >= max_pairs: break\n",
        "    return final\n",
        "\n",
        "def apply_automap_and_rename(df_src, feats_src, df_tgt, feats_tgt, outdir, tag_prefix):\n",
        "    common = list(sorted(set(feats_src).intersection(set(feats_tgt))))\n",
        "    audit = {\"mode\": \"intersection\", \"count\": len(common), \"pairs\": []}\n",
        "    audit_path = os.path.join(outdir, f\"{tag_prefix}__feature_automap.json\")\n",
        "    if len(common) > 0:\n",
        "        with open(audit_path, \"w\") as f: json.dump(audit, f, indent=2)\n",
        "        with open(os.path.join(outdir, f\"{tag_prefix}_common_features.json\"), \"w\") as f:\n",
        "            json.dump({\"count\": len(common), \"features\": common, \"audit\": os.path.basename(audit_path)}, f, indent=2)\n",
        "        return df_src, df_tgt, common, audit_path\n",
        "    matches = automap_features(df_src, feats_src, df_tgt, feats_tgt,\n",
        "                               threshold=CFG[\"automap\"][\"similarity_threshold\"],\n",
        "                               max_pairs=CFG[\"automap\"][\"max_pairs\"])\n",
        "    audit = {\"mode\": \"automap\", \"count\": len(matches),\n",
        "             \"pairs\": [{\"src\":a,\"tgt\":b,\"similarity\":sim} for a,b,sim in matches]}\n",
        "    df_tgt2 = df_tgt.copy()\n",
        "    rename_map = {b:a for a,b,_ in matches}\n",
        "    df_tgt2 = df_tgt2.rename(columns=rename_map)\n",
        "    common2 = [a for a,_,_ in matches]\n",
        "    audit[\"renamed\"] = rename_map\n",
        "    with open(audit_path, \"w\") as f: json.dump(audit, f, indent=2)\n",
        "    with open(os.path.join(outdir, f\"{tag_prefix}_common_features.json\"), \"w\") as f:\n",
        "        json.dump({\"count\": len(common2), \"features\": common2, \"audit\": os.path.basename(audit_path)}, f, indent=2)\n",
        "    return df_src, df_tgt2, common2, audit_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "b-7wku3rXUvS"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Helpers: RUN_DIR + artifact I/O\n",
        "# -----------------\n",
        "def get_run_dir(outdir):\n",
        "    rd = CFG[\"paths\"][\"run_dir\"] or os.path.join(outdir, \"artifacts\")\n",
        "    os.makedirs(rd, exist_ok=True)\n",
        "    return rd\n",
        "\n",
        "def save_artifact(obj, path):\n",
        "    tmp = path + f\".tmp{int(time.time()*1000)}\"\n",
        "    dump(obj, tmp)\n",
        "    os.replace(tmp, path)\n",
        "\n",
        "def metric_row_csv(csv_path, header, row):\n",
        "    new = not os.path.exists(csv_path)\n",
        "    with open(csv_path, \"a\") as f:\n",
        "        if new: f.write(\",\".join(header)+\"\\n\")\n",
        "        f.write(\",\".join(map(str,row))+\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hlYbkoAKTY5s"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# NF in-domain\n",
        "# -----------------\n",
        "def run_in_domain_nf(nf_df, nf_feats, nf_bin_col, nf_mc_col, outdir):\n",
        "    RUN_DIR = get_run_dir(outdir)\n",
        "\n",
        "    yb = build_binary_labels(nf_df, nf_bin_col, nf_mc_col)\n",
        "    X = nf_df[nf_feats].values\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(X, yb, test_size=CFG[\"train\"][\"test_size\"],\n",
        "                                              stratify=yb, random_state=CFG[\"train\"][\"random_state\"])\n",
        "\n",
        "    pipe, mlp = fit_lr_then_mlp(X_tr, y_tr, X_te, y_te,\n",
        "                                CFG[\"train\"][\"use_smote\"], CFG[\"train\"][\"random_state\"],\n",
        "                                CFG[\"train\"][\"max_epochs\"], CFG[\"train\"][\"batch_size\"],\n",
        "                                CFG[\"train\"][\"mlp_hidden_units\"])\n",
        "\n",
        "    if pipe is not None and mlp is not None:\n",
        "        save_artifact(pipe, os.path.join(RUN_DIR, \"NF_in_domain_pipe.joblib\"))\n",
        "        save_artifact(mlp,  os.path.join(RUN_DIR, \"NF_in_domain_mlp.joblib\"))\n",
        "\n",
        "    prob_pos = None\n",
        "    if pipe is not None:\n",
        "        try:\n",
        "            Z_te = pipe.decision_function(X_te).reshape(-1,1)\n",
        "        except Exception:\n",
        "            Z_te = np.log(np.clip(pipe.predict_proba(X_te), 1e-7, 1-1e-7)).reshape(-1,1)\n",
        "        prob_pos = mlp.predict_proba(Z_te)[:,1] if mlp is not None else pipe.predict_proba(X_te)[:,1]\n",
        "    eval_binary(y_te, prob_pos, \"NF_ToN_IoT__in_domain\", outdir)\n",
        "\n",
        "    if prob_pos is not None:\n",
        "        roc = roc_auc_score(y_te, prob_pos)\n",
        "        aupr = average_precision_score(y_te, prob_pos)\n",
        "        f90, _ = fpr_at_dr(y_te, prob_pos, 0.90); f95, _ = fpr_at_dr(y_te, prob_pos, 0.95)\n",
        "        metric_row_csv(os.path.join(RUN_DIR, \"metrics_log.csv\"),\n",
        "                       [\"phase\",\"roc_auc\",\"aupr\",\"fpr@0.90\",\"fpr@0.95\"],\n",
        "                       [\"NF_clean\", roc, aupr, f90, f95])\n",
        "\n",
        "    if pipe is not None:\n",
        "        Xt_tr_std = pipe.named_steps[\"scaler\"].transform(\n",
        "            pipe.named_steps[\"varth\"].transform(\n",
        "                pipe.named_steps[\"imputer\"].transform(\n",
        "                    pipe.named_steps[\"clean\"].transform(X_tr))))\n",
        "        Xt_te_std = pipe.named_steps[\"scaler\"].transform(\n",
        "            pipe.named_steps[\"varth\"].transform(\n",
        "                pipe.named_steps[\"imputer\"].transform(\n",
        "                    pipe.named_steps[\"clean\"].transform(X_te))))\n",
        "        Xmin, Xmax = Xt_tr_std.min(axis=0), Xt_tr_std.max(axis=0)\n",
        "\n",
        "        if Xt_te_std.shape[0] > 200000:\n",
        "            rs = np.random.RandomState(42)\n",
        "            idx = rs.choice(Xt_te_std.shape[0], size=200000, replace=False)\n",
        "            Xt_te_std = Xt_te_std[idx]; y_te_adv = y_te[idx]\n",
        "        else:\n",
        "            y_te_adv = y_te\n",
        "\n",
        "        lr = pipe.named_steps[\"lr\"]\n",
        "        for eps in CFG[\"robust\"][\"eps\"]:\n",
        "            X_fgsm = fgsm(Xt_te_std, y_te_adv, lr, eps)\n",
        "            X_fgsm = clip_to_train_range(X_fgsm, pipe.named_steps[\"scaler\"], Xmin, Xmax)\n",
        "            z_fgsm = lr.decision_function(X_fgsm).reshape(-1,1)\n",
        "            prob_fgsm = mlp.predict_proba(z_fgsm)[:,1] if mlp is not None else 1.0/(1.0+np.exp(-z_fgsm)).ravel()\n",
        "            eval_binary(y_te_adv, prob_fgsm, f\"NF_ToN_IoT__in_domain__FGSM_eps={eps}\", outdir)\n",
        "\n",
        "            X_pgd = pgd(Xt_te_std, y_te_adv, lr, eps, CFG[\"robust\"][\"pgd_alpha\"], CFG[\"robust\"][\"pgd_steps\"])\n",
        "            X_pgd = clip_to_train_range(X_pgd, pipe.named_steps[\"scaler\"], Xmin, Xmax)\n",
        "            z_pgd = lr.decision_function(X_pgd).reshape(-1,1)\n",
        "            prob_pgd = mlp.predict_proba(z_pgd)[:,1] if mlp is not None else 1.0/(1.0+np.exp(-z_pgd)).ravel()\n",
        "            eval_binary(y_te_adv, prob_pgd, f\"NF_ToN_IoT__in_domain__PGD_eps={eps}\", outdir)\n",
        "\n",
        "    if nf_mc_col:\n",
        "        ym = nf_df[nf_mc_col].astype(int).values\n",
        "        Xm_tr, Xm_te, ym_tr, ym_te = train_test_split(X, ym, test_size=CFG[\"train\"][\"test_size\"],\n",
        "                                                      stratify=ym, random_state=CFG[\"train\"][\"random_state\"])\n",
        "        if len(np.unique(ym_tr)) >= 2:\n",
        "            pipe_m = SkPipeline([\n",
        "              (\"clean\", SafeNaNDropper()),\n",
        "              (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
        "              (\"scaler\", StandardScaler()),\n",
        "              (\"clf\", LogisticRegression(max_iter=2000, n_jobs=-1))\n",
        "            ])\n",
        "            pipe_m.fit(Xm_tr, ym_tr)\n",
        "            probas = pipe_m.predict_proba(Xm_te)\n",
        "\n",
        "            class_names = [f\"C{c}\" for c in sorted(np.unique(ym))]\n",
        "            eval_multiclass(ym_te, probas, class_names, \"NF_ToN_IoT__in_domain_native_mc\", outdir,\n",
        "                            train_classes=list(pipe_m.named_steps[\"clf\"].classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iQ6ho_0STY2Q"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# CIC native multiclass\n",
        "# ------------------------------\n",
        "def run_in_domain_cic_native_mc(cic_tr_df, cic_tr_feats, cic_tr_mc_col,\n",
        "                                cic_te_df, cic_te_feats, cic_te_mc_col, outdir):\n",
        "    common = list(sorted(set(cic_tr_feats).intersection(set(cic_te_feats))))\n",
        "    if len(common) == 0: return\n",
        "    Xtr = cic_tr_df[common].values\n",
        "    Xte = cic_te_df[common].values\n",
        "    ym_tr = cic_tr_df[cic_tr_mc_col].astype(int).values if cic_tr_mc_col else None\n",
        "    ym_te = cic_te_df[cic_te_mc_col].astype(int).values if cic_te_mc_col else None\n",
        "    if ym_tr is None or ym_te is None or len(np.unique(ym_tr)) < 2: return\n",
        "\n",
        "    pipe_m = SkPipeline([\n",
        "    (\"clean\", SafeNaNDropper()),\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=2000, n_jobs=-1))\n",
        "    ])\n",
        "    pipe_m.fit(Xtr, ym_tr)\n",
        "    probas = pipe_m.predict_proba(Xte)\n",
        "\n",
        "    class_names = [f\"C{c}\" for c in sorted(np.unique(ym_te))]\n",
        "    train_classes = list(pipe_m.named_steps[\"clf\"].classes_)\n",
        "    eval_multiclass(ym_te, probas, class_names, \"CIC_IoMT__native_multiclass__train_to_test\", outdir, train_classes=train_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2BVlcc7qTYzM"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# CIC tiny benign slice experiment (with artifacts + robustness)\n",
        "# ----------------------------------------------------------------------\n",
        "def run_cic_with_tiny_benign_slice(cic_tr_df, cic_tr_feats, cic_tr_bin_col, cic_tr_mc_col,\n",
        "                                   cic_te_df, cic_te_feats, cic_te_bin_col, cic_te_mc_col,\n",
        "                                   outdir, slice_frac=0.015, seed=42):\n",
        "    RUN_DIR = get_run_dir(outdir)\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    try:\n",
        "        rs = np.random.RandomState(seed)\n",
        "        common = list(sorted(set(cic_tr_feats).intersection(set(cic_te_feats))))\n",
        "        if len(common) == 0:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: no shared numeric features between CIC_train and CIC_test.\\n\")\n",
        "            return\n",
        "        if cic_tr_mc_col is None or cic_te_mc_col is None:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: multiclass label column not found in CIC train/test.\\n\")\n",
        "            return\n",
        "\n",
        "        y_tr_mc = cic_tr_df[cic_tr_mc_col].astype(int).values\n",
        "        X_tr_all = cic_tr_df[common].values\n",
        "        A_idx = np.where(y_tr_mc != 0)[0]\n",
        "        if len(A_idx) == 0:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: CIC_train has no attacks; cannot build binary head.\\n\")\n",
        "            return\n",
        "        X_attack_all = X_tr_all[A_idx]\n",
        "\n",
        "        y_te_mc = cic_te_df[cic_te_mc_col].astype(int).values\n",
        "        X_te_all = cic_te_df[common].values\n",
        "        ben_idx_all = np.where(y_te_mc == 0)[0]\n",
        "        atk_idx_all = np.where(y_te_mc != 0)[0]\n",
        "        if len(ben_idx_all) == 0:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: no benign samples in CIC_test.\\n\")\n",
        "            return\n",
        "\n",
        "        n_ben_slice = max(1, int(len(ben_idx_all) * slice_frac))\n",
        "        ben_slice = rs.choice(ben_idx_all, size=n_ben_slice, replace=False)\n",
        "        n_ben_cal  = max(1, n_ben_slice // 2)\n",
        "        n_ben_train = n_ben_slice - n_ben_cal\n",
        "        rs.shuffle(ben_slice)\n",
        "        ben_train_idx = ben_slice[:n_ben_train]\n",
        "        ben_cal_idx   = ben_slice[n_ben_train:]\n",
        "        n_atk_cal = min(len(atk_idx_all), n_ben_cal)\n",
        "        atk_cal_idx = rs.choice(atk_idx_all, size=n_atk_cal, replace=False)\n",
        "\n",
        "        held_out_mask = np.ones(len(y_te_mc), dtype=bool)\n",
        "        held_out_mask[ben_slice] = False\n",
        "        held_out_mask[atk_cal_idx] = False\n",
        "        X_eval = X_te_all[held_out_mask]\n",
        "        y_eval_bin = (y_te_mc[held_out_mask] != 0).astype(int)\n",
        "        if X_eval.shape[0] == 0 or len(np.unique(y_eval_bin)) < 2:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: empty or single-class held-out evaluation set after slicing.\\n\")\n",
        "            return\n",
        "\n",
        "        X_train = np.vstack([X_attack_all, X_te_all[ben_train_idx]])\n",
        "        y_train_bin = np.concatenate([np.ones(len(X_attack_all), dtype=int),\n",
        "                                      np.zeros(len(ben_train_idx), dtype=int)])\n",
        "\n",
        "        X_cal = np.vstack([X_te_all[atk_cal_idx], X_te_all[ben_cal_idx]])\n",
        "        y_cal_bin = np.concatenate([np.ones(len(atk_cal_idx), dtype=int),\n",
        "                                    np.zeros(len(ben_cal_idx), dtype=int)])\n",
        "\n",
        "        pipe_b, mlp_b = fit_lr_then_mlp(\n",
        "            X_train, y_train_bin,\n",
        "            X_eval,  y_eval_bin,\n",
        "            CFG[\"train\"][\"use_smote\"], CFG[\"train\"][\"random_state\"],\n",
        "            CFG[\"train\"][\"max_epochs\"], CFG[\"train\"][\"batch_size\"],\n",
        "            CFG[\"train\"][\"mlp_hidden_units\"]\n",
        "        )\n",
        "        if pipe_b is None:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: training pipeline failed (single-class or pipeline error).\\n\")\n",
        "            return\n",
        "\n",
        "        save_artifact(pipe_b, os.path.join(RUN_DIR, \"CIC_tiny_slice_pipe.joblib\"))\n",
        "        save_artifact(mlp_b,  os.path.join(RUN_DIR, \"CIC_tiny_slice_mlp.joblib\"))\n",
        "\n",
        "        try:\n",
        "            Z_eval = pipe_b.decision_function(X_eval).reshape(-1,1)\n",
        "            Z_cal  = pipe_b.decision_function(X_cal).reshape(-1,1)\n",
        "            prob_eval = mlp_b.predict_proba(Z_eval)[:,1]\n",
        "            prob_cal  = mlp_b.predict_proba(Z_cal)[:,1]\n",
        "        except Exception:\n",
        "            prob_eval = pipe_b.predict_proba(X_eval)[:,1]\n",
        "            prob_cal  = pipe_b.predict_proba(X_cal)[:,1]\n",
        "\n",
        "        auc_unc = float(roc_auc_score(y_eval_bin, prob_eval))\n",
        "        aupr_unc = float(average_precision_score(y_eval_bin, prob_eval))\n",
        "        fpr90_unc, thr90_unc = fpr_at_dr(y_eval_bin, prob_eval, target_dr=0.90)\n",
        "        fpr95_unc, thr95_unc = fpr_at_dr(y_eval_bin, prob_eval, target_dr=0.95)\n",
        "        eval_binary(y_eval_bin, prob_eval, \"CIC_IoMT__tiny_benign_slice\", outdir)\n",
        "\n",
        "        rows = []\n",
        "        def _row(kind, auc, aupr, f90, t90, f95, t95):\n",
        "            return {\"scenario\": f\"CIC_tiny_slice__{kind}\",\n",
        "                    \"roc_auc\": auc, \"aupr\": aupr,\n",
        "                    \"fpr@dr=0.90\": f90, \"thr@dr=0.90\": t90,\n",
        "                    \"fpr@dr=0.95\": f95, \"thr@dr=0.95\": t95}\n",
        "        rows.append(_row(\"uncalibrated\", auc_unc, aupr_unc, fpr90_unc, thr90_unc, fpr95_unc, thr95_unc))\n",
        "\n",
        "        for method in [\"temperature\", \"isotonic\"]:\n",
        "            prob_eval_cal, meta = calibrate_scores(prob_cal, y_cal_bin, prob_eval, method=method)\n",
        "            auc_c = float(roc_auc_score(y_eval_bin, prob_eval_cal))\n",
        "            aupr_c = float(average_precision_score(y_eval_bin, prob_eval_cal))\n",
        "            fpr90_c, thr90_c = fpr_at_dr(y_eval_bin, prob_eval_cal, target_dr=0.90)\n",
        "            fpr95_c, thr95_c = fpr_at_dr(y_eval_bin, prob_eval_cal, target_dr=0.95)\n",
        "            eval_binary(y_eval_bin, prob_eval_cal, f\"CIC_IoMT__tiny_benign_slice__Calibrated({method})\", outdir)\n",
        "            with open(os.path.join(outdir, f\"CIC_IoMT__tiny_benign_slice__Calibrated({method})__meta.json\"), \"w\") as f:\n",
        "                json.dump(meta, f, indent=2)\n",
        "            rows.append(_row(f\"Calibrated({method})\", auc_c, aupr_c, fpr90_c, thr90_c, fpr95_c, thr95_c))\n",
        "\n",
        "        Xt_tr_std = pipe_b.named_steps[\"scaler\"].transform(\n",
        "            pipe_b.named_steps[\"varth\"].transform(\n",
        "                pipe_b.named_steps[\"imputer\"].transform(\n",
        "                    pipe_b.named_steps[\"clean\"].transform(X_train))))\n",
        "        Xt_eval_std = pipe_b.named_steps[\"scaler\"].transform(\n",
        "            pipe_b.named_steps[\"varth\"].transform(\n",
        "                pipe_b.named_steps[\"imputer\"].transform(\n",
        "                    pipe_b.named_steps[\"clean\"].transform(X_eval))))\n",
        "        Xmin, Xmax = Xt_tr_std.min(axis=0), Xt_tr_std.max(axis=0)\n",
        "\n",
        "        if Xt_eval_std.shape[0] > 200000:\n",
        "            rs2 = np.random.RandomState(123)\n",
        "            idx = rs2.choice(Xt_eval_std.shape[0], size=200000, replace=False)\n",
        "            Xt_eval_std = Xt_eval_std[idx]; y_eval_small = y_eval_bin[idx]\n",
        "        else:\n",
        "            y_eval_small = y_eval_bin\n",
        "        lr = pipe_b.named_steps[\"lr\"]\n",
        "        for eps in CFG[\"robust\"][\"eps\"]:\n",
        "            X_fgsm = fgsm(Xt_eval_std, y_eval_small, lr, eps)\n",
        "            X_fgsm = clip_to_train_range(X_fgsm, pipe_b.named_steps[\"scaler\"], Xmin, Xmax)\n",
        "            z_fgsm = lr.decision_function(X_fgsm).reshape(-1,1)\n",
        "            prob_fgsm = mlp_b.predict_proba(z_fgsm)[:,1] if mlp_b is not None else 1.0/(1.0+np.exp(-z_fgsm)).ravel()\n",
        "            eval_binary(y_eval_small, prob_fgsm, f\"CIC_IoMT__tiny_benign_slice__FGSM_eps={eps}\", outdir)\n",
        "\n",
        "            X_pgd = pgd(Xt_eval_std, y_eval_small, lr, eps, CFG['robust']['pgd_alpha'], CFG['robust']['pgd_steps'])\n",
        "            X_pgd = clip_to_train_range(X_pgd, pipe_b.named_steps[\"scaler\"], Xmin, Xmax)\n",
        "            z_pgd = lr.decision_function(X_pgd).reshape(-1,1)\n",
        "            prob_pgd = mlp_b.predict_proba(z_pgd)[:,1] if mlp_b is not None else 1.0/(1.0+np.exp(-z_pgd)).ravel()\n",
        "            eval_binary(y_eval_small, prob_pgd, f\"CIC_IoMT__tiny_benign_slice__PGD_eps={eps}\", outdir)\n",
        "\n",
        "        pd.DataFrame(rows).to_csv(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__summary.csv\"), index=False)\n",
        "\n",
        "        with open(os.path.join(RUN_DIR, \"metrics_log.csv\"), \"a\") as f:\n",
        "            f.write(f\"CIC_tiny_slice_uncalibrated,{auc_unc},{aupr_unc},{fpr90_unc},{fpr95_unc}\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__ERROR.txt\"), \"w\") as f:\n",
        "            f.write(\"Exception occurred during tiny-slice run:\\n\")\n",
        "            f.write(str(e) + \"\\n\\n\" + traceback.format_exc())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Nb_uMHq4XsHA"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Collapsed-binary\n",
        "# -----------------\n",
        "def run_in_domain_cic_collapsed(cic_tr_df, cic_tr_feats, cic_tr_mc_col,\n",
        "                                cic_te_df, cic_te_feats, cic_te_mc_col, outdir, calib_method=\"temperature\"):\n",
        "    common = list(sorted(set(cic_tr_feats).intersection(set(cic_te_feats))))\n",
        "    if len(common) == 0:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__train_to_test__binary_from_mc__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(\"Skipped: no shared numeric features between CIC_train and CIC_test.\\n\")\n",
        "        return\n",
        "    Xtr = cic_tr_df[common].values\n",
        "    Xte_full = cic_te_df[common].values\n",
        "    ym_tr = cic_tr_df[cic_tr_mc_col].astype(int).values if cic_tr_mc_col else None\n",
        "    ym_te_full = cic_te_df[cic_te_mc_col].astype(int).values if cic_te_mc_col else None\n",
        "    if ym_tr is None or ym_te_full is None or len(np.unique(ym_tr)) < 2:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__train_to_test__binary_from_mc__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(\"Skipped: multiclass labels missing or single-class in CIC_train/CIC_test.\\n\")\n",
        "        return\n",
        "\n",
        "    pipe_m = SkPipeline([\n",
        "    (\"clean\", SafeNaNDropper()),\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=2000, n_jobs=-1))\n",
        "    ])\n",
        "    pipe_m.fit(Xtr, ym_tr)\n",
        "\n",
        "    X_cal, X_eval, y_cal, y_eval = train_test_split(Xte_full, ym_te_full, test_size=1.0-CFG[\"calibration\"][\"cic_calib_frac\"],\n",
        "                                                    stratify=ym_te_full, random_state=CFG[\"train\"][\"random_state\"])\n",
        "    probas_cal = pipe_m.predict_proba(X_cal)\n",
        "    probas_eval = pipe_m.predict_proba(X_eval)\n",
        "    ben_mask_cal = (y_cal == 0)\n",
        "    if ben_mask_cal.sum() == 0:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__train_to_test__binary_from_mc__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(\"Skipped: no benign in CIC_test calibration split; cannot align benign column.\\n\")\n",
        "        return\n",
        "    mean_probs_on_ben = probas_cal[ben_mask_cal].mean(axis=0)\n",
        "    benign_idx_aligned = int(np.argmax(mean_probs_on_ben))\n",
        "    if mean_probs_on_ben[benign_idx_aligned] < 0.25:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__train_to_test__binary_from_mc__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(f\"Skipped: aligned 'benign' column probability on benign-cal < 0.25 ({mean_probs_on_ben[benign_idx_aligned]:.3f}).\\n\")\n",
        "        return\n",
        "    s_attack_cal  = 1.0 - np.clip(probas_cal[:,  benign_idx_aligned], 1e-6, 1-1e-6)\n",
        "    s_attack_eval = 1.0 - np.clip(probas_eval[:, benign_idx_aligned], 1e-6, 1-1e-6)\n",
        "    auc_cal = roc_auc_score((y_cal != 0).astype(int), s_attack_cal)\n",
        "    if auc_cal < 0.5:\n",
        "        s_attack_cal  = 1.0 - s_attack_cal\n",
        "        s_attack_eval = 1.0 - s_attack_eval\n",
        "    eval_binary((y_eval != 0).astype(int), s_attack_eval, \"CIC_IoMT__train_to_test__binary_from_mc\", outdir)\n",
        "    s_eval_cal, meta = calibrate_scores(s_attack_cal, (y_cal != 0).astype(int), s_attack_eval, method=calib_method)\n",
        "    eval_binary((y_eval != 0).astype(int), s_eval_cal, f\"CIC_IoMT__train_to_test__binary_from_mc__Calibrated({calib_method})\", outdir)\n",
        "    with open(os.path.join(outdir, f\"CIC_IoMT__train_to_test__binary_from_mc__Calibrated({calib_method})__meta.json\"), \"w\") as f:\n",
        "        json.dump({\"benign_alignment\": {\"column_index\": benign_idx_aligned,\n",
        "                                        \"mean_prob_on_benign_cal\": float(mean_probs_on_ben[benign_idx_aligned])},\n",
        "                   **meta}, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tXsSOUBRTYwT"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Cross-domain\n",
        "# -----------------\n",
        "def run_cross_domain(nf_df, nf_feats, nf_bin_col, nf_mc_col,\n",
        "                     cic_tr_df, cic_tr_feats, cic_tr_bin_col, cic_tr_mc_col,\n",
        "                     cic_te_df, cic_te_feats, cic_te_bin_col, cic_te_mc_col,\n",
        "                     outdir, automap_min=5):\n",
        "    RUN_DIR = get_run_dir(outdir)\n",
        "\n",
        "    nf_df2, cic_te_df2, common_nf_cic, audit1 = apply_automap_and_rename(nf_df, nf_feats, cic_te_df, cic_te_feats, outdir, \"NF_to_CIC\")\n",
        "    if len(common_nf_cic) < automap_min:\n",
        "        with open(os.path.join(outdir, \"NF_to_CIC__xfer__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(f\"Skipped: shared features {len(common_nf_cic)} < {automap_min}\\n\")\n",
        "    else:\n",
        "        Xs = nf_df2[common_nf_cic].values\n",
        "        Xt = cic_te_df2[common_nf_cic].values\n",
        "        ys = build_binary_labels(nf_df2, nf_bin_col, nf_mc_col)\n",
        "        yt = build_binary_labels(cic_te_df2, cic_te_bin_col, cic_te_mc_col)\n",
        "        pipe, mlp = fit_lr_then_mlp(Xs, ys, Xt, np.zeros(len(Xt)),\n",
        "                                    CFG[\"train\"][\"use_smote\"], CFG[\"train\"][\"random_state\"],\n",
        "                                    CFG[\"train\"][\"max_epochs\"], CFG[\"train\"][\"batch_size\"],\n",
        "                                    CFG[\"train\"][\"mlp_hidden_units\"])\n",
        "        if pipe is not None and mlp is not None:\n",
        "            save_artifact(pipe, os.path.join(RUN_DIR, \"XFER_NF_to_CIC_pipe.joblib\"))\n",
        "            save_artifact(mlp,  os.path.join(RUN_DIR, \"XFER_NF_to_CIC_mlp.joblib\"))\n",
        "        prob_pos = None\n",
        "        if pipe is not None:\n",
        "            try:\n",
        "                Zt = pipe.decision_function(Xt).reshape(-1,1)\n",
        "            except Exception:\n",
        "                Zt = np.log(np.clip(pipe.predict_proba(Xt), 1e-7, 1-1e-7)).reshape(-1,1)\n",
        "            prob_pos = mlp.predict_proba(Zt)[:,1] if mlp is not None else pipe.predict_proba(Xt)[:,1]\n",
        "        eval_binary(yt, prob_pos, \"NF_ToN_IoT__to__CIC_IoMT_test__binary_xfer\", outdir)\n",
        "        if pipe is not None:\n",
        "            Xt_std = pipe.named_steps[\"scaler\"].transform(\n",
        "                pipe.named_steps[\"varth\"].transform(\n",
        "                    pipe.named_steps[\"imputer\"].transform(\n",
        "                        pipe.named_steps[\"clean\"].transform(Xt))))\n",
        "            Xs_std = pipe.named_steps[\"scaler\"].transform(\n",
        "                pipe.named_steps[\"varth\"].transform(\n",
        "                    pipe.named_steps[\"imputer\"].transform(\n",
        "                        pipe.named_steps[\"clean\"].transform(Xs))))\n",
        "            Xmin, Xmax = Xs_std.min(axis=0), Xs_std.max(axis=0)\n",
        "            lr = pipe.named_steps[\"lr\"]\n",
        "            for eps in CFG[\"robust\"][\"eps\"]:\n",
        "                Xt_fgsm = fgsm(Xt_std, yt, lr, eps)\n",
        "                Xt_fgsm = clip_to_train_range(Xt_fgsm, pipe.named_steps[\"scaler\"], Xmin, Xmax)\n",
        "                z_fgsm = lr.decision_function(Xt_fgsm).reshape(-1,1)\n",
        "                prob_fgsm = mlp.predict_proba(z_fgsm)[:,1] if mlp is not None else 1.0/(1.0+np.exp(-z_fgsm)).ravel()\n",
        "                eval_binary(yt, prob_fgsm, f\"NF_ToN_IoT__to__CIC_IoMT_test__FGSM_eps={eps}\", outdir)\n",
        "\n",
        "                Xt_pgd = pgd(Xt_std, yt, lr, eps, CFG[\"robust\"][\"pgd_alpha\"], CFG[\"robust\"][\"pgd_steps\"])\n",
        "                Xt_pgd = clip_to_train_range(Xt_pgd, pipe.named_steps[\"scaler\"], Xmin, Xmax)\n",
        "                z_pgd = lr.decision_function(Xt_pgd).reshape(-1,1)\n",
        "                prob_pgd = mlp.predict_proba(z_pgd)[:,1] if mlp is not None else 1.0/(1.0+np.exp(-z_pgd)).ravel()\n",
        "                eval_binary(yt, prob_pgd, f\"NF_ToN_IoT__to__CIC_IoMT_test__PGD_eps={eps}\", outdir)\n",
        "\n",
        "    cic_tr_df2, nf_df2b, common_cic_nf, audit2 = apply_automap_and_rename(cic_tr_df, cic_tr_feats, nf_df, nf_feats, outdir, \"CIC_to_NF\")\n",
        "    if len(common_cic_nf) < automap_min:\n",
        "        with open(os.path.join(outdir, \"CIC_to_NF__xfer__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(f\"Skipped: shared features {len(common_cic_nf)} < {automap_min}\\n\")\n",
        "    else:\n",
        "        Xs2 = cic_tr_df2[common_cic_nf].values\n",
        "        Xt2 = nf_df2b[common_cic_nf].values\n",
        "        ys2 = build_binary_labels(cic_tr_df2, cic_tr_bin_col, cic_tr_mc_col)\n",
        "        yt2 = build_binary_labels(nf_df2b, nf_bin_col, nf_mc_col)\n",
        "        pipe2, mlp2 = fit_lr_then_mlp(Xs2, ys2, Xt2, np.zeros(len(Xt2)),\n",
        "                                      CFG[\"train\"][\"use_smote\"], CFG[\"train\"][\"random_state\"],\n",
        "                                      CFG[\"train\"][\"max_epochs\"], CFG[\"train\"][\"batch_size\"],\n",
        "                                      CFG[\"train\"][\"mlp_hidden_units\"])\n",
        "        if pipe2 is not None and mlp2 is not None:\n",
        "            save_artifact(pipe2, os.path.join(RUN_DIR, \"XFER_CIC_to_NF_pipe.joblib\"))\n",
        "            save_artifact(mlp2,  os.path.join(RUN_DIR, \"XFER_CIC_to_NF_mlp.joblib\"))\n",
        "        prob_pos2=None\n",
        "        if pipe2 is not None:\n",
        "            try:\n",
        "                Zt2 = pipe2.decision_function(Xt2).reshape(-1,1)\n",
        "            except Exception:\n",
        "                Zt2 = np.log(np.clip(pipe2.predict_proba(Xt2), 1e-7, 1-1e-7)).reshape(-1,1)\n",
        "            prob_pos2 = mlp2.predict_proba(Zt2)[:,1] if mlp2 is not None else pipe2.predict_proba(Xt2)[:,1]\n",
        "        eval_binary(yt2, prob_pos2, \"CIC_IoMT_train__to__NF_ToN_IoT__binary_xfer\", outdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bkpLLHZ0XyfF"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# ZIP helper\n",
        "# -----------------\n",
        "def zip_outputs(outdir, zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'w', compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root, _, files in os.walk(outdir):\n",
        "            for f in files:\n",
        "                fp = os.path.join(root, f)\n",
        "                arc = os.path.relpath(fp, start=outdir)\n",
        "                zf.write(fp, arc)\n",
        "    return zip_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoIlzTx5Tjvk",
        "outputId": "861c3937-dab4-4f32-98bf-23bf63c49ea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Skipping LR pipeline (single-class training data).\n"
          ]
        }
      ],
      "source": [
        "# -----------------\n",
        "# Main\n",
        "# -----------------\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--grid\", action=\"store_true\", help=\"(unused here)\")\n",
        "    parser.add_argument(\"--adv-train-eps\", type=float, default=0.0)\n",
        "    parser.add_argument(\"--adv-train-frac\", type=float, default=0.3)\n",
        "    parser.add_argument(\"--cic-calib\", type=str, choices=[\"temperature\",\"isotonic\"], default=\"temperature\")\n",
        "    parser.add_argument(\"--automap-min\", type=int, default=5, help=\"Minimum shared features for cross-domain metrics\")\n",
        "    parser.add_argument(\"--no-cic-tiny-slice\", action=\"store_true\", help=\"Disable the CIC tiny benign slice experiment (enabled by default).\")\n",
        "    parser.add_argument(\"--cic-slice-frac\", type=float, default=0.015, help=\"Fraction of CIC_test benign to use for training+calibration (default 1.5%).\")\n",
        "    parser.add_argument(\"--cic-slice-seed\", type=int, default=42, help=\"Random seed for benign-slice sampling.\")\n",
        "    parser.add_argument(\"--zip\", action=\"store_true\", help=\"Also compress outputs to a ZIP bundle.\")\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    outdir = CFG[\"paths\"][\"outdir\"]\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    os.makedirs(get_run_dir(outdir), exist_ok=True)\n",
        "\n",
        "    nf_df, nf_feats, nf_bin_col, nf_mc_col = load_dataset(CFG[\"paths\"][\"nf_csv\"])\n",
        "    cic_tr_df, cic_tr_feats, cic_tr_bin_col, cic_tr_mc_col = load_dataset(CFG[\"paths\"][\"cic_train_csv\"])\n",
        "    cic_te_df, cic_te_feats, cic_te_bin_col, cic_te_mc_col = load_dataset(CFG[\"paths\"][\"cic_test_csv\"])\n",
        "\n",
        "    with open(os.path.join(outdir, \"hyperparams.json\"), \"w\") as f:\n",
        "        json.dump({\n",
        "            \"random_state\": CFG[\"train\"][\"random_state\"],\n",
        "            \"use_smote\": CFG[\"train\"][\"use_smote\"],\n",
        "            \"mlp_hidden_units\": CFG[\"train\"][\"mlp_hidden_units\"],\n",
        "            \"max_epochs\": CFG[\"train\"][\"max_epochs\"],\n",
        "            \"batch_size\": CFG[\"train\"][\"batch_size\"],\n",
        "            \"target_drs\": CFG[\"metrics\"][\"target_drs\"],\n",
        "            \"robust_eps\": CFG[\"robust\"][\"eps\"],\n",
        "            \"pgd_steps\": CFG[\"robust\"][\"pgd_steps\"],\n",
        "            \"pgd_alpha\": CFG[\"robust\"][\"pgd_alpha\"],\n",
        "            \"cic_calib_frac\": CFG[\"calibration\"][\"cic_calib_frac\"],\n",
        "            \"cic_calib_method\": args.cic_calib,\n",
        "            \"automap_min\": args.automap_min,\n",
        "            \"automap_threshold\": CFG[\"automap\"][\"similarity_threshold\"],\n",
        "            \"automap_max_pairs\": CFG[\"automap\"][\"max_pairs\"],\n",
        "            \"cic_slice_frac\": args.cic_slice_frac,\n",
        "            \"cic_slice_seed\": args.cic_slice_seed\n",
        "        }, f, indent=2)\n",
        "\n",
        "    run_in_domain_nf(nf_df, nf_feats, nf_bin_col, nf_mc_col, outdir)\n",
        "\n",
        "    if cic_tr_mc_col and cic_te_mc_col:\n",
        "        run_in_domain_cic_native_mc(cic_tr_df, cic_tr_feats, cic_tr_mc_col,\n",
        "                                    cic_te_df, cic_te_feats, cic_te_mc_col, outdir)\n",
        "        run_in_domain_cic_collapsed(cic_tr_df, cic_tr_feats, cic_tr_mc_col,\n",
        "                                    cic_te_df, cic_te_feats, cic_te_mc_col, outdir, calib_method=args.cic_calib)\n",
        "\n",
        "    if not args.no_cic_tiny_slice:\n",
        "        run_cic_with_tiny_benign_slice(\n",
        "            cic_tr_df, cic_tr_feats, cic_tr_bin_col, cic_tr_mc_col,\n",
        "            cic_te_df, cic_te_feats, cic_te_bin_col, cic_te_mc_col,\n",
        "            outdir, slice_frac=args.cic_slice_frac, seed=args.cic_slice_seed\n",
        "        )\n",
        "\n",
        "    run_cross_domain(nf_df, nf_feats, nf_bin_col, nf_mc_col,\n",
        "                     cic_tr_df, cic_tr_feats, cic_tr_bin_col, cic_tr_mc_col,\n",
        "                     cic_te_df, cic_te_feats, cic_te_bin_col, cic_te_mc_col,\n",
        "                     outdir, automap_min=args.automap_min)\n",
        "\n",
        "    if args.zip:\n",
        "        zip_path = os.path.join(Path(outdir).parent, \"outputs_bundle.zip\")\n",
        "        zip_outputs(outdir, zip_path)\n",
        "        print(f\"[OK] Wrote ZIP bundle → {zip_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "11VAH40xJCy_3sls1Kqj7W8CD48J0RPNR",
      "authorship_tag": "ABX9TyNxATx5Z270cQVf5dVpIwEg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}