{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM+ULyBjxvtkmpqvQ8Sarrq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankeawthong/Project-1-Lita-Chatbot/blob/main/%5B20250213%5D%20Implementing%20PGD%20Adversarial%20on%20UNSW-NB15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hybrid model With PGD adversarial training**"
      ],
      "metadata": {
        "id": "w6h_hLDrlaJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y foolbox\n",
        "!pip uninstall -y foolbox-native"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnHmTXzglfc1",
        "outputId": "897757fc-4445-423e-851a-f582120757a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping foolbox as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping foolbox-native as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install foolbox==3.3.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDFmxsGQl3vV",
        "outputId": "02f505fc-59fa-4612-cf1b-37dddc894a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting foolbox==3.3.3\n",
            "  Downloading foolbox-3.3.3-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (1.13.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (75.1.0)\n",
            "Collecting eagerpy>=0.30.0 (from foolbox==3.3.3)\n",
            "  Downloading eagerpy-0.30.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: GitPython>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (3.1.44)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.11/dist-packages (from foolbox==3.3.3) (2.32.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython>=3.0.7->foolbox==3.3.3) (4.0.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox==3.3.3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox==3.3.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox==3.3.3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox==3.3.3) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox==3.3.3) (5.0.2)\n",
            "Downloading foolbox-3.3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eagerpy-0.30.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: eagerpy, foolbox\n",
            "Successfully installed eagerpy-0.30.0 foolbox-3.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üîπ Step 1: Data Preprocessing (Save to File)**"
      ],
      "metadata": {
        "id": "j-XUfK6Gl78X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "#import foolbox as fb  # For CW and PGD attacks"
      ],
      "metadata": {
        "id": "Jl-Fr6QIl3sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load and preprocess dataset ---\n",
        "dataset = pd.read_csv(\"Dataset_10Classes.csv\").dropna()\n",
        "for column in dataset.columns:\n",
        "    if dataset[column].dtype == 'object':\n",
        "        dataset[column] = LabelEncoder().fit_transform(dataset[column])\n",
        "X = dataset.drop(['Class'], axis=1)\n",
        "y = dataset['Class']"
      ],
      "metadata": {
        "id": "IgguXaphl3p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Class Distribution:\", np.bincount(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLSrCwnmmVdG",
        "outputId": "2c6e437a-4bd6-47f7-a971-e91819f867a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Class Distribution: [93000  2677  2329 16353 44525 24246 58871 13987  1511   174]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "7FKxlc08l3nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SMOTE for class balance\n",
        "smote = SMOTE(random_state=42)\n",
        "X, y = smote.fit_resample(X, y)\n",
        "# Verify the balanced dataset distribution\n",
        "print(\"Balanced Class Distribution:\", np.bincount(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZk3HjOGl3km",
        "outputId": "8e719ecf-83eb-45e9-9778-7ff5cbd8c48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced Class Distribution: [93000 93000 93000 93000 93000 93000 93000 93000 93000 93000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# ‚úÖ Save preprocessed data\n",
        "with open(\"preprocessed_data.pkl\", \"wb\") as f:\n",
        "    pickle.dump((X, y), f)\n",
        "\n",
        "print(\"‚úÖ Preprocessed data saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX-H2ysnmlLg",
        "outputId": "05882fd9-ecf3-4756-f92d-9b2fde74ebdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Preprocessed data saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# ‚úÖ Load preprocessed data\n",
        "with open(\"preprocessed_data.pkl\", \"rb\") as f:\n",
        "    X, y = pickle.load(f)\n",
        "\n",
        "# ‚úÖ Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# ‚úÖ Train Logistic Regression for Feature Extraction\n",
        "lr_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=500, random_state=42)\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# ‚úÖ Extract probabilities for BiLSTM\n",
        "train_lr_features = lr_model.predict_proba(X_train)\n",
        "test_lr_features = lr_model.predict_proba(X_test)\n",
        "train_lr_features = np.expand_dims(train_lr_features, axis=1)\n",
        "test_lr_features = np.expand_dims(test_lr_features, axis=1)\n",
        "\n",
        "# ‚úÖ One-hot encode labels\n",
        "num_classes = len(np.unique(y))\n",
        "y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "# ‚úÖ Save features\n",
        "with open(\"lr_features.pkl\", \"wb\") as f:\n",
        "    pickle.dump((train_lr_features, test_lr_features, y_train_encoded, y_test_encoded), f)\n",
        "\n",
        "print(\"‚úÖ Logistic Regression features saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7tbthOLmAbk",
        "outputId": "c779b0fc-8a18-4be1-c4da-8f92990eff95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Logistic Regression features saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üîπ Step 3: Hybrid LR-BiLSTM Training**"
      ],
      "metadata": {
        "id": "HMQIvbp2m1UK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, Dropout, Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import pickle\n",
        "\n",
        "# ‚úÖ Load Logistic Regression features\n",
        "with open(\"lr_features.pkl\", \"rb\") as f:\n",
        "    train_lr_features, test_lr_features, y_train_encoded, y_test_encoded = pickle.load(f)\n",
        "\n",
        "# ‚úÖ Define BiLSTM Model\n",
        "bilstm_model = Sequential([\n",
        "    Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer=l2(0.0001)), input_shape=(1, train_lr_features.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    Bidirectional(LSTM(32, kernel_regularizer=l2(0.0001))),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_train_encoded.shape[1], activation=\"softmax\")\n",
        "])\n",
        "bilstm_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# ‚úÖ Train model\n",
        "bilstm_model.fit(train_lr_features, y_train_encoded, validation_split=0.2, epochs=25, batch_size=64, verbose=1)\n",
        "\n",
        "# ‚úÖ Save trained model\n",
        "bilstm_model.save(\"bilstm_model.h5\")\n",
        "print(\"‚úÖ BiLSTM Model saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT3D9GowmAZC",
        "outputId": "bb092c16-3e7f-4426-d7f1-1e3e6626ab43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - accuracy: 0.9925 - loss: 0.1702 - val_accuracy: 0.9999 - val_loss: 0.0035\n",
            "Epoch 2/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0031 - val_accuracy: 0.9999 - val_loss: 0.0017\n",
            "Epoch 3/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9999 - val_loss: 0.0013\n",
            "Epoch 4/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 5/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 6/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9999 - val_loss: 0.0013\n",
            "Epoch 7/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
            "Epoch 8/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.8183e-04 - val_accuracy: 0.9999 - val_loss: 9.8826e-04\n",
            "Epoch 9/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 8.0409e-04\n",
            "Epoch 10/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.4570e-04 - val_accuracy: 0.9999 - val_loss: 9.7380e-04\n",
            "Epoch 11/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.8864e-04 - val_accuracy: 0.9999 - val_loss: 0.0011\n",
            "Epoch 12/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9999 - val_loss: 7.5276e-04\n",
            "Epoch 13/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 9.4330e-04 - val_accuracy: 0.9999 - val_loss: 9.6358e-04\n",
            "Epoch 14/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 7.8887e-04\n",
            "Epoch 15/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 9.5586e-04 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 16/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 8.3918e-04\n",
            "Epoch 17/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 9.9184e-04\n",
            "Epoch 18/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 19/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9999 - val_loss: 0.0012\n",
            "Epoch 20/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
            "Epoch 21/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 8.7407e-04\n",
            "Epoch 22/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0014 - val_accuracy: 0.9999 - val_loss: 0.0013\n",
            "Epoch 23/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.1988e-04 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 24/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9999 - val_loss: 8.3442e-04\n",
            "Epoch 25/25\n",
            "\u001b[1m9300/9300\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.9999 - val_loss: 9.0821e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ BiLSTM Model saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üî∏ PGD & FGSM Adversarial Training**"
      ],
      "metadata": {
        "id": "jFvTLNURnDuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import foolbox as fb\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# ‚úÖ Load the trained BiLSTM model\n",
        "bilstm_model = tf.keras.models.load_model(\"bilstm_model.h5\")\n",
        "\n",
        "# ‚úÖ Convert model to Foolbox format\n",
        "fmodel = fb.TensorFlowModel(bilstm_model, bounds=(0, 1))\n",
        "\n",
        "# ‚úÖ Generate PGD Adversarial Examples (for evaluation)\n",
        "def generate_pgd_examples(attack, X_test, y_test, eps=0.02, steps=10, batch_size=1024):\n",
        "    \"\"\"\n",
        "    Generate PGD adversarial examples in batches for efficient computation.\n",
        "    \"\"\"\n",
        "    num_samples = X_test.shape[0]\n",
        "    adv_examples = []\n",
        "\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        batch_X = X_test[i:i + batch_size]\n",
        "        batch_y = np.argmax(y_test[i:i + batch_size], axis=1)\n",
        "\n",
        "        # Convert batch to TensorFlow tensor\n",
        "        batch_X_tf = tf.convert_to_tensor(batch_X, dtype=tf.float32)\n",
        "\n",
        "        # Generate adversarial examples using PGD\n",
        "        adv_batch, *_ = attack(fmodel, batch_X_tf, batch_y, epsilons=eps)\n",
        "        adv_examples.append(adv_batch.numpy())\n",
        "\n",
        "    return np.vstack(adv_examples)\n",
        "\n",
        "# ‚úÖ Define PGD Attack (More Steps for Stronger Perturbation)\n",
        "attack_pgd = fb.attacks.LinfPGD(steps=10)\n",
        "\n",
        "# ‚úÖ Generate Adversarial PGD Samples\n",
        "print(\"\\nüîπ Generating PGD Adversarial Examples for Model Evaluation...\")\n",
        "adv_pgd_test = generate_pgd_examples(attack_pgd, test_lr_features, y_test_encoded, eps=0.02, steps=10)\n",
        "\n",
        "# ‚úÖ Evaluate the model against PGD adversarial examples\n",
        "print(\"\\nüîπ Evaluating Model Performance on PGD Attacks...\")\n",
        "pgd_predictions = bilstm_model.predict(adv_pgd_test)\n",
        "pgd_predictions_labels = np.argmax(pgd_predictions, axis=1)\n",
        "true_labels = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# ‚úÖ Compute Performance Metrics\n",
        "pgd_accuracy = accuracy_score(true_labels, pgd_predictions_labels)\n",
        "pgd_precision = precision_score(true_labels, pgd_predictions_labels, average='macro')\n",
        "pgd_recall = recall_score(true_labels, pgd_predictions_labels, average='macro')\n",
        "pgd_f1 = f1_score(true_labels, pgd_predictions_labels, average='macro')\n",
        "\n",
        "print(\"\\nüîπ Hybrid Model Performance Against PGD Attacks:\")\n",
        "print(\"‚úÖ Accuracy:\", pgd_accuracy)\n",
        "print(\"‚úÖ Precision:\", pgd_precision)\n",
        "print(\"‚úÖ Recall:\", pgd_recall)\n",
        "print(\"‚úÖ F1-Score:\", pgd_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53DEH1dmnH8f",
        "outputId": "31acfbe2-4f6e-4dc3-e54a-b2fcee909f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/foolbox/models/tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ Generating PGD Adversarial Examples for Model Evaluation...\n",
            "\n",
            "üîπ Evaluating Model Performance on PGD Attacks...\n",
            "\u001b[1m5813/5813\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step\n",
            "\n",
            "üîπ Hybrid Model Performance Against PGD Attacks:\n",
            "‚úÖ Accuracy: 0.9999139784946236\n",
            "‚úÖ Precision: 0.9999140044997159\n",
            "‚úÖ Recall: 0.9999139784946237\n",
            "‚úÖ F1-Score: 0.999913973286192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Display detection rate (DR) of the Hybrid Model Performance Against PGD Attacks:\n",
        "\n",
        "# Detection Rate (Recall for each class) against PGD attacks\n",
        "pgd_detection_rate = recall_score(true_labels, pgd_predictions_labels, average=None)\n",
        "for i in range(len(pgd_detection_rate)):\n",
        "    print(f\"Detection Rate for Class {i} against PGD attacks: {pgd_detection_rate[i]:.10f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvvrkhvustxN",
        "outputId": "ae8cdc73-c71f-4e48-9d0d-ca4a16d31c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detection Rate for Class 0 against PGD attacks: 1.0000000000\n",
            "Detection Rate for Class 1 against PGD attacks: 1.0000000000\n",
            "Detection Rate for Class 2 against PGD attacks: 0.9999462366\n",
            "Detection Rate for Class 3 against PGD attacks: 1.0000000000\n",
            "Detection Rate for Class 4 against PGD attacks: 1.0000000000\n",
            "Detection Rate for Class 5 against PGD attacks: 0.9998924731\n",
            "Detection Rate for Class 6 against PGD attacks: 0.9993010753\n",
            "Detection Rate for Class 7 against PGD attacks: 1.0000000000\n",
            "Detection Rate for Class 8 against PGD attacks: 1.0000000000\n",
            "Detection Rate for Class 9 against PGD attacks: 1.0000000000\n"
          ]
        }
      ]
    }
  ]
}