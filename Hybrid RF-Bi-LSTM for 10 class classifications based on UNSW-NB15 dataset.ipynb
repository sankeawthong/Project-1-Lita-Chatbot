{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5JHk6Pc9wA44mCyHfFJrX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankeawthong/Project-1-Lita-Chatbot/blob/main/Hybrid%20RF-Bi-LSTM%20for%2010%20class%20classifications%20based%20on%20UNSW-NB15%20dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hybrid RF-Bi-LSTM for 10 class classifications based on UNSW-NB15 dataset**"
      ],
      "metadata": {
        "id": "1ADTD_VYltRD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vzTFXlW7K_OU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Bidirectional, LSTM\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "dataset = pd.read_csv(\"dataset_P2.2.csv\")\n",
        "dataset.shape\n",
        "dataset.isnull().sum()\n",
        "dataset.info()\n",
        "dataset[\"Class\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvfyJxSwLA5W",
        "outputId": "eaeb42bd-c5ce-45a3-f8ff-ac5e87853903"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 175341 entries, 0 to 175340\n",
            "Data columns (total 41 columns):\n",
            " #   Column             Non-Null Count   Dtype  \n",
            "---  ------             --------------   -----  \n",
            " 0   id                 175341 non-null  int64  \n",
            " 1   dur                175341 non-null  float64\n",
            " 2   spkts              175341 non-null  int64  \n",
            " 3   dpkts              175341 non-null  int64  \n",
            " 4   sbytes             175341 non-null  int64  \n",
            " 5   dbytes             175341 non-null  int64  \n",
            " 6   rate               175341 non-null  float64\n",
            " 7   sttl               175341 non-null  int64  \n",
            " 8   dttl               175341 non-null  int64  \n",
            " 9   sload              175341 non-null  float64\n",
            " 10  dload              175341 non-null  float64\n",
            " 11  sloss              175341 non-null  int64  \n",
            " 12  dloss              175341 non-null  int64  \n",
            " 13  sinpkt             175341 non-null  float64\n",
            " 14  dinpkt             175341 non-null  float64\n",
            " 15  sjit               175341 non-null  float64\n",
            " 16  djit               175341 non-null  float64\n",
            " 17  swin               175341 non-null  int64  \n",
            " 18  stcpb              175341 non-null  int64  \n",
            " 19  dtcpb              175341 non-null  int64  \n",
            " 20  dwin               175341 non-null  int64  \n",
            " 21  tcprtt             175341 non-null  float64\n",
            " 22  synack             175341 non-null  float64\n",
            " 23  ackdat             175341 non-null  float64\n",
            " 24  smean              175341 non-null  int64  \n",
            " 25  dmean              175341 non-null  int64  \n",
            " 26  trans_depth        175341 non-null  int64  \n",
            " 27  response_body_len  175341 non-null  int64  \n",
            " 28  ct_srv_src         175341 non-null  int64  \n",
            " 29  ct_state_ttl       175341 non-null  int64  \n",
            " 30  ct_dst_ltm         175341 non-null  int64  \n",
            " 31  ct_src_dport_ltm   175341 non-null  int64  \n",
            " 32  ct_dst_sport_ltm   175341 non-null  int64  \n",
            " 33  ct_dst_src_ltm     175341 non-null  int64  \n",
            " 34  is_ftp_login       175341 non-null  int64  \n",
            " 35  ct_ftp_cmd         175341 non-null  int64  \n",
            " 36  ct_flw_http_mthd   175341 non-null  int64  \n",
            " 37  ct_src_ltm         175341 non-null  int64  \n",
            " 38  ct_srv_dst         175341 non-null  int64  \n",
            " 39  is_sm_ips_ports    175341 non-null  int64  \n",
            " 40  Class              175341 non-null  int64  \n",
            "dtypes: float64(11), int64(30)\n",
            "memory usage: 54.8 MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 1, 5, 8, 7, 4, 3, 9, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "y = dataset['Class'].values\n",
        "X = dataset.drop(['Class'], axis=1)\n",
        "X = X.values"
      ],
      "metadata": {
        "id": "UDf1gjOiLA1r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data balancing using SMOTE\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "psoosYdrLAp2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the data for LSTM\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)"
      ],
      "metadata": {
        "id": "GrPpSXPTLEAW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "NForYrobLD9U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train.reshape(X_train.shape[0], -1), y_train)  # Reshape X_train to 2D\n",
        "\n",
        "y_pred_rf = rf_model.predict(X_test.reshape(X_test.shape[0], -1))  # Reshape X_test to 2D\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calculate accuracy for Random Forest model\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Random Forest Accuracy:\", accuracy_rf)\n",
        "\n",
        "# Evaluate Random Forest model\n",
        "rf_report = classification_report(y_test, y_pred_rf)\n",
        "print(\"Random Forest Model Classification Report:\")\n",
        "print(rf_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R32sT9L3LD5v",
        "outputId": "a7eb17fc-9f45-4bcf-9f82-e52f0eada75e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.8667857142857143\n",
            "Random Forest Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98     11176\n",
            "           1       0.76      0.81      0.79     11344\n",
            "           2       0.74      0.84      0.79     11130\n",
            "           3       0.63      0.59      0.61     11037\n",
            "           4       0.78      0.74      0.76     11263\n",
            "           5       0.92      0.91      0.91     11308\n",
            "           6       1.00      0.98      0.99     11179\n",
            "           7       0.90      0.83      0.87     11358\n",
            "           8       0.96      1.00      0.98     11137\n",
            "           9       1.00      1.00      1.00     11068\n",
            "\n",
            "    accuracy                           0.87    112000\n",
            "   macro avg       0.87      0.87      0.87    112000\n",
            "weighted avg       0.87      0.87      0.87    112000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "# Bi-LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(X_train.shape[1], 1)))\n",
        "lstm_model.add(Dropout(0.2))\n",
        "lstm_model.add(Bidirectional(LSTM(64)))\n",
        "lstm_model.add(Dropout(0.2))\n",
        "lstm_model.add(Dense(10, activation='softmax'))\n",
        "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "lstm_model.summary()\n",
        "\n",
        "# Convert labels to one-hot encoded vectors\n",
        "num_classes = len(np.unique(y))\n",
        "y_train_encoded = to_categorical(y_train, num_classes)\n",
        "y_test_encoded = to_categorical(y_test, num_classes)\n",
        "\n",
        "lstm_model.fit(X_train, y_train_encoded, epochs=10, batch_size=64, validation_data=(X_test, y_test_encoded), verbose=1)\n",
        "\n",
        "##y_pred_lstm = lstm_model.predict_classes(X_test)\n",
        "y_pred_lstm_prob = lstm_model.predict(X_test)\n",
        "y_pred_lstm = np.argmax(y_pred_lstm_prob, axis=1)\n",
        "\n",
        "# Calculate accuracy for Bi-LSTM model\n",
        "accuracy_lstm = accuracy_score(y_test, y_pred_lstm)\n",
        "print(\"Bi-LSTM Accuracy:\", accuracy_lstm)\n",
        "\n",
        "# Evaluate Bi-LSTM model\n",
        "lstm_report = classification_report(y_test, y_pred_lstm)\n",
        "print(\"Bi-LSTM Model Classification Report:\")\n",
        "print(lstm_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kksQBexMk18",
        "outputId": "37164d4b-e913-4207-b78b-4151df120e94"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 40, 128)          33792     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,898\n",
            "Trainable params: 133,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "7000/7000 [==============================] - 1119s 159ms/step - loss: 0.9133 - accuracy: 0.6484 - val_loss: 0.7685 - val_accuracy: 0.6957\n",
            "Epoch 2/10\n",
            "7000/7000 [==============================] - 1111s 159ms/step - loss: 0.7756 - accuracy: 0.6923 - val_loss: 0.7327 - val_accuracy: 0.7080\n",
            "Epoch 3/10\n",
            "7000/7000 [==============================] - 1110s 159ms/step - loss: 0.7356 - accuracy: 0.7056 - val_loss: 0.7068 - val_accuracy: 0.7130\n",
            "Epoch 4/10\n",
            "7000/7000 [==============================] - 1107s 158ms/step - loss: 0.7147 - accuracy: 0.7120 - val_loss: 0.6934 - val_accuracy: 0.7194\n",
            "Epoch 5/10\n",
            "7000/7000 [==============================] - 1108s 158ms/step - loss: 0.7006 - accuracy: 0.7168 - val_loss: 0.6799 - val_accuracy: 0.7208\n",
            "Epoch 6/10\n",
            "7000/7000 [==============================] - 1109s 158ms/step - loss: 0.6855 - accuracy: 0.7220 - val_loss: 0.6751 - val_accuracy: 0.7233\n",
            "Epoch 7/10\n",
            "7000/7000 [==============================] - 1107s 158ms/step - loss: 0.6786 - accuracy: 0.7237 - val_loss: 0.6553 - val_accuracy: 0.7309\n",
            "Epoch 8/10\n",
            "7000/7000 [==============================] - 1109s 158ms/step - loss: 0.6682 - accuracy: 0.7278 - val_loss: 0.6561 - val_accuracy: 0.7319\n",
            "Epoch 9/10\n",
            "7000/7000 [==============================] - 1098s 157ms/step - loss: 0.6638 - accuracy: 0.7300 - val_loss: 0.6512 - val_accuracy: 0.7320\n",
            "Epoch 10/10\n",
            "7000/7000 [==============================] - 1074s 153ms/step - loss: 0.6586 - accuracy: 0.7315 - val_loss: 0.6504 - val_accuracy: 0.7331\n",
            "3500/3500 [==============================] - 93s 26ms/step\n",
            "Bi-LSTM Accuracy: 0.7330892857142857\n",
            "Bi-LSTM Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.82      0.89     11176\n",
            "           1       0.42      0.65      0.51     11344\n",
            "           2       0.57      0.34      0.43     11130\n",
            "           3       0.35      0.48      0.40     11037\n",
            "           4       0.75      0.49      0.59     11263\n",
            "           5       0.83      0.86      0.84     11308\n",
            "           6       1.00      0.98      0.99     11179\n",
            "           7       0.90      0.79      0.84     11358\n",
            "           8       0.88      0.95      0.92     11137\n",
            "           9       0.96      0.98      0.97     11068\n",
            "\n",
            "    accuracy                           0.73    112000\n",
            "   macro avg       0.76      0.73      0.74    112000\n",
            "weighted avg       0.76      0.73      0.74    112000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine Random Forest and Bi-LSTM predictions\n",
        "combined_pred = np.concatenate((y_pred_rf.reshape(-1, 1), y_pred_lstm.reshape(-1, 1)), axis=1)\n",
        "y_pred_combined = [np.bincount(row).argmax() for row in combined_pred]\n",
        "\n",
        "# Calculate accuracy for the combined model\n",
        "accuracy_combined = accuracy_score(y_test, y_pred_combined)\n",
        "print(\"Combined Model Accuracy:\", accuracy_combined)\n",
        "\n",
        "# Evaluate the combined model\n",
        "combined_report = classification_report(y_test, y_pred_combined)\n",
        "print(\"Combined Model Classification Report:\")\n",
        "print(combined_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwmRMx8XMuNI",
        "outputId": "4fdd5fe3-f8c1-4e7d-a4a0-f2e7849dd2cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Model Accuracy: 0.8\n",
            "Combined Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97     11176\n",
            "           1       0.48      0.90      0.62     11344\n",
            "           2       0.69      0.55      0.61     11130\n",
            "           3       0.51      0.48      0.49     11037\n",
            "           4       0.83      0.52      0.64     11263\n",
            "           5       0.94      0.87      0.90     11308\n",
            "           6       1.00      0.98      0.99     11179\n",
            "           7       0.93      0.79      0.86     11358\n",
            "           8       0.95      0.96      0.96     11137\n",
            "           9       1.00      0.98      0.99     11068\n",
            "\n",
            "    accuracy                           0.80    112000\n",
            "   macro avg       0.83      0.80      0.80    112000\n",
            "weighted avg       0.83      0.80      0.80    112000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}