{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMFyQzgA8BAHljdEf7CBr8D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankeawthong/Project-1-Lita-Chatbot/blob/main/%5BAdditional_20251226%5D%20TrustFed-IDS%E2%80%93WSN-BFSF%20(SMOTE-balanced%20clients%20%2B%20C-focal%20loss).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TrustFed-IDS – WSN-BFSF (SMOTE-balanced clients + C-focal loss) with CM"
      ],
      "metadata": {
        "id": "7pYH_WBXYB4y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUVKiYsDX95V"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# ----------------------------------------------------------------------\n",
        "#    TrustFed-IDS  –  WSN-BFSF   (SMOTE-balanced clients + C-focal loss)\n",
        "# ----------------------------------------------------------------------\n",
        "import os, time, psutil, warnings, numpy as np, pandas as pd, tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (accuracy_score, precision_score,\n",
        "                             recall_score, f1_score, confusion_matrix)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.spatial.distance import cosine\n",
        "import seaborn as sns, matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------- CONFIG ---------------------------------\n",
        "SEED               = 40\n",
        "NUM_CLIENTS        = 5\n",
        "ROUNDS             = 75         # cut-down run (≈15-20 min on Colab T4)\n",
        "LOCAL_EPOCHS       = 1\n",
        "BATCH_SIZE         = 32\n",
        "DIRICHLET_ALPHA    = 0.5\n",
        "HISTORY_KEEP       = 6\n",
        "TRUST_ALPHA        = (0.30, 0.55, 0.15)   # similarity, loss, stability\n",
        "TRUST_CLIP         = (0.05, 0.60)\n",
        "DATA_PATH          = \"dataset.csv\" # <- use your cleaned CSV here\n",
        "LOG_DIR            = \"/mnt/data\"\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "np.random.seed(SEED); tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "wD1OaivHYHxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- 1. GLOBAL LOAD + STANDARDISE --------------------------\n",
        "df = pd.read_csv(DATA_PATH).dropna()\n",
        "for col in df.select_dtypes(include=\"object\"):\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "X = df.drop(\"Class\", axis=1).astype(\"float32\").values\n",
        "y = df[\"Class\"].astype(\"int64\").values\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=SEED)\n",
        "\n",
        "scaler = StandardScaler().fit(X_tr)\n",
        "X_tr, X_te = scaler.transform(X_tr), scaler.transform(X_te)\n",
        "\n",
        "n_classes = int(y_tr.max() + 1)\n",
        "INPUT_SHAPE = (X_tr.shape[1], 1)\n",
        "\n",
        "# ---------------- 2. NON-IID PARTITION  ---------------------------------\n",
        "def dirichlet_split(X, y, k, alpha, rng):\n",
        "    idx_by_cls = {c: rng.permutation(np.where(y == c)[0]) for c in np.unique(y)}\n",
        "    client_idx = [[] for _ in range(k)]\n",
        "    for c, idx in idx_by_cls.items():\n",
        "        parts = (rng.dirichlet([alpha] * k) * len(idx)).astype(int)\n",
        "        while parts.sum() < len(idx): parts[rng.randint(0, k)] += 1\n",
        "        start = 0\n",
        "        for cid, cnt in enumerate(parts):\n",
        "            client_idx[cid].extend(idx[start:start + cnt]); start += cnt\n",
        "    for lst in client_idx: rng.shuffle(lst)\n",
        "    return [X[l] for l in client_idx], [y[l] for l in client_idx]\n",
        "\n",
        "rng = np.random.RandomState(SEED)\n",
        "c_X_raw, c_y_raw = dirichlet_split(X_tr, y_tr, NUM_CLIENTS,\n",
        "                                   DIRICHLET_ALPHA, rng)\n",
        "\n",
        "# ------------- 2a. ★ SMOTE PER-CLIENT BALANCING ★ -----------------------\n",
        "client_X, client_y = [], []\n",
        "for cid, (Xi, yi) in enumerate(zip(c_X_raw, c_y_raw)):\n",
        "    try:\n",
        "        Xi, yi = SMOTE(random_state=SEED).fit_resample(Xi, yi)\n",
        "        print(f\"[CID {cid}] SMOTE → {len(Xi):,} samples.\")\n",
        "    except ValueError as e:                      # too few minority points\n",
        "        print(f\"[CID {cid}] SMOTE skipped ({e}); using raw data.\")\n",
        "    client_X.append(Xi[..., None])               # add channel dim\n",
        "    client_y.append(to_categorical(yi, n_classes))\n",
        "\n",
        "X_te = X_te[..., None]\n",
        "y_te_cat = to_categorical(y_te, n_classes)"
      ],
      "metadata": {
        "id": "ipBl1MiaYHf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- 3. MODEL BUILDER --------------------------------------\n",
        "def build_model(inp_shape=INPUT_SHAPE, classes=n_classes):\n",
        "    m = Sequential([\n",
        "        InputLayer(shape=inp_shape),\n",
        "        LSTM(128, return_sequences=True, activation='tanh',\n",
        "             kernel_regularizer=l2(5e-4)),\n",
        "        LSTM(64, activation='tanh', kernel_regularizer=l2(5e-4)),\n",
        "        Dense(256, activation='relu'), Dropout(0.20),\n",
        "        Dense(128, activation='relu'), Dropout(0.25),\n",
        "        Dense(classes, activation='softmax')\n",
        "    ])\n",
        "    lr = CosineDecay(5e-4, decay_steps=ROUNDS, alpha=0.4)\n",
        "    m.compile(tf.keras.optimizers.Nadam(lr, clipnorm=2.0),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return m\n",
        "\n",
        "# ---------------- 4. TRUST HELPERS --------------------------------------\n",
        "def weight_delta(local, global_):\n",
        "    return [l - g for l, g in zip(local, global_)]\n",
        "\n",
        "def vec_cos(a, b):\n",
        "    f1 = np.concatenate([w.ravel() for w in a])\n",
        "    f2 = np.concatenate([w.ravel() for w in b])\n",
        "    if np.all(f1 == 0) or np.all(f2 == 0): return 0.0\n",
        "    return 1 - cosine(f1, f2)\n",
        "\n",
        "def stability(u, hist):\n",
        "    if len(hist) < 2: return 1.0\n",
        "    return float(np.mean([vec_cos(u, h) for h in hist[-HISTORY_KEEP:]]))\n",
        "\n",
        "def compute_trust(upd, vloss, hist):\n",
        "    lo, hi = min(vloss.values()), max(vloss.values())\n",
        "    raw = {cid: (TRUST_ALPHA[0] * vec_cos(u, [np.zeros_like(w) for w in u]) +\n",
        "                 TRUST_ALPHA[1] * (1 - (vloss[cid] - lo) / (hi - lo + 1e-8)) +\n",
        "                 TRUST_ALPHA[2] * stability(u, hist[cid]))\n",
        "           for cid, u in upd.items()}\n",
        "    clipped = {cid: np.clip(s, *TRUST_CLIP) for cid, s in raw.items()}\n",
        "    Z = sum(clipped.values())\n",
        "    return {cid: s / Z for cid, s in clipped.items()}\n",
        "\n",
        "def aggregate(ws, trust, ns):\n",
        "    tot = sum(trust[c] * ns[c] for c in ws)\n",
        "    return [sum(trust[c] * ns[c] * ws[c][l] for c in ws) / tot\n",
        "            for l in range(len(next(iter(ws.values()))))]\n",
        "\n",
        "# ---------------- 5. INITIALISE -----------------------------------------\n",
        "g_model   = build_model()\n",
        "g_weights = g_model.get_weights()\n",
        "histories = {c: [] for c in range(NUM_CLIENTS)}\n",
        "perf_log, comm_log, trust_log = [], [], []\n",
        "\n",
        "# ---------------- 6. FEDERATED LOOP -------------------------------------\n",
        "for rnd in range(1, ROUNDS + 1):\n",
        "    t0 = time.time()\n",
        "    lw, upd, vloss, ns, bytes_out = {}, {}, {}, {}, 0\n",
        "\n",
        "    for cid in range(NUM_CLIENTS):\n",
        "        n_val = max(1, int(0.15 * len(client_X[cid])))\n",
        "        Xv, yv = client_X[cid][:n_val], client_y[cid][:n_val]\n",
        "        Xt, yt = client_X[cid][n_val:], client_y[cid][n_val:]\n",
        "\n",
        "        local = build_model(); local.set_weights(g_weights)\n",
        "        local.fit(Xt, yt, epochs=LOCAL_EPOCHS,\n",
        "                  batch_size=BATCH_SIZE, verbose=0)\n",
        "\n",
        "        w = local.get_weights()\n",
        "        upd[cid]   = weight_delta(w, g_weights)\n",
        "        vloss[cid] = local.evaluate(Xv, yv, verbose=0)[0]\n",
        "        lw[cid]    = w\n",
        "        ns[cid]    = len(Xt)\n",
        "        histories[cid] = (histories[cid] + [upd[cid]])[-HISTORY_KEEP:]\n",
        "        bytes_out += sum(x.nbytes for x in w)\n",
        "\n",
        "    trust = compute_trust(upd, vloss, histories)\n",
        "    g_weights = aggregate(lw, trust, ns)\n",
        "    g_model.set_weights(g_weights)\n",
        "\n",
        "    y_pred = np.argmax(g_model.predict(X_te, verbose=0), 1)\n",
        "    perf_log.append(dict(round=rnd,\n",
        "                         acc=accuracy_score(y_te, y_pred),\n",
        "                         f1=f1_score(y_te, y_pred, average='weighted'),\n",
        "                         prec=precision_score(y_te, y_pred, average='weighted', zero_division=0),\n",
        "                         rec=recall_score(y_te, y_pred, average='weighted', zero_division=0)))\n",
        "    comm_log.append(dict(round=rnd, MB=bytes_out / 2**20))\n",
        "    trust_log.extend([dict(round=rnd, client=c, trust=trust[c]) for c in trust])\n",
        "\n",
        "    print(f\"R{rnd:02d} acc={perf_log[-1]['acc']:.8f}  \"\n",
        "          f\"F1={perf_log[-1]['f1']:.8f}  \"\n",
        "          f\"Prec={perf_log[-1]['prec']:.8f}  \"\n",
        "          f\"Rec={perf_log[-1]['rec']:.8f}  \"\n",
        "          f\"MB={bytes_out/2**20:.2f}\")"
      ],
      "metadata": {
        "id": "GEtHrCdbkV7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- 7. CONFUSION MATRIX -----------------------------------\n",
        "print(\"\\n✓ Training done – creating confusion matrix …\")\n",
        "cm = confusion_matrix(y_te,\n",
        "                      np.argmax(g_model.predict(X_te, verbose=0), 1))\n",
        "cm_csv = os.path.join(LOG_DIR, \"cm_WSN-BFSF_TrustFed.csv\")\n",
        "np.savetxt(cm_csv, cm, fmt=\"%d\", delimiter=\",\")\n",
        "plt.figure(figsize=(4.5, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=[f\"C{i}\" for i in range(n_classes)],\n",
        "            yticklabels=[f\"C{i}\" for i in range(n_classes)],\n",
        "            linewidths=.5, linecolor='grey')\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix – TrustFed-IDS (WSN-BFSF)\")\n",
        "plt.tight_layout()\n",
        "cm_png = cm_csv.replace(\".csv\", \".png\")\n",
        "plt.savefig(cm_png, dpi=300); plt.close()\n",
        "print(\"• CSV  ⇒\", cm_csv)\n",
        "print(\"• PNG  ⇒\", cm_png)"
      ],
      "metadata": {
        "id": "7uztNnnNYHaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- 8. LOGS -----------------------------------------------\n",
        "pd.DataFrame(perf_log ).to_csv(f\"{LOG_DIR}/perf_log_WSN-BFSF_trust.csv\",   index=False)\n",
        "pd.DataFrame(comm_log ).to_csv(f\"{LOG_DIR}/comm_log_WSN-BFSF_trust.csv\",   index=False)\n",
        "pd.DataFrame(trust_log).to_csv(f\"{LOG_DIR}/trust_log_WSN-BFSF_trust.csv\",  index=False)\n",
        "\n",
        "profile = dict(Params_MB = round(sum(w.nbytes for w in g_weights)/2**20, 3),\n",
        "               Rounds    = ROUNDS,\n",
        "               Clients   = NUM_CLIENTS,\n",
        "               PeakMem_MB= round(psutil.Process(\n",
        "                                os.getpid()).memory_info().rss/2**20, 2))\n",
        "pd.DataFrame([profile]).to_csv(f\"{LOG_DIR}/model_profile_WSN-BFSF_trust.csv\",\n",
        "                               index=False)\n",
        "print(\"\\n✓ All artefacts saved to\", LOG_DIR)"
      ],
      "metadata": {
        "id": "ETb6zRRwYaDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Download log files aboved\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/mnt/data/cm_WSN-BFSF_TrustFed.csv')"
      ],
      "metadata": {
        "id": "_LJoW7YbYlFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('/mnt/data/cm_WSN-BFSF_TrustFed.png')"
      ],
      "metadata": {
        "id": "L7YqgiJQYpEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('/mnt/data/perf_log_WSN-BFSF_trust.csv')"
      ],
      "metadata": {
        "id": "jNE6lOhEYrS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('/mnt/data/comm_log_WSN-BFSF_trust.csv')"
      ],
      "metadata": {
        "id": "VF1aT9DkYvHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('/mnt/data/trust_log_WSN-BFSF_trust.csv')"
      ],
      "metadata": {
        "id": "U5pMvwqFYyqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('/mnt/data/model_profile_WSN-BFSF_trust.csv')"
      ],
      "metadata": {
        "id": "QUGUYlNTY0jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cm(cm, classes, title, normalise=False):\n",
        "    if normalise:\n",
        "        cm = cm / cm.sum(axis=1, keepdims=True)\n",
        "        fmt, cmap = \".2%\", \"Blues\"\n",
        "    else:\n",
        "        fmt, cmap = \"d\", \"Blues\"\n",
        "    sns.heatmap(cm, annot=True, fmt=fmt, cmap=cmap, cbar=False,\n",
        "                xticklabels=classes, yticklabels=classes,\n",
        "                linewidths=.5, linecolor='grey')\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
        "    plt.title(title); plt.tight_layout()\n",
        "\n",
        "plt.figure(figsize=(9,4))\n",
        "plt.subplot(1,2,1); plot_cm(cm,  [f\"C{i}\" for i in range(n_classes)],\n",
        "                            \"Raw counts\", normalise=False)\n",
        "plt.subplot(1,2,2); plot_cm(cm,  [f\"C{i}\" for i in range(n_classes)],\n",
        "                            \"Row-normalised\", normalise=True)\n",
        "plt.savefig(\"/mnt/data/cm_WSN-BFSF_dual.png\", dpi=300)"
      ],
      "metadata": {
        "id": "u9gxta65Y315"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}