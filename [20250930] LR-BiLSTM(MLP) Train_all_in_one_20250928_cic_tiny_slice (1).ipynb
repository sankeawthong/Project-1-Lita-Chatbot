{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankeawthong/Project-1-Lita-Chatbot/blob/main/%5B20250930%5D%20LR-BiLSTM(MLP)%20Train_all_in_one_20250928_cic_tiny_slice%20(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZFzxwK-rfne"
      },
      "source": [
        "train_all_in_one — CIC fixes + tiny benign slice (2025-09-28, v2)\n",
        "\n",
        "Why this version?\n",
        "- Ensures the CIC tiny-slice experiment RUNS BY DEFAULT (no flag needed).\n",
        "- Always writes either the requested output files OR an explicit SKIPPED/ERROR file explaining why.\n",
        "- Keeps your earlier fixes (A–C essential, E recommended) intact.\n",
        "\n",
        "Key outputs from tiny-slice mode (when successful):\n",
        "\n",
        "  • CIC_IoMT__tiny_benign_slice__summary.csv\n",
        "\n",
        "  • CIC_IoMT__tiny_benign_slice__binary_metrics.json\n",
        "\n",
        "  • CIC_IoMT__tiny_benign_slice__Calibrated(isotonic)__binary_metrics.json (+ __meta.json)\n",
        "\n",
        "  • CIC_IoMT__tiny_benign_slice__Calibrated(temperature)__binary_metrics.json (+ __meta.json)\n",
        "\n",
        "And the automapper audit files:\n",
        "\n",
        "  • NF_to_CIC__feature_automap.json, NF_to_CIC_common_features.json\n",
        "\n",
        "  • CIC_to_NF__feature_automap.json, CIC_to_NF_common_features.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t6ACr4K_rYg2"
      },
      "outputs": [],
      "source": [
        "import os, json, argparse, re, difflib, traceback\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline as SkPipeline\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import (accuracy_score, f1_score, classification_report,\n",
        "                             average_precision_score, roc_auc_score, precision_recall_curve,\n",
        "                             confusion_matrix, ConfusionMatrixDisplay)\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R6G_Gn53tueg"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "\n",
        "CFG = {\n",
        "    \"paths\": {\n",
        "        \"nf_csv\": \"/content/Dataset_NF-ToN-IoT.csv\",\n",
        "        \"cic_train_csv\": \"/content/CIC_IoMT_2024_WiFi_MQTT_train.csv\",\n",
        "        \"cic_test_csv\": \"/content/CIC_IoMT_2024_WiFi_MQTT_test.csv\",\n",
        "        \"outdir\": \"/mnt/data/iot_ids_refactor/outputs\"\n",
        "    },\n",
        "    \"label_columns\": {\n",
        "        \"binary_candidates\": [\"Label\", \"label\", \"Binary\", \"binary\"],\n",
        "        \"multiclass_candidates\": [\"Class\", \"class\", \"Category\", \"category\"],\n",
        "        \"drop_non_feature_if_present\": [\"Attack\", \"attack\", \"Label\", \"label\", \"Class\", \"class\"]\n",
        "    },\n",
        "    \"train\": {\n",
        "        \"random_state\": 42,\n",
        "        \"test_size\": 0.2,\n",
        "        \"use_smote\": True,\n",
        "        \"mlp_hidden_units\": 64,\n",
        "        \"max_epochs\": 25,\n",
        "        \"batch_size\": 2048\n",
        "    },\n",
        "    \"metrics\": {\"target_drs\": [0.90, 0.95]},\n",
        "    \"calibration\": {\"cic_calib_frac\": 0.10},\n",
        "    \"robust\": {\"eps\": [0.05, 0.10], \"pgd_steps\": 10, \"pgd_alpha\": 0.02},\n",
        "    # E) loosened defaults\n",
        "    \"automap\": {\"similarity_threshold\": 0.75, \"max_pairs\": 256}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C4wxEtwut4l4"
      },
      "outputs": [],
      "source": [
        "# --------------------------\n",
        "# Canonical feature aliases\n",
        "# --------------------------\n",
        "CANON = {\n",
        "    \"duration\": [\"dur\", \"flow_duration\", \"duration\", \"dur_ms\", \"flowdur\", \"flow_dur\"],\n",
        "    \"tot_fwd_pkts\": [\"Tot Fwd Pkts\", \"tot_fwd_pkts\", \"total_fwd_packets\", \"fwd_pkts_tot\", \"fwd_pkts_total\", \"fwd_packets_total\"],\n",
        "    \"tot_bwd_pkts\": [\"Tot Bwd Pkts\", \"tot_bwd_pkts\", \"total_bwd_packets\", \"bwd_pkts_tot\", \"bwd_pkts_total\", \"bwd_packets_total\"],\n",
        "    \"totlen_fwd_pkts\": [\"TotLen Fwd Pkts\", \"totlen_fwd_pkts\", \"total_length_of_fwd_packets\", \"fwd_pkts_len_tot\", \"fwd_bytes_total\", \"total_fwd_bytes\"],\n",
        "    \"totlen_bwd_pkts\": [\"TotLen Bwd Pkts\", \"totlen_bwd_pkts\", \"total_length_of_bwd_packets\", \"bwd_pkts_len_tot\", \"bwd_bytes_total\", \"total_bwd_bytes\"],\n",
        "    \"fwd_pkt_len_mean\": [\"Fwd Pkt Len Mean\", \"fwd_pkt_len_mean\", \"fwd_packet_length_mean\", \"fwd_pkt_length_mean\"],\n",
        "    \"bwd_pkt_len_mean\": [\"Bwd Pkt Len Mean\", \"bwd_pkt_len_mean\", \"bwd_packet_length_mean\", \"bwd_pkt_length_mean\"],\n",
        "    \"fwd_iat_mean\": [\"Fwd IAT Mean\", \"fwd_iat_mean\", \"fwd_interarrival_mean\", \"fwd_iat_avg\"],\n",
        "    \"bwd_iat_mean\": [\"Bwd IAT Mean\", \"bwd_iat_mean\", \"bwd_interarrival_mean\", \"bwd_iat_avg\"],\n",
        "    \"pkt_len_mean\": [\"Pkt Len Mean\", \"pkt_len_mean\", \"packet_length_mean\", \"pkt_length_mean\"],\n",
        "    \"pkt_len_std\": [\"Pkt Len Std\", \"pkt_len_std\", \"packet_length_std\", \"pkt_length_std\"],\n",
        "    \"flow_pkts_s\": [\"Flow Pkts/s\", \"flow_pkts_s\", \"packets_per_second\", \"pkts_per_sec\", \"pkt_rate\"],\n",
        "    \"flow_byts_s\": [\"Flow Byts/s\", \"flow_byts_s\", \"bytes_per_second\", \"byte_rate\", \"bytes_per_sec\", \"throughput\"],\n",
        "    \"protocol\": [\"Protocol\", \"proto\", \"protocol\", \"protocol_type\", \"l4_proto\"],\n",
        "    \"src_port\": [\"Src Port\", \"src_port\", \"sport\", \"source_port\"],\n",
        "    \"dst_port\": [\"Dst Port\", \"dst_port\", \"dport\", \"destination_port\"],\n",
        "    \"flags\": [\"flags\", \"tcp_flags\", \"flag_count\", \"tcpflag\", \"flag_total\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UdDxObn8EC6u"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Feature utilities\n",
        "# -----------------\n",
        "def build_rename_map(df_cols):\n",
        "    lower = {c.lower(): c for c in df_cols}\n",
        "    rename = {}\n",
        "    for canon, aliases in CANON.items():\n",
        "        for a in aliases:\n",
        "            key = a.lower()\n",
        "            if key in lower:\n",
        "                rename[lower[key]] = canon\n",
        "                break\n",
        "    return rename\n",
        "\n",
        "def normalize_features(df):\n",
        "    rename = build_rename_map(df.columns)\n",
        "    return df.rename(columns=rename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u3aLv3Hh8r9r"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# I/O helpers\n",
        "# -----------------\n",
        "def detect_label_column(df, candidates):\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def pick_features(df, drop_cols):\n",
        "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    feat_cols = [c for c in num_cols if c not in set(drop_cols)]\n",
        "    return feat_cols\n",
        "\n",
        "def load_dataset(path):\n",
        "    df_raw = pd.read_csv(path)\n",
        "    df = normalize_features(df_raw)\n",
        "    bin_col = detect_label_column(df, CFG[\"label_columns\"][\"binary_candidates\"])\n",
        "    mc_col  = detect_label_column(df, CFG[\"label_columns\"][\"multiclass_candidates\"])\n",
        "    feat_cols = pick_features(df, CFG[\"label_columns\"][\"drop_non_feature_if_present\"])\n",
        "    return df, feat_cols, bin_col, mc_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "25dEpkH58umq"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Labels\n",
        "# -----------------\n",
        "def map_label_string_to_family(s: str) -> str:\n",
        "    st = str(s).lower().strip()\n",
        "    if \"benign\" in st or \"normal\" in st:\n",
        "        return \"Benign\"\n",
        "    return \"Attack\"\n",
        "\n",
        "def build_binary_labels(df, bin_col, mc_col):\n",
        "    if bin_col and bin_col in df.columns:\n",
        "        try:\n",
        "            y_bin = df[bin_col].astype(int).values\n",
        "        except ValueError:\n",
        "            y_bin = df[bin_col].apply(lambda x: 0 if map_label_string_to_family(str(x)) == \"Benign\" else 1).values\n",
        "    elif mc_col and mc_col in df.columns:\n",
        "        try:\n",
        "            y_bin = (df[mc_col].astype(int).values != 0).astype(int)\n",
        "        except ValueError:\n",
        "            y_bin = df[mc_col].apply(lambda x: 0 if map_label_string_to_family(str(x)) == \"Benign\" else 1).values\n",
        "    else:\n",
        "        raise ValueError(\"No binary or multiclass label column found.\")\n",
        "    return y_bin\n",
        "\n",
        "def make_one_hot(y, n_classes):\n",
        "    out = np.zeros((len(y), n_classes), dtype=int)\n",
        "    out[np.arange(len(y)), y] = 1\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HmS_wuCo8vWT"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Calibration\n",
        "# -----------------\n",
        "def sigmoid(x): return 1.0/(1.0+np.exp(-x))\n",
        "\n",
        "def fit_temperature(z_val, y_val, n_iters=300, lr=0.05):\n",
        "    T = 1.0\n",
        "    for _ in range(n_iters):\n",
        "        p = sigmoid(z_val / T)\n",
        "        p = np.clip(p, 1e-7, 1-1e-7)\n",
        "        grad = np.mean((p - y_val) * (-z_val/(T*T)))\n",
        "        T -= lr * grad\n",
        "        T = float(np.clip(T, 0.05, 50.0))\n",
        "    return T\n",
        "\n",
        "def apply_temperature(z, T):\n",
        "    return sigmoid(z / T)\n",
        "\n",
        "def calibrate_scores(scores_cal, y_cal_bin, scores_eval, method=\"temperature\"):\n",
        "    s_cal = np.clip(scores_cal, 1e-6, 1-1e-6)\n",
        "    s_eval = np.clip(scores_eval, 1e-6, 1-1e-6)\n",
        "    if method == \"isotonic\":\n",
        "        iso = IsotonicRegression(out_of_bounds=\"clip\")\n",
        "        iso.fit(s_cal, y_cal_bin.astype(int))\n",
        "        s_eval_cal = iso.predict(s_eval)\n",
        "        return s_eval_cal, {\"method\": \"isotonic\"}\n",
        "    else:\n",
        "        z_cal = np.log(s_cal/(1-s_cal))\n",
        "        T = fit_temperature(z_cal, y_cal_bin.astype(int), n_iters=300, lr=0.05)\n",
        "        z_eval = np.log(s_eval/(1-s_eval))\n",
        "        s_eval_cal = apply_temperature(z_eval, T)\n",
        "        return s_eval_cal, {\"method\": \"temperature\", \"T\": float(T)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "siaubI5yiUQw"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Metrics & plots\n",
        "# -----------------\n",
        "def fpr_at_dr(y_true, scores, target_dr=0.95, positive_label=1):\n",
        "    thresholds = np.unique(scores)\n",
        "    thresholds.sort()\n",
        "    best_fpr = None\n",
        "    best_thr = None\n",
        "    for thr in thresholds:\n",
        "        y_pred = (scores >= thr).astype(int)\n",
        "        pos = (y_true == positive_label)\n",
        "        neg = ~pos\n",
        "        tp = (pos & (y_pred == 1)).sum()\n",
        "        fn = (pos & (y_pred == 0)).sum()\n",
        "        dr = tp / max(tp + fn, 1)\n",
        "        if dr >= target_dr:\n",
        "            fp = (neg & (y_pred == 1)).sum()\n",
        "            fpr = fp / max(neg.sum(), 1)\n",
        "            if best_fpr is None or fpr < best_fpr:\n",
        "                best_fpr = fpr\n",
        "                best_thr = thr\n",
        "    return best_fpr if best_fpr is not None else np.nan, best_thr\n",
        "\n",
        "def expected_calibration_error(y_true, probas, n_bins=15):\n",
        "    confidences = probas.max(axis=1)\n",
        "    predictions = probas.argmax(axis=1)\n",
        "    correct = (predictions == y_true).astype(float)\n",
        "    bins = np.linspace(0.0, 1.0, n_bins+1)\n",
        "    ece = 0.0\n",
        "    for i in range(n_bins):\n",
        "        mask = (confidences > bins[i]) & (confidences <= bins[i+1])\n",
        "        if mask.sum() == 0:\n",
        "            continue\n",
        "        acc = correct[mask].mean()\n",
        "        conf = confidences[mask].mean()\n",
        "        ece += (mask.mean()) * abs(acc - conf)\n",
        "    return ece\n",
        "\n",
        "def plot_pr_curves(y_onehot, probas, class_names, out_png):\n",
        "    n_classes = y_onehot.shape[1]\n",
        "    plt.figure()\n",
        "    for c in range(n_classes):\n",
        "        precision, recall, _ = precision_recall_curve(y_onehot[:, c], probas[:, c])\n",
        "        ap = average_precision_score(y_onehot[:, c], probas[:, c])\n",
        "        plt.plot(recall, precision, label=f\"{class_names[c]} (AP={ap:.3f})\")\n",
        "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall Curves\")\n",
        "    plt.legend(); plt.tight_layout(); plt.savefig(out_png, dpi=180); plt.close()\n",
        "\n",
        "def plot_confusion(y_true, y_pred, class_names, out_png, normalize='true'):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)), normalize=normalize)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "    fig, ax = plt.subplots(); disp.plot(ax=ax, values_format=\".2f\", cmap=None, colorbar=False)\n",
        "    plt.title(\"Confusion Matrix\" + (f\" (normalized={normalize})\" if normalize else \"\"))\n",
        "    plt.tight_layout(); plt.savefig(out_png, dpi=180); plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JSt2RXWfxDM_"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Models\n",
        "# -----------------\n",
        "def build_scaler(name):\n",
        "    if name == \"standard\":\n",
        "        return StandardScaler()\n",
        "    elif name == \"robust\":\n",
        "        return RobustScaler(with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0))\n",
        "    elif name == \"quantile\":\n",
        "        return QuantileTransformer(output_distribution=\"normal\", subsample=200000, random_state=CFG[\"train\"][\"random_state\"])\n",
        "    else:\n",
        "        return StandardScaler()\n",
        "\n",
        "def get_lr_pipeline(use_smote, random_state, y_train, scaler_name='standard', C=1.0):\n",
        "    if len(np.unique(y_train)) < 2:\n",
        "        print(\"[WARN] Skipping LR pipeline (single-class training data).\")\n",
        "        return None\n",
        "    lr = LogisticRegression(C=C, max_iter=2000, solver=\"lbfgs\", class_weight=\"balanced\", n_jobs=-1)\n",
        "    steps = [(\"scaler\", build_scaler(scaler_name))]\n",
        "    if use_smote:\n",
        "        steps.append((\"smote\", SMOTE(random_state=random_state)))\n",
        "    steps.append((\"lr\", lr))\n",
        "    pipe = ImbPipeline(steps=steps)\n",
        "    return pipe\n",
        "\n",
        "def fit_lr_then_mlp(X_train, y_train, X_val, y_val, use_smote, random_state, max_epochs, batch_size, hidden_units, alpha=1e-4, scaler_name='standard', C=1.0, early_stopping=True):\n",
        "    pipe = get_lr_pipeline(use_smote, random_state, y_train, scaler_name=scaler_name, C=C)\n",
        "    if pipe is None:\n",
        "        return None, None\n",
        "    pipe.fit(X_train, y_train)\n",
        "    scaler = pipe.named_steps[\"scaler\"]\n",
        "    lr = pipe.named_steps[\"lr\"]\n",
        "    try:\n",
        "        Z_train = lr.decision_function(scaler.transform(X_train))\n",
        "        Z_val   = lr.decision_function(scaler.transform(X_val))\n",
        "        if Z_train.ndim == 1:\n",
        "            Z_train = Z_train.reshape(-1,1)\n",
        "            Z_val   = Z_val.reshape(-1,1)\n",
        "    except Exception:\n",
        "        Z_train = np.log(np.clip(lr.predict_proba(scaler.transform(X_train)), 1e-7, 1-1e-7))\n",
        "        Z_val   = np.log(np.clip(lr.predict_proba(scaler.transform(X_val)), 1e-7, 1-1e-7))\n",
        "        if Z_train.ndim == 1:\n",
        "            Z_train = Z_train.reshape(-1,1)\n",
        "        if Z_val.ndim == 1:\n",
        "            Z_val = Z_val.reshape(-1,1)\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(hidden_units,), alpha=alpha,\n",
        "                        batch_size=batch_size, learning_rate_init=1e-3,\n",
        "                        max_iter=max_epochs, random_state=random_state,\n",
        "                        early_stopping=early_stopping, n_iter_no_change=5, validation_fraction=0.1)\n",
        "    mlp.fit(Z_train, y_train)\n",
        "    return pipe, mlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "t0JVlS4IETUW"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Binary / Multiclass evaluation\n",
        "# ------------------------------\n",
        "def eval_binary(y_true, prob_pos, tag, outdir):\n",
        "    if prob_pos is None or len(prob_pos) == 0:\n",
        "        with open(os.path.join(outdir, f\"{tag}__binary_report.txt\"), \"w\") as f:\n",
        "            f.write(\"Binary evaluation skipped due to insufficient classes or probabilities.\\n\")\n",
        "        return\n",
        "    auc = roc_auc_score(y_true, prob_pos)\n",
        "    aupr = average_precision_score(y_true, prob_pos)\n",
        "    metrics = {\"roc_auc\": float(auc), \"aupr\": float(aupr)}\n",
        "    for dr in CFG[\"metrics\"][\"target_drs\"]:\n",
        "        fpr, thr = fpr_at_dr(y_true, prob_pos, target_dr=dr)\n",
        "        metrics[f\"fpr@dr={dr}\"] = float(fpr) if fpr==fpr else None\n",
        "        metrics[f\"thr@dr={dr}\"] = float(thr) if thr is not None else None\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    with open(os.path.join(outdir, f\"{tag}__binary_metrics.json\"), \"w\") as f:\n",
        "        json.dump(metrics, f, indent=2)\n",
        "    best_thr = metrics.get(\"thr@dr=0.95\", 0.5)\n",
        "    y_pred = (prob_pos >= (best_thr if best_thr is not None else 0.5)).astype(int)\n",
        "    report = classification_report(y_true, y_pred, digits=4)\n",
        "    with open(os.path.join(outdir, f\"{tag}__binary_report.txt\"), \"w\") as f:\n",
        "        f.write(report)\n",
        "\n",
        "def eval_multiclass(y_true, probas, class_names, tag, outdir, train_classes=None):\n",
        "    if probas is None or probas.shape[0] == 0:\n",
        "        with open(os.path.join(outdir, f\"{tag}__multiclass_metrics.json\"), \"w\") as f:\n",
        "            json.dump({\"accuracy\": np.nan, \"f1_macro\": np.nan,\n",
        "                       \"aupr_micro\": np.nan, \"aupr_per_class\": {}, \"ece\": np.nan}, f, indent=2)\n",
        "        return\n",
        "    test_classes = sorted(np.unique(y_true))\n",
        "    if train_classes is None:\n",
        "        k = min(len(test_classes), probas.shape[1])\n",
        "        probas_aligned = np.zeros((probas.shape[0], len(test_classes)))\n",
        "        probas_aligned[:, :k] = probas[:, :k]\n",
        "        used_classes = test_classes\n",
        "    else:\n",
        "        used_classes = test_classes\n",
        "        probas_aligned = np.zeros((probas.shape[0], len(test_classes)))\n",
        "        for j, cls in enumerate(train_classes):\n",
        "            if cls in test_classes:\n",
        "                idx = test_classes.index(cls)\n",
        "                probas_aligned[:, idx] = probas[:, j]\n",
        "    y_pred = probas_aligned.argmax(axis=1)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1m = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    class_names_eval = [f\"C{c}\" for c in used_classes]\n",
        "    y_idx = np.array([used_classes.index(c) for c in y_true])\n",
        "    y_onehot = make_one_hot(y_idx, len(used_classes))\n",
        "    aupr_micro = average_precision_score(y_onehot, probas_aligned, average=\"micro\")\n",
        "    aupr_per = {class_names_eval[i]: float(average_precision_score(y_onehot[:, i], probas_aligned[:, i]))\n",
        "                for i in range(len(used_classes))}\n",
        "    ece = expected_calibration_error(y_idx, probas_aligned, n_bins=15)\n",
        "    with open(os.path.join(outdir, f\"{tag}__multiclass_metrics.json\"), \"w\") as f:\n",
        "        json.dump({\"accuracy\": float(acc), \"f1_macro\": float(f1m),\n",
        "                   \"aupr_micro\": float(aupr_micro),\n",
        "                   \"aupr_per_class\": aupr_per, \"ece\": float(ece)}, f, indent=2)\n",
        "    plot_pr_curves(y_onehot, probas_aligned, class_names_eval, os.path.join(outdir, f\"{tag}__pr_curves.png\"))\n",
        "    plot_confusion(y_idx, y_pred, class_names_eval, os.path.join(outdir, f\"{tag}__confusion.png\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X7TkQfIxiaY2"
      },
      "outputs": [],
      "source": [
        "# --------------------------------------------------------\n",
        "# Adversarial utils (feature-space on standardized inputs)\n",
        "# --------------------------------------------------------\n",
        "def fgsm(X_std, y, model, eps):\n",
        "    W = model.coef_.reshape(1, -1)\n",
        "    z = model.decision_function(X_std)\n",
        "    p = 1.0/(1.0+np.exp(-z))\n",
        "    grad = (p - y.reshape(-1))[:, None] * W\n",
        "    return X_std + eps * np.sign(grad)\n",
        "\n",
        "def pgd(X_std, y, model, eps, alpha, steps):\n",
        "    X_adv = X_std.copy()\n",
        "    for _ in range(steps):\n",
        "        X_adv = fgsm(X_adv, y, model, alpha)\n",
        "        delta = np.clip(X_adv - X_std, -eps, eps)\n",
        "        X_adv = X_std + delta\n",
        "    return X_adv\n",
        "\n",
        "def clip_to_train_range(X_std, scaler, train_min, train_max):\n",
        "    if hasattr(scaler, 'inverse_transform'):\n",
        "        X_raw = scaler.inverse_transform(X_std)\n",
        "    else:\n",
        "        X_raw = X_std * scaler.scale_ + scaler.mean_\n",
        "    X_raw = np.clip(X_raw, train_min, train_max)\n",
        "    return scaler.transform(X_raw)\n",
        "\n",
        "def augment_with_adversarial(X_tr, y_tr, pipe, lr, frac=0.3, eps=0.05):\n",
        "    if eps <= 0.0 or frac <= 0.0:\n",
        "        return X_tr, y_tr\n",
        "    n = len(y_tr)\n",
        "    m = max(1, int(frac * n))\n",
        "    rs = np.random.RandomState(CFG[\"train\"][\"random_state\"])\n",
        "    sel = rs.choice(n, size=m, replace=False)\n",
        "    scaler = pipe.named_steps[\"scaler\"]\n",
        "    X_std = scaler.transform(X_tr)\n",
        "    z = lr.decision_function(X_std)\n",
        "    p = 1.0/(1.0+np.exp(-z))\n",
        "    W = lr.coef_.reshape(1, -1)\n",
        "    grad = (p - y_tr.reshape(-1))[:, None] * W\n",
        "    X_std_adv = X_std.copy()\n",
        "    X_std_adv[sel] = X_std_adv[sel] + eps * np.sign(grad[sel])\n",
        "    X_std_adv = clip_to_train_range(X_std_adv, scaler, X_tr.min(axis=0), X_tr.max(axis=0))\n",
        "    X_adv = scaler.inverse_transform(X_std_adv) if hasattr(scaler, \"inverse_transform\") else (X_std_adv * scaler.scale_ + scaler.mean_)\n",
        "    X_mix = X_tr.copy()\n",
        "    X_mix[sel] = X_adv[sel]\n",
        "    return X_mix, y_tr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5_of5ESbEa-V"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Automapper\n",
        "# -----------------\n",
        "_token_map = {\n",
        "    \"packets\":\"pkts\",\"packet\":\"pkt\",\"length\":\"len\",\"average\":\"mean\",\"stddev\":\"std\",\"std_dev\":\"std\",\n",
        "    \"backward\":\"bwd\",\"forward\":\"fwd\",\"persec\":\"persec\",\"per_second\":\"persec\",\"rate\":\"persec\",\n",
        "    \"bytes\":\"byts\",\"byte\":\"byt\",\"duration\":\"dur\",\"interarrival\":\"iat\",\"src\":\"src\",\"dst\":\"dst\"\n",
        "}\n",
        "def keyify(name: str) -> str:\n",
        "    s = re.sub(r'[^a-zA-Z0-9]+', '', name.lower())\n",
        "    for k,v in _token_map.items():\n",
        "        s = s.replace(k, v)\n",
        "    return s\n",
        "\n",
        "def automap_features(dfA, featsA, dfB, featsB, threshold=0.86, max_pairs=64):\n",
        "    keysA = {f: keyify(f) for f in featsA}\n",
        "    keysB = {f: keyify(f) for f in featsB}\n",
        "    pairs = []\n",
        "    for a,ka in keysA.items():\n",
        "        best_b = None; best_sim = 0.0\n",
        "        for b,kb in keysB.items():\n",
        "            sim = difflib.SequenceMatcher(None, ka, kb).ratio()\n",
        "            if sim > best_sim:\n",
        "                best_sim, best_b = sim, b\n",
        "        if best_sim >= threshold and np.issubdtype(dfA[a].dtype, np.number) and np.issubdtype(dfB[best_b].dtype, np.number):\n",
        "            pairs.append((a, best_b, float(best_sim)))\n",
        "    pairs.sort(key=lambda x: -x[2])\n",
        "    usedA, usedB, final = set(), set(), []\n",
        "    for a,b,sim in pairs:\n",
        "        if a in usedA or b in usedB: continue\n",
        "        final.append((a,b,sim))\n",
        "        usedA.add(a); usedB.add(b)\n",
        "        if len(final) >= max_pairs: break\n",
        "    return final\n",
        "\n",
        "def apply_automap_and_rename(df_src, feats_src, df_tgt, feats_tgt, outdir, tag_prefix):\n",
        "    common = list(sorted(set(feats_src).intersection(set(feats_tgt))))\n",
        "    audit = {\"mode\": \"intersection\", \"count\": len(common), \"pairs\": []}\n",
        "    audit_path = os.path.join(outdir, f\"{tag_prefix}__feature_automap.json\")\n",
        "    if len(common) > 0:\n",
        "        with open(audit_path, \"w\") as f:\n",
        "            json.dump(audit, f, indent=2)\n",
        "        with open(os.path.join(outdir, f\"{tag_prefix}_common_features.json\"), \"w\") as f:\n",
        "            json.dump({\"count\": len(common), \"features\": common, \"audit\": os.path.basename(audit_path)}, f, indent=2)\n",
        "        return df_src, df_tgt, common, audit_path\n",
        "    matches = automap_features(df_src, feats_src, df_tgt, feats_tgt,\n",
        "                               threshold=CFG[\"automap\"][\"similarity_threshold\"],\n",
        "                               max_pairs=CFG[\"automap\"][\"max_pairs\"])\n",
        "    audit = {\"mode\": \"automap\", \"count\": len(matches),\n",
        "             \"pairs\": [{\"src\":a,\"tgt\":b,\"similarity\":sim} for a,b,sim in matches]}\n",
        "    df_tgt2 = df_tgt.copy()\n",
        "    rename_map = {b:a for a,b,_ in matches}\n",
        "    df_tgt2 = df_tgt2.rename(columns=rename_map)\n",
        "    common2 = [a for a,_,_ in matches]\n",
        "    audit[\"renamed\"] = rename_map\n",
        "    with open(audit_path, \"w\") as f:\n",
        "        json.dump(audit, f, indent=2)\n",
        "    with open(os.path.join(outdir, f\"{tag_prefix}_common_features.json\"), \"w\") as f:\n",
        "        json.dump({\"count\": len(common2), \"features\": common2, \"audit\": os.path.basename(audit_path)}, f, indent=2)\n",
        "    return df_src, df_tgt2, common2, audit_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qJ-ne0UgEc5-"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# NF in-domain\n",
        "# -----------------\n",
        "def run_in_domain_nf(nf_df, nf_feats, nf_bin_col, nf_mc_col, outdir):\n",
        "    yb = build_binary_labels(nf_df, nf_bin_col, nf_mc_col)\n",
        "    X = nf_df[nf_feats].values\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(X, yb, test_size=CFG[\"train\"][\"test_size\"],\n",
        "                                              stratify=yb, random_state=CFG[\"train\"][\"random_state\"])\n",
        "    pipe, mlp = fit_lr_then_mlp(X_tr, y_tr, X_te, y_te,\n",
        "                                CFG[\"train\"][\"use_smote\"], CFG[\"train\"][\"random_state\"],\n",
        "                                CFG[\"train\"][\"max_epochs\"], CFG[\"train\"][\"batch_size\"],\n",
        "                                CFG[\"train\"][\"mlp_hidden_units\"])\n",
        "    prob_pos = None; lr=None; scaler=None\n",
        "    if pipe is not None:\n",
        "        scaler = pipe.named_steps[\"scaler\"]; lr = pipe.named_steps[\"lr\"]\n",
        "        try:\n",
        "            Z_te = lr.decision_function(scaler.transform(X_te))\n",
        "        except Exception:\n",
        "            Z_te = np.log(np.clip(lr.predict_proba(scaler.transform(X_te)), 1e-7, 1-1e-7))\n",
        "        if Z_te.ndim == 1: Z_te = Z_te.reshape(-1,1)\n",
        "        prob_pos = mlp.predict_proba(Z_te)[:,1] if mlp is not None else lr.predict_proba(scaler.transform(X_te))[:,1]\n",
        "    eval_binary(y_te, prob_pos, \"NF_ToN_IoT__in_domain\", outdir)\n",
        "\n",
        "    if pipe is not None:\n",
        "        Xte_std = scaler.transform(X_te)\n",
        "        for eps in CFG[\"robust\"][\"eps\"]:\n",
        "            X_fgsm = fgsm(Xte_std, y_te, lr, eps)\n",
        "            X_fgsm = clip_to_train_range(X_fgsm, scaler, X_tr.min(axis=0), X_tr.max(axis=0))\n",
        "            z_fgsm = lr.decision_function(X_fgsm)\n",
        "            prob_fgsm = 1.0/(1.0+np.exp(-z_fgsm))\n",
        "            eval_binary(y_te, prob_fgsm, f\"NF_ToN_IoT__in_domain__FGSM_eps={eps}\", outdir)\n",
        "\n",
        "            X_pgd = pgd(Xte_std, y_te, lr, eps, CFG[\"robust\"][\"pgd_alpha\"], CFG[\"robust\"][\"pgd_steps\"])\n",
        "            X_pgd = clip_to_train_range(X_pgd, scaler, X_tr.min(axis=0), X_tr.max(axis=0))\n",
        "            z_pgd = lr.decision_function(X_pgd)\n",
        "            prob_pgd = 1.0/(1.0+np.exp(-z_pgd))\n",
        "            eval_binary(y_te, prob_pgd, f\"NF_ToN_IoT__in_domain__PGD_eps={eps}\", outdir)\n",
        "\n",
        "    if nf_mc_col:\n",
        "        ym = nf_df[nf_mc_col].astype(int).values\n",
        "        Xm_tr, Xm_te, ym_tr, ym_te = train_test_split(X, ym, test_size=CFG[\"train\"][\"test_size\"],\n",
        "                                                      stratify=ym, random_state=CFG[\"train\"][\"random_state\"])\n",
        "        if len(np.unique(ym_tr)) >= 2:\n",
        "            pipe_m = SkPipeline([(\"scaler\", StandardScaler()),\n",
        "                                 (\"clf\", LogisticRegression(max_iter=2000, n_jobs=-1))])\n",
        "            pipe_m.fit(Xm_tr, ym_tr)\n",
        "            probas = pipe_m.predict_proba(Xm_te)\n",
        "            class_names = [f\"C{c}\" for c in sorted(np.unique(ym))]\n",
        "            eval_multiclass(ym_te, probas, class_names, \"NF_ToN_IoT__in_domain_native_mc\", outdir, train_classes=list(pipe_m.named_steps[\"clf\"].classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6ZC41SB9EhPS"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------\n",
        "# CIC in-domain (train→test) collapsed-binary (guarded)\n",
        "# -----------------------------------------------------\n",
        "def run_in_domain_cic_collapsed(cic_tr_df, cic_tr_feats, cic_tr_mc_col,\n",
        "                                cic_te_df, cic_te_feats, cic_te_mc_col, outdir, calib_method=\"temperature\"):\n",
        "    common = list(sorted(set(cic_tr_feats).intersection(set(cic_te_feats))))\n",
        "    if len(common) == 0:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__train_to_test__binary_from_mc__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(\"Skipped: no shared numeric features between CIC_train and CIC_test.\\n\")\n",
        "        return\n",
        "\n",
        "    Xtr = cic_tr_df[common].values\n",
        "    Xte_full = cic_te_df[common].values\n",
        "    ym_tr = cic_tr_df[cic_tr_mc_col].astype(int).values if cic_tr_mc_col else None\n",
        "    ym_te_full = cic_te_df[cic_te_mc_col].astype(int).values if cic_te_mc_col else None\n",
        "    if ym_tr is None or ym_te_full is None or len(np.unique(ym_tr)) < 2:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__train_to_test__binary_from_mc__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(\"Skipped: multiclass labels missing or single-class in CIC_train/CIC_test.\\n\")\n",
        "        return\n",
        "\n",
        "    pipe_m = SkPipeline([(\"scaler\", StandardScaler()),\n",
        "                         (\"clf\", LogisticRegression(max_iter=2000, n_jobs=-1))])\n",
        "    pipe_m.fit(Xtr, ym_tr)\n",
        "    X_cal, X_eval, y_cal, y_eval = train_test_split(Xte_full, ym_te_full, test_size=1.0-CFG[\"calibration\"][\"cic_calib_frac\"],\n",
        "                                                    stratify=ym_te_full, random_state=CFG[\"train\"][\"random_state\"])\n",
        "    probas_cal = pipe_m.predict_proba(X_cal)\n",
        "    probas_eval = pipe_m.predict_proba(X_eval)\n",
        "\n",
        "    ben_mask_cal = (y_cal == 0)\n",
        "    if ben_mask_cal.sum() == 0:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__train_to_test__binary_from_mc__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(\"Skipped: no benign in CIC_test calibration split; cannot align benign column.\\n\")\n",
        "        return\n",
        "\n",
        "    mean_probs_on_ben = probas_cal[ben_mask_cal].mean(axis=0)\n",
        "    benign_idx_aligned = int(np.argmax(mean_probs_on_ben))\n",
        "    if mean_probs_on_ben[benign_idx_aligned] < 0.25:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__train_to_test__binary_from_mc__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(f\"Skipped: aligned 'benign' column probability on benign-cal < 0.25 ({mean_probs_on_ben[benign_idx_aligned]:.3f}).\\n\")\n",
        "        return\n",
        "\n",
        "    s_attack_cal  = 1.0 - np.clip(probas_cal[:,  benign_idx_aligned], 1e-6, 1-1e-6)\n",
        "    s_attack_eval = 1.0 - np.clip(probas_eval[:, benign_idx_aligned], 1e-6, 1-1e-6)\n",
        "\n",
        "    auc_cal = roc_auc_score((y_cal != 0).astype(int), s_attack_cal)\n",
        "    if auc_cal < 0.5:\n",
        "        s_attack_cal  = 1.0 - s_attack_cal\n",
        "        s_attack_eval = 1.0 - s_attack_eval\n",
        "\n",
        "    eval_binary((y_eval != 0).astype(int), s_attack_eval,\n",
        "                \"CIC_IoMT__train_to_test__binary_from_mc\", outdir)\n",
        "\n",
        "    s_eval_cal, meta = calibrate_scores(s_attack_cal, (y_cal != 0).astype(int),\n",
        "                                        s_attack_eval, method=calib_method)\n",
        "    eval_binary((y_eval != 0).astype(int), s_eval_cal,\n",
        "                f\"CIC_IoMT__train_to_test__binary_from_mc__Calibrated({calib_method})\", outdir)\n",
        "    with open(os.path.join(outdir, f\"CIC_IoMT__train_to_test__binary_from_mc__Calibrated({calib_method})__meta.json\"), \"w\") as f:\n",
        "        json.dump({\"benign_alignment\": {\"column_index\": benign_idx_aligned,\n",
        "                                        \"mean_prob_on_benign_cal\": float(mean_probs_on_ben[benign_idx_aligned])},\n",
        "                   **meta}, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WB-E7IlT4AJn"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# CIC native multiclass (always)\n",
        "# ------------------------------\n",
        "def run_in_domain_cic_native_mc(cic_tr_df, cic_tr_feats, cic_tr_mc_col,\n",
        "                                cic_te_df, cic_te_feats, cic_te_mc_col, outdir):\n",
        "    common = list(sorted(set(cic_tr_feats).intersection(set(cic_te_feats))))\n",
        "    if len(common) == 0:\n",
        "        return\n",
        "    Xtr = cic_tr_df[common].values\n",
        "    Xte = cic_te_df[common].values\n",
        "    ym_tr = cic_tr_df[cic_tr_mc_col].astype(int).values if cic_tr_mc_col else None\n",
        "    ym_te = cic_te_df[cic_te_mc_col].astype(int).values if cic_te_mc_col else None\n",
        "    if ym_tr is None or ym_te is None or len(np.unique(ym_tr)) < 2:\n",
        "        return\n",
        "    pipe_m = SkPipeline([(\"scaler\", StandardScaler()),\n",
        "                         (\"clf\", LogisticRegression(max_iter=2000, n_jobs=-1))])\n",
        "    pipe_m.fit(Xtr, ym_tr)\n",
        "    probas = pipe_m.predict_proba(Xte)\n",
        "    class_names = [f\"C{c}\" for c in sorted(np.unique(ym_te))]\n",
        "    train_classes = list(pipe_m.named_steps[\"clf\"].classes_)\n",
        "    # Use eval_multiclass to write metrics + plots\n",
        "    eval_multiclass(ym_te, probas, class_names, \"CIC_IoMT__native_multiclass__train_to_test\", outdir, train_classes=train_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Le_EDDUIop3i"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# CIC tiny benign slice experiment (writes explicit SKIPPED/ERROR files)\n",
        "# ----------------------------------------------------------------------\n",
        "def run_cic_with_tiny_benign_slice(cic_tr_df, cic_tr_feats, cic_tr_bin_col, cic_tr_mc_col,\n",
        "                                   cic_te_df, cic_te_feats, cic_te_bin_col, cic_te_mc_col,\n",
        "                                   outdir, slice_frac=0.015, seed=42):\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    try:\n",
        "        rs = np.random.RandomState(seed)\n",
        "\n",
        "        # 0) Feature intersection\n",
        "        common = list(sorted(set(cic_tr_feats).intersection(set(cic_te_feats))))\n",
        "        if len(common) == 0:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: no shared numeric features between CIC_train and CIC_test.\\n\")\n",
        "            return\n",
        "\n",
        "        # 1) Labels\n",
        "        if cic_tr_mc_col is None or cic_te_mc_col is None:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: multiclass label column not found in CIC train/test.\\n\")\n",
        "            return\n",
        "        y_tr_mc = cic_tr_df[cic_tr_mc_col].astype(int).values\n",
        "        X_tr_all = cic_tr_df[common].values\n",
        "        A_idx = np.where(y_tr_mc != 0)[0]\n",
        "        if len(A_idx) == 0:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: CIC_train has no attacks; cannot build binary head.\\n\")\n",
        "            return\n",
        "        X_attack_all = X_tr_all[A_idx]\n",
        "\n",
        "        y_te_mc = cic_te_df[cic_te_mc_col].astype(int).values\n",
        "        X_te_all = cic_te_df[common].values\n",
        "        ben_idx_all = np.where(y_te_mc == 0)[0]\n",
        "        atk_idx_all = np.where(y_te_mc != 0)[0]\n",
        "        if len(ben_idx_all) == 0:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: no benign samples in CIC_test.\\n\")\n",
        "            return\n",
        "\n",
        "        # 2) Sample tiny benign slice\n",
        "        n_ben_slice = max(1, int(len(ben_idx_all) * slice_frac))\n",
        "        ben_slice = rs.choice(ben_idx_all, size=n_ben_slice, replace=False)\n",
        "\n",
        "        # Split benign slice into train/cal halves\n",
        "        n_ben_cal  = max(1, n_ben_slice // 2)\n",
        "        n_ben_train = n_ben_slice - n_ben_cal\n",
        "        rs.shuffle(ben_slice)\n",
        "        ben_train_idx = ben_slice[:n_ben_train]\n",
        "        ben_cal_idx   = ben_slice[n_ben_train:]\n",
        "\n",
        "        # Cal set: include a small set of attacks to balance calibration\n",
        "        n_atk_cal = min(len(atk_idx_all), n_ben_cal)\n",
        "        atk_cal_idx = rs.choice(atk_idx_all, size=n_atk_cal, replace=False)\n",
        "\n",
        "        # Held-out eval: everything except the slice+atk_cal\n",
        "        held_out_mask = np.ones(len(y_te_mc), dtype=bool)\n",
        "        held_out_mask[ben_slice] = False\n",
        "        held_out_mask[atk_cal_idx] = False\n",
        "        X_eval = X_te_all[held_out_mask]\n",
        "        y_eval_bin = (y_te_mc[held_out_mask] != 0).astype(int)\n",
        "        if X_eval.shape[0] == 0 or len(np.unique(y_eval_bin)) < 2:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: empty or single-class held-out evaluation set after slicing.\\n\")\n",
        "            return\n",
        "\n",
        "        # Train set: CIC_train attacks + tiny benign_train\n",
        "        X_train = np.vstack([X_attack_all, X_te_all[ben_train_idx]])\n",
        "        y_train_bin = np.concatenate([np.ones(len(X_attack_all), dtype=int),\n",
        "                                      np.zeros(len(ben_train_idx), dtype=int)])\n",
        "\n",
        "        # Calibration set\n",
        "        X_cal = np.vstack([X_te_all[atk_cal_idx], X_te_all[ben_cal_idx]])\n",
        "        y_cal_bin = np.concatenate([np.ones(len(atk_cal_idx), dtype=int),\n",
        "                                    np.zeros(len(ben_cal_idx), dtype=int)])\n",
        "\n",
        "        # 3) Fit binary LR→MLP head\n",
        "        pipe_b, mlp_b = fit_lr_then_mlp(\n",
        "            X_train, y_train_bin,\n",
        "            X_eval,  y_eval_bin,\n",
        "            CFG[\"train\"][\"use_smote\"], CFG[\"train\"][\"random_state\"],\n",
        "            CFG[\"train\"][\"max_epochs\"], CFG[\"train\"][\"batch_size\"],\n",
        "            CFG[\"train\"][\"mlp_hidden_units\"]\n",
        "        )\n",
        "        if pipe_b is None:\n",
        "            with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__SKIPPED.txt\"), \"w\") as f:\n",
        "                f.write(\"Skipped: training pipeline failed (single-class or pipeline error).\\n\")\n",
        "            return\n",
        "\n",
        "        scaler = pipe_b.named_steps[\"scaler\"]; lr = pipe_b.named_steps[\"lr\"]\n",
        "        try:\n",
        "            Z_eval = lr.decision_function(scaler.transform(X_eval))\n",
        "            Z_cal  = lr.decision_function(scaler.transform(X_cal))\n",
        "            if Z_eval.ndim == 1: Z_eval = Z_eval.reshape(-1,1)\n",
        "            if Z_cal.ndim  == 1: Z_cal  = Z_cal.reshape(-1,1)\n",
        "            if mlp_b is not None:\n",
        "                prob_eval = mlp_b.predict_proba(Z_eval)[:,1]\n",
        "                prob_cal  = mlp_b.predict_proba(Z_cal)[:,1]\n",
        "            else:\n",
        "                prob_eval = 1.0/(1.0+np.exp(-Z_eval)).ravel()\n",
        "                prob_cal  = 1.0/(1.0+np.exp(-Z_cal)).ravel()\n",
        "        except Exception:\n",
        "            prob_eval = lr.predict_proba(scaler.transform(X_eval))[:,1]\n",
        "            prob_cal  = lr.predict_proba(scaler.transform(X_cal))[:,1]\n",
        "\n",
        "        # 4) Uncalibrated metrics\n",
        "        auc_unc = float(roc_auc_score(y_eval_bin, prob_eval))\n",
        "        aupr_unc = float(average_precision_score(y_eval_bin, prob_eval))\n",
        "        fpr90_unc, thr90_unc = fpr_at_dr(y_eval_bin, prob_eval, target_dr=0.90)\n",
        "        fpr95_unc, thr95_unc = fpr_at_dr(y_eval_bin, prob_eval, target_dr=0.95)\n",
        "        eval_binary(y_eval_bin, prob_eval, \"CIC_IoMT__tiny_benign_slice\", outdir)\n",
        "\n",
        "        # 5) Calibrated metrics (temperature & isotonic)\n",
        "        rows = []\n",
        "        def _add_row(kind, auc, aupr, fpr90, thr90, fpr95, thr95):\n",
        "            rows.append({\"scenario\": f\"CIC_tiny_slice__{kind}\",\n",
        "                         \"roc_auc\": auc, \"aupr\": aupr,\n",
        "                         \"fpr@dr=0.90\": fpr90, \"thr@dr=0.90\": thr90,\n",
        "                         \"fpr@dr=0.95\": fpr95, \"thr@dr=0.95\": thr95})\n",
        "\n",
        "        _add_row(\"uncalibrated\", auc_unc, aupr_unc, fpr90_unc, thr90_unc, fpr95_unc, thr95_unc)\n",
        "\n",
        "        for method in [\"temperature\", \"isotonic\"]:\n",
        "            prob_eval_cal, meta = calibrate_scores(prob_cal, y_cal_bin, prob_eval, method=method)\n",
        "            auc_c = float(roc_auc_score(y_eval_bin, prob_eval_cal))\n",
        "            aupr_c = float(average_precision_score(y_eval_bin, prob_eval_cal))\n",
        "            fpr90_c, thr90_c = fpr_at_dr(y_eval_bin, prob_eval_cal, target_dr=0.90)\n",
        "            fpr95_c, thr95_c = fpr_at_dr(y_eval_bin, prob_eval_cal, target_dr=0.95)\n",
        "            eval_binary(y_eval_bin, prob_eval_cal,\n",
        "                        f\"CIC_IoMT__tiny_benign_slice__Calibrated({method})\", outdir)\n",
        "            with open(os.path.join(outdir, f\"CIC_IoMT__tiny_benign_slice__Calibrated({method})__meta.json\"), \"w\") as f:\n",
        "                json.dump(meta, f, indent=2)\n",
        "            _add_row(f\"Calibrated({method})\", auc_c, aupr_c, fpr90_c, thr90_c, fpr95_c, thr95_c)\n",
        "\n",
        "        # 6) CSV mini-table + meta\n",
        "        pd.DataFrame(rows).to_csv(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__summary.csv\"), index=False)\n",
        "\n",
        "        meta_all = {\n",
        "            \"slice_frac\": float(slice_frac),\n",
        "            \"seed\": int(seed),\n",
        "            \"n_ben_train\": int(len(ben_train_idx)),\n",
        "            \"n_ben_cal\": int(len(ben_cal_idx)),\n",
        "            \"n_atk_cal\": int(len(atk_cal_idx)),\n",
        "            \"n_eval_total\": int(len(y_eval_bin)),\n",
        "            \"class_balance_eval\": {\"benign\": int((y_eval_bin==0).sum()), \"attack\": int((y_eval_bin==1).sum())},\n",
        "            \"features_used\": common\n",
        "        }\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__meta.json\"), \"w\") as f:\n",
        "            json.dump(meta_all, f, indent=2)\n",
        "\n",
        "        print(\"[OK] CIC tiny-benign-slice run complete.\")\n",
        "    except Exception as e:\n",
        "        with open(os.path.join(outdir, \"CIC_IoMT__tiny_benign_slice__ERROR.txt\"), \"w\") as f:\n",
        "            f.write(\"Exception occurred during tiny-slice run:\\n\")\n",
        "            f.write(str(e) + \"\\n\\n\" + traceback.format_exc())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rE9JkAmV4FOp"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Cross-domain\n",
        "# -----------------\n",
        "def run_cross_domain(nf_df, nf_feats, nf_bin_col, nf_mc_col,\n",
        "                     cic_tr_df, cic_tr_feats, cic_tr_bin_col, cic_tr_mc_col,\n",
        "                     cic_te_df, cic_te_feats, cic_te_bin_col, cic_te_mc_col,\n",
        "                     outdir, automap_min=5):\n",
        "\n",
        "    # NF → CIC_test\n",
        "    nf_df2, cic_te_df2, common_nf_cic, audit1 = apply_automap_and_rename(nf_df, nf_feats, cic_te_df, cic_te_feats, outdir, \"NF_to_CIC\")\n",
        "    if len(common_nf_cic) < automap_min:\n",
        "        msg = f\"Skipped: shared features {len(common_nf_cic)} < {automap_min}\\n\"\n",
        "        with open(os.path.join(outdir, \"NF_to_CIC__xfer__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(msg)\n",
        "    else:\n",
        "        Xs = nf_df2[common_nf_cic].values\n",
        "        Xt = cic_te_df2[common_nf_cic].values\n",
        "        ys = build_binary_labels(nf_df2, nf_bin_col, nf_mc_col)\n",
        "        yt = build_binary_labels(cic_te_df2, cic_te_bin_col, cic_te_mc_col)\n",
        "        pipe, mlp = fit_lr_then_mlp(Xs, ys, Xt, np.zeros(len(Xt)),\n",
        "                                    CFG[\"train\"][\"use_smote\"], CFG[\"train\"][\"random_state\"],\n",
        "                                    CFG[\"train\"][\"max_epochs\"], CFG[\"train\"][\"batch_size\"],\n",
        "                                    CFG[\"train\"][\"mlp_hidden_units\"])\n",
        "        prob_pos = None; scaler=None; lr=None\n",
        "        if pipe is not None:\n",
        "            scaler = pipe.named_steps[\"scaler\"]; lr = pipe.named_steps[\"lr\"]\n",
        "            try:\n",
        "                Zt = lr.decision_function(scaler.transform(Xt))\n",
        "            except Exception:\n",
        "                Zt = np.log(np.clip(lr.predict_proba(scaler.transform(Xt)), 1e-7, 1-1e-7))\n",
        "            if Zt.ndim == 1: Zt = Zt.reshape(-1,1)\n",
        "            prob_pos = mlp.predict_proba(Zt)[:,1] if mlp is not None else lr.predict_proba(scaler.transform(Xt))[:,1]\n",
        "        eval_binary(yt, prob_pos, \"NF_ToN_IoT__to__CIC_IoMT_test__binary_xfer\", outdir)\n",
        "\n",
        "        if pipe is not None:\n",
        "            Xt_std = scaler.transform(Xt)\n",
        "            for eps in CFG[\"robust\"][\"eps\"]:\n",
        "                Xt_fgsm = fgsm(Xt_std, yt, lr, eps)\n",
        "                Xt_fgsm = clip_to_train_range(Xt_fgsm, scaler, Xs.min(axis=0), Xs.max(axis=0))\n",
        "                z_fgsm = lr.decision_function(Xt_fgsm); prob_fgsm = 1.0/(1.0+np.exp(-z_fgsm))\n",
        "                eval_binary(yt, prob_fgsm, f\"NF_ToN_IoT__to__CIC_IoMT_test__FGSM_eps={eps}\", outdir)\n",
        "\n",
        "                Xt_pgd = pgd(Xt_std, yt, lr, eps, CFG[\"robust\"][\"pgd_alpha\"], CFG[\"robust\"][\"pgd_steps\"])\n",
        "                Xt_pgd = clip_to_train_range(Xt_pgd, scaler, Xs.min(axis=0), Xs.max(axis=0))\n",
        "                z_pgd = lr.decision_function(Xt_pgd); prob_pgd = 1.0/(1.0+np.exp(-z_pgd))\n",
        "                eval_binary(yt, prob_pgd, f\"NF_ToN_IoT__to__CIC_IoMT_test__PGD_eps={eps}\", outdir)\n",
        "\n",
        "    # CIC_train → NF (guarded)\n",
        "    cic_tr_df2, nf_df2b, common_cic_nf, audit2 = apply_automap_and_rename(cic_tr_df, cic_tr_feats, nf_df, nf_feats, outdir, \"CIC_to_NF\")\n",
        "    if len(common_cic_nf) < automap_min:\n",
        "        msg = f\"Skipped: shared features {len(common_cic_nf)} < {automap_min}\\n\"\n",
        "        with open(os.path.join(outdir, \"CIC_to_NF__xfer__SKIPPED.txt\"), \"w\") as f:\n",
        "            f.write(msg)\n",
        "    else:\n",
        "        Xs2 = cic_tr_df2[common_cic_nf].values\n",
        "        Xt2 = nf_df2b[common_cic_nf].values\n",
        "        ys2 = build_binary_labels(cic_tr_df2, cic_tr_bin_col, cic_tr_mc_col)\n",
        "        yt2 = build_binary_labels(nf_df2b, nf_bin_col, nf_mc_col)\n",
        "        pipe2, mlp2 = fit_lr_then_mlp(Xs2, ys2, Xt2, np.zeros(len(Xt2)),\n",
        "                                      CFG[\"train\"][\"use_smote\"], CFG[\"train\"][\"random_state\"],\n",
        "                                      CFG[\"train\"][\"max_epochs\"], CFG[\"train\"][\"batch_size\"],\n",
        "                                      CFG[\"train\"][\"mlp_hidden_units\"])\n",
        "        prob_pos2=None; scaler2=None; lr2=None\n",
        "        if pipe2 is not None:\n",
        "            scaler2 = pipe2.named_steps[\"scaler\"]; lr2 = pipe2.named_steps[\"lr\"]\n",
        "            try:\n",
        "                Zt2 = lr2.decision_function(scaler2.transform(Xt2))\n",
        "            except Exception:\n",
        "                Zt2 = np.log(np.clip(lr2.predict_proba(scaler2.transform(Xt2)), 1e-7, 1-1e-7))\n",
        "            if Zt2.ndim == 1: Zt2 = Zt2.reshape(-1,1)\n",
        "            prob_pos2 = mlp2.predict_proba(Zt2)[:,1] if mlp2 is not None else lr2.predict_proba(scaler2.transform(Xt2))[:,1]\n",
        "        eval_binary(yt2, prob_pos2, \"CIC_IoMT_train__to__NF_ToN_IoT__binary_xfer\", outdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRvVYVCS9P_N",
        "outputId": "e0ebd30f-679c-4137-9e7e-27fbc43d514b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3953389373.py:47: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
            "  plt.legend(); plt.tight_layout(); plt.savefig(out_png, dpi=180); plt.close()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] CIC tiny-benign-slice run complete.\n"
          ]
        }
      ],
      "source": [
        "# -----------------\n",
        "# Main\n",
        "# -----------------\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--grid\", action=\"store_true\", help=\"Run compact NF grid and write grid_summary.json\")\n",
        "    parser.add_argument(\"--adv-train-eps\", type=float, default=0.0)\n",
        "    parser.add_argument(\"--adv-train-frac\", type=float, default=0.3)\n",
        "    parser.add_argument(\"--cic-calib\", type=str, choices=[\"temperature\",\"isotonic\"], default=\"temperature\")\n",
        "    parser.add_argument(\"--automap-min\", type=int, default=5, help=\"Minimum shared features for cross-domain metrics\")\n",
        "    # Tiny-slice controls\n",
        "    parser.add_argument(\"--no-cic-tiny-slice\", action=\"store_true\",\n",
        "                        help=\"Disable the CIC tiny benign slice experiment (enabled by default).\")\n",
        "    parser.add_argument(\"--cic-slice-frac\", type=float, default=0.015,\n",
        "                        help=\"Fraction of CIC_test benign to use for training+calibration (default 0.015 = 1.5%).\")\n",
        "    parser.add_argument(\"--cic-slice-seed\", type=int, default=42,\n",
        "                        help=\"Random seed for benign-slice sampling.\")\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    outdir = CFG[\"paths\"][\"outdir\"]\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "    # Load datasets\n",
        "    nf_df, nf_feats, nf_bin_col, nf_mc_col = load_dataset(CFG[\"paths\"][\"nf_csv\"])\n",
        "    cic_tr_df, cic_tr_feats, cic_tr_bin_col, cic_tr_mc_col = load_dataset(CFG[\"paths\"][\"cic_train_csv\"])\n",
        "    cic_te_df, cic_te_feats, cic_te_bin_col, cic_te_mc_col = load_dataset(CFG[\"paths\"][\"cic_test_csv\"])\n",
        "\n",
        "    with open(os.path.join(outdir, \"hyperparams.json\"), \"w\") as f:\n",
        "        json.dump({\n",
        "            \"random_state\": CFG[\"train\"][\"random_state\"],\n",
        "            \"use_smote\": CFG[\"train\"][\"use_smote\"],\n",
        "            \"mlp_hidden_units\": CFG[\"train\"][\"mlp_hidden_units\"],\n",
        "            \"max_epochs\": CFG[\"train\"][\"max_epochs\"],\n",
        "            \"batch_size\": CFG[\"train\"][\"batch_size\"],\n",
        "            \"target_drs\": CFG[\"metrics\"][\"target_drs\"],\n",
        "            \"robust_eps\": CFG[\"robust\"][\"eps\"],\n",
        "            \"pgd_steps\": CFG[\"robust\"][\"pgd_steps\"],\n",
        "            \"pgd_alpha\": CFG[\"robust\"][\"pgd_alpha\"],\n",
        "            \"cic_calib_frac\": CFG[\"calibration\"][\"cic_calib_frac\"],\n",
        "            \"cic_calib_method\": args.cic_calib,\n",
        "            \"automap_min\": args.automap_min,\n",
        "            \"automap_threshold\": CFG[\"automap\"][\"similarity_threshold\"],\n",
        "            \"automap_max_pairs\": CFG[\"automap\"][\"max_pairs\"],\n",
        "            \"cic_slice_frac\": args.cic_slice_frac,\n",
        "            \"cic_slice_seed\": args.cic_slice_seed\n",
        "        }, f, indent=2)\n",
        "\n",
        "    # NF in-domain (clean + adversarial)\n",
        "    run_in_domain_nf(nf_df, nf_feats, nf_bin_col, nf_mc_col, outdir)\n",
        "\n",
        "    # CIC native multiclass\n",
        "    run_in_domain_cic_native_mc(cic_tr_df, cic_tr_feats, cic_tr_mc_col,\n",
        "                                cic_te_df, cic_te_feats, cic_te_mc_col, outdir)\n",
        "\n",
        "    # CIC collapsed-binary (guarded)\n",
        "    run_in_domain_cic_collapsed(cic_tr_df, cic_tr_feats, cic_tr_mc_col,\n",
        "                                cic_te_df, cic_te_feats, cic_te_mc_col, outdir, calib_method=args.cic_calib)\n",
        "\n",
        "    # CIC tiny-slice (ENABLED by default)\n",
        "    if not args.no_cic_tiny_slice:\n",
        "        run_cic_with_tiny_benign_slice(\n",
        "            cic_tr_df, cic_tr_feats, cic_tr_bin_col, cic_tr_mc_col,\n",
        "            cic_te_df, cic_te_feats, cic_te_bin_col, cic_te_mc_col,\n",
        "            outdir, slice_frac=args.cic_slice_frac, seed=args.cic_slice_seed\n",
        "        )\n",
        "\n",
        "    # Cross-domain (guarded by automap_min)\n",
        "    run_cross_domain(nf_df, nf_feats, nf_bin_col, nf_mc_col,\n",
        "                     cic_tr_df, cic_tr_feats, cic_tr_bin_col, cic_tr_mc_col,\n",
        "                     cic_te_df, cic_te_feats, cic_te_bin_col, cic_te_mc_col,\n",
        "                     outdir, automap_min=args.automap_min)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyN3BDUGMvrIfneb4sXi3Nu6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}