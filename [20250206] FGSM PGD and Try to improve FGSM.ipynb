{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankeawthong/Project-1-Lita-Chatbot/blob/main/%5B20250206%5D%20FGSM%20PGD%20and%20Try%20to%20improve%20FGSM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zi8pwJKYJJ6F"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DX2I_3uFMMxS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyfvH2qXM4WT"
      },
      "source": [
        "**PART 1: Data Preprocessing & Balancing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EIXtl20gMOtK"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "dataset = pd.read_csv(\"Dataset_10Classes.csv\")\n",
        "\n",
        "# Handle missing values\n",
        "dataset = dataset.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "8zTnYg60JY-E",
        "outputId": "1c8bce69-5489-4c4c-d8e5-b38f5d7429c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         ID_Cb     id       dur proto service state  spkts  dpkts  sbytes  \\\n",
              "0            1      1  0.121478   tcp       -   FIN      6      4     258   \n",
              "1            2      2  0.649902   tcp       -   FIN     14     38     734   \n",
              "2            3      3  1.623129   tcp       -   FIN      8     16     364   \n",
              "3            4      4  1.681642   tcp     ftp   FIN     12     12     628   \n",
              "4            5      5  0.449454   tcp       -   FIN     10      6     534   \n",
              "...        ...    ...       ...   ...     ...   ...    ...    ...     ...   \n",
              "257668  257669  82328  0.000005   udp       -   INT      2      0     104   \n",
              "257669  257670  82329  1.106101   tcp       -   FIN     20      8   18062   \n",
              "257670  257671  82330  0.000000   arp       -   INT      1      0      46   \n",
              "257671  257672  82331  0.000000   arp       -   INT      1      0      46   \n",
              "257672  257673  82332  0.000009   udp       -   INT      2      0     104   \n",
              "\n",
              "        dbytes  ...  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
              "0          172  ...               1             0           0   \n",
              "1        42014  ...               2             0           0   \n",
              "2        13186  ...               3             0           0   \n",
              "3          770  ...               3             1           1   \n",
              "4          268  ...              40             0           0   \n",
              "...        ...  ...             ...           ...         ...   \n",
              "257668       0  ...               2             0           0   \n",
              "257669     354  ...               1             0           0   \n",
              "257670       0  ...               1             0           0   \n",
              "257671       0  ...               1             0           0   \n",
              "257672       0  ...               1             0           0   \n",
              "\n",
              "        ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \\\n",
              "0                      0           1           1                0      Normal   \n",
              "1                      0           1           6                0      Normal   \n",
              "2                      0           2           6                0      Normal   \n",
              "3                      0           2           1                0      Normal   \n",
              "4                      0           2          39                0      Normal   \n",
              "...                  ...         ...         ...              ...         ...   \n",
              "257668                 0           2           1                0      Normal   \n",
              "257669                 0           3           2                0      Normal   \n",
              "257670                 0           1           1                1      Normal   \n",
              "257671                 0           1           1                1      Normal   \n",
              "257672                 0           1           1                0      Normal   \n",
              "\n",
              "        label  Class  \n",
              "0           0      0  \n",
              "1           0      0  \n",
              "2           0      0  \n",
              "3           0      0  \n",
              "4           0      0  \n",
              "...       ...    ...  \n",
              "257668      0      0  \n",
              "257669      0      0  \n",
              "257670      0      0  \n",
              "257671      0      0  \n",
              "257672      0      0  \n",
              "\n",
              "[257673 rows x 47 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83ad58fa-d681-4edb-a045-f2ce9655c9cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID_Cb</th>\n",
              "      <th>id</th>\n",
              "      <th>dur</th>\n",
              "      <th>proto</th>\n",
              "      <th>service</th>\n",
              "      <th>state</th>\n",
              "      <th>spkts</th>\n",
              "      <th>dpkts</th>\n",
              "      <th>sbytes</th>\n",
              "      <th>dbytes</th>\n",
              "      <th>...</th>\n",
              "      <th>ct_dst_src_ltm</th>\n",
              "      <th>is_ftp_login</th>\n",
              "      <th>ct_ftp_cmd</th>\n",
              "      <th>ct_flw_http_mthd</th>\n",
              "      <th>ct_src_ltm</th>\n",
              "      <th>ct_srv_dst</th>\n",
              "      <th>is_sm_ips_ports</th>\n",
              "      <th>attack_cat</th>\n",
              "      <th>label</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.121478</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>258</td>\n",
              "      <td>172</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.649902</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>14</td>\n",
              "      <td>38</td>\n",
              "      <td>734</td>\n",
              "      <td>42014</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1.623129</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>364</td>\n",
              "      <td>13186</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.681642</td>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp</td>\n",
              "      <td>FIN</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>628</td>\n",
              "      <td>770</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0.449454</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>534</td>\n",
              "      <td>268</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257668</th>\n",
              "      <td>257669</td>\n",
              "      <td>82328</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257669</th>\n",
              "      <td>257670</td>\n",
              "      <td>82329</td>\n",
              "      <td>1.106101</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>18062</td>\n",
              "      <td>354</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257670</th>\n",
              "      <td>257671</td>\n",
              "      <td>82330</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>arp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257671</th>\n",
              "      <td>257672</td>\n",
              "      <td>82331</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>arp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257672</th>\n",
              "      <td>257673</td>\n",
              "      <td>82332</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>257673 rows × 47 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83ad58fa-d681-4edb-a045-f2ce9655c9cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-83ad58fa-d681-4edb-a045-f2ce9655c9cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-83ad58fa-d681-4edb-a045-f2ce9655c9cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-855d5036-2066-473a-883b-35daa9eafb5f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-855d5036-2066-473a-883b-35daa9eafb5f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-855d5036-2066-473a-883b-35daa9eafb5f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5547bc0e-4b55-4bb8-b240-4d4d5b694e71\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5547bc0e-4b55-4bb8-b240-4d4d5b694e71 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLHABU7lMKFS",
        "outputId": "ad756e5e-cc26-4a8d-d0c4-defbeb33f46a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Preprocessing complete! Data saved to 'preprocessed_data.pkl'.\n"
          ]
        }
      ],
      "source": [
        "# Encode categorical columns\n",
        "for column in dataset.columns:\n",
        "    if dataset[column].dtype == 'object':\n",
        "        dataset[column] = LabelEncoder().fit_transform(dataset[column])\n",
        "\n",
        "# Separate features & target\n",
        "X = dataset.drop(['Class'], axis=1)\n",
        "y = dataset['Class']\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Balance dataset using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X, y = smote.fit_resample(X, y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Save preprocessed data\n",
        "with open(\"preprocessed_data.pkl\", \"wb\") as f:\n",
        "    pickle.dump((X_train, X_test, y_train, y_test), f)\n",
        "\n",
        "print(\"✅ Preprocessing complete! Data saved to 'preprocessed_data.pkl'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXfLTTuzM1TU"
      },
      "source": [
        "**PART 2: Feature Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7MsZuluMfpB",
        "outputId": "a7920547-151e-4270-976d-f847e849558e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Feature extraction complete! Data saved to 'features.pkl'.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load preprocessed data\n",
        "with open(\"preprocessed_data.pkl\", \"rb\") as f:\n",
        "    X_train, X_test, y_train, y_test = pickle.load(f)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "lr_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=500, random_state=42)\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Extract probability features\n",
        "train_lr_features = lr_model.predict_proba(X_train)\n",
        "test_lr_features = lr_model.predict_proba(X_test)\n",
        "\n",
        "# Expand dimensions for BiLSTM\n",
        "train_lr_features = np.expand_dims(train_lr_features, axis=1)\n",
        "test_lr_features = np.expand_dims(test_lr_features, axis=1)\n",
        "\n",
        "# One-hot encode labels\n",
        "num_classes = len(np.unique(y_train))\n",
        "y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "# Save features and labels\n",
        "with open(\"features.pkl\", \"wb\") as f:\n",
        "    pickle.dump((train_lr_features, test_lr_features, y_train_encoded, y_test_encoded), f)\n",
        "\n",
        "print(\"✅ Feature extraction complete! Data saved to 'features.pkl'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do8DMX5CMzYT"
      },
      "source": [
        "**PART 3: Build & Train BiLSTM Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7kmwP8eMjEj",
        "outputId": "47f667ba-3cef-43a0-c3fc-8e03e4f0deb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 1.1120 - val_accuracy: 0.9999 - val_loss: 0.2996\n",
            "Epoch 2/10\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.3324 - val_accuracy: 0.9999 - val_loss: 0.2435\n",
            "Epoch 3/10\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.2847 - val_accuracy: 0.9999 - val_loss: 0.2287\n",
            "Epoch 4/10\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.2718 - val_accuracy: 0.9999 - val_loss: 0.2242\n",
            "Epoch 5/10\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.2681 - val_accuracy: 0.9999 - val_loss: 0.2230\n",
            "Epoch 6/10\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.2667 - val_accuracy: 0.9999 - val_loss: 0.2225\n",
            "Epoch 7/10\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.2664 - val_accuracy: 0.9999 - val_loss: 0.2225\n",
            "Epoch 8/10\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.2663 - val_accuracy: 0.9999 - val_loss: 0.2224\n",
            "Epoch 9/10\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.2661 - val_accuracy: 0.9999 - val_loss: 0.2218\n",
            "Epoch 10/10\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.2645 - val_accuracy: 0.9999 - val_loss: 0.2204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model training complete! Model saved to 'bilstm_model.h5'.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout, Input\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Load feature data\n",
        "with open(\"features.pkl\", \"rb\") as f:\n",
        "    train_lr_features, test_lr_features, y_train_encoded, y_test_encoded = pickle.load(f)\n",
        "\n",
        "# Define BiLSTM model\n",
        "bilstm_model = Sequential([\n",
        "    Input(shape=(1, train_lr_features.shape[2])),\n",
        "    Bidirectional(LSTM(32, return_sequences=True, kernel_regularizer=l2(0.002))),\n",
        "    Dropout(0.5),\n",
        "    Bidirectional(LSTM(16, kernel_regularizer=l2(0.002))),\n",
        "    Dropout(0.5),\n",
        "    Dense(y_train_encoded.shape[1], activation='softmax', kernel_regularizer=l2(0.002))\n",
        "])\n",
        "bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "bilstm_model.fit(\n",
        "    train_lr_features, y_train_encoded,\n",
        "    validation_data=(test_lr_features, y_test_encoded),\n",
        "    epochs=10, batch_size=256, verbose=1\n",
        ")\n",
        "\n",
        "# Save model\n",
        "bilstm_model.save(\"bilstm_model.h5\")\n",
        "print(\"✅ Model training complete! Model saved to 'bilstm_model.h5'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdyV67HBP-kg",
        "outputId": "3c2f5396-94c3-430d-f4e2-d2ba3ce5bee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step\n",
            "Accuracy: 0.9999462365591398\n",
            "Precision: 0.9999462403154785\n",
            "Recall: 0.9999462365591398\n",
            "F1-score: 0.999946234968669\n"
          ]
        }
      ],
      "source": [
        "# prompt: Please display a model Accuracy, precision, recall, and f1-score\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pickle\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout, Input\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# ... (Your existing code from Part 1 to Part 3) ...\n",
        "\n",
        "# Load the saved model\n",
        "bilstm_model = tf.keras.models.load_model(\"bilstm_model.h5\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_encoded = bilstm_model.predict(test_lr_features)\n",
        "y_pred = np.argmax(y_pred_encoded, axis=1)\n",
        "y_true = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRG7SmIbMpsI"
      },
      "source": [
        "**PART 4: Generate Adversarial Examples**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDBMoIlFQdin",
        "outputId": "e2c2b71d-b63a-497c-b48f-1d88c51c886f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting foolbox\n",
            "  Downloading foolbox-3.3.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from foolbox) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from foolbox) (1.13.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from foolbox) (75.1.0)\n",
            "Collecting eagerpy>=0.30.0 (from foolbox)\n",
            "  Downloading eagerpy-0.30.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: GitPython>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from foolbox) (3.1.44)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.11/dist-packages (from foolbox) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.11/dist-packages (from foolbox) (2.32.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython>=3.0.7->foolbox) (4.0.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox) (2024.12.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (5.0.2)\n",
            "Downloading foolbox-3.3.4-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eagerpy-0.30.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: eagerpy, foolbox\n",
            "Successfully installed eagerpy-0.30.0 foolbox-3.3.4\n"
          ]
        }
      ],
      "source": [
        "!pip install foolbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPcjbQpnMm7V",
        "outputId": "aef77f54-3bb9-4884-c47a-d76cd394fdd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Error: Physical devices cannot be modified after being initialized\n",
            "✅ Model recompiled successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/foolbox/models/tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Generating FGSM Attack...\n",
            "🔹 Running LinfFastGradientAttack (ε=0.01)...\n",
            "\n",
            "🔹 Generating PGD Attack...\n",
            "🔹 Running LinfProjectedGradientDescentAttack (ε=0.02)...\n",
            "\n",
            "🔹 Generating CW Attack (Optimized)...\n",
            "🔹 Running L2CarliniWagnerAttack (ε=0.01)...\n",
            "\n",
            "✅ Adversarial examples generated & saved to 'adversarial_examples.pkl'.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "# ✅ Step 1: Set TensorFlow to Allocate GPU Memory Dynamically\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"✅ Enabled dynamic GPU memory allocation\")\n",
        "    except RuntimeError as e:\n",
        "        print(\"❌ Error:\", e)\n",
        "\n",
        "# ✅ Step 2: Load Model & Data\n",
        "bilstm_model = load_model(\"bilstm_model.h5\")\n",
        "\n",
        "# ✅ Step 3: Recompile Model After Loading\n",
        "bilstm_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "print(\"✅ Model recompiled successfully!\")\n",
        "\n",
        "# ✅ Step 4: Load Features & Labels\n",
        "with open(\"features.pkl\", \"rb\") as f:\n",
        "    train_lr_features, test_lr_features, y_train_encoded, y_test_encoded = pickle.load(f)\n",
        "\n",
        "# ✅ Step 5: Convert to Foolbox Model\n",
        "fmodel = fb.TensorFlowModel(bilstm_model, bounds=(0, 1))\n",
        "\n",
        "# ✅ Step 6: Define Adversarial Example Generation Function\n",
        "def generate_adversarial_examples(attack, eps):\n",
        "    print(f\"🔹 Running {attack.__class__.__name__} (ε={eps})...\")\n",
        "    raw_adversarials, *_ = attack(\n",
        "        fmodel,\n",
        "        tf.convert_to_tensor(test_lr_features, dtype=tf.float32),\n",
        "        np.argmax(y_test_encoded, axis=1),\n",
        "        epsilons=eps\n",
        "    )\n",
        "    return raw_adversarials.numpy()\n",
        "\n",
        "# ✅ Step 7: Run Attacks\n",
        "print(\"\\n🔹 Generating FGSM Attack...\")\n",
        "adv_fgsm = generate_adversarial_examples(fb.attacks.FGSM(), 0.01)\n",
        "\n",
        "print(\"\\n🔹 Generating PGD Attack...\")\n",
        "adv_pgd = generate_adversarial_examples(fb.attacks.LinfPGD(steps=10), 0.02)\n",
        "\n",
        "print(\"\\n🔹 Generating CW Attack (Optimized)...\")\n",
        "adv_cw = generate_adversarial_examples(fb.attacks.L2CarliniWagnerAttack(binary_search_steps=3, steps=5), 0.01)\n",
        "\n",
        "# ✅ Step 8: Save Adversarial Examples\n",
        "with open(\"adversarial_examples.pkl\", \"wb\") as f:\n",
        "    pickle.dump((adv_fgsm, adv_pgd, adv_cw), f)\n",
        "\n",
        "print(\"\\n✅ Adversarial examples generated & saved to 'adversarial_examples.pkl'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCELSg0LNBYC"
      },
      "source": [
        "**PART 5: Adversarial Training & Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1S-Cm2KM-2n",
        "outputId": "f17c224a-879b-4183-b583-c0752b16ab20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m11625/11625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - accuracy: 0.3253 - loss: 2.2541\n",
            "Epoch 2/5\n",
            "\u001b[1m11625/11625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - accuracy: 0.3241 - loss: 2.1963\n",
            "Epoch 3/5\n",
            "\u001b[1m11625/11625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - accuracy: 0.3255 - loss: 2.1950\n",
            "Epoch 4/5\n",
            "\u001b[1m11625/11625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7ms/step - accuracy: 0.3252 - loss: 2.1958\n",
            "Epoch 5/5\n",
            "\u001b[1m11625/11625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7ms/step - accuracy: 0.3241 - loss: 2.1968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Adversarial training complete! Model saved as 'bilstm_model_adversarial.h5'.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# Load model, adversarial examples & data\n",
        "bilstm_model = load_model(\"bilstm_model.h5\")\n",
        "\n",
        "with open(\"features.pkl\", \"rb\") as f:\n",
        "    train_lr_features, test_lr_features, y_train_encoded, y_test_encoded = pickle.load(f)\n",
        "\n",
        "with open(\"adversarial_examples.pkl\", \"rb\") as f:\n",
        "    adv_fgsm, adv_pgd, adv_cw = pickle.load(f)\n",
        "\n",
        "# Ensure all adversarial examples have the same shape as train_lr_features\n",
        "min_samples = min(train_lr_features.shape[0], adv_fgsm.shape[0], adv_pgd.shape[0], adv_cw.shape[0])\n",
        "\n",
        "# Trim all feature sets to the minimum number of samples to avoid mismatch\n",
        "train_lr_features = train_lr_features[:min_samples]\n",
        "adv_fgsm = adv_fgsm[:min_samples]\n",
        "adv_pgd = adv_pgd[:min_samples]\n",
        "adv_cw = adv_cw[:min_samples]\n",
        "\n",
        "# Trim labels to match the correct number of features\n",
        "y_train_encoded = y_train_encoded[:min_samples]\n",
        "\n",
        "# Combine clean and adversarial data\n",
        "combined_features = np.vstack([train_lr_features, adv_fgsm, adv_pgd, adv_cw])\n",
        "combined_labels = np.vstack([y_train_encoded] * 4)  # Ensure correct duplication\n",
        "\n",
        "# Ensure combined features and labels match in shape\n",
        "assert combined_features.shape[0] == combined_labels.shape[0], \"Mismatch in features & labels!\"\n",
        "\n",
        "# Recompile model (ensuring it's ready for training)\n",
        "bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Retrain model with adversarial data\n",
        "bilstm_model.fit(combined_features, combined_labels, epochs=5, batch_size=64, verbose=1)\n",
        "\n",
        "# Save updated model\n",
        "bilstm_model.save(\"bilstm_model_adversarial.h5\")\n",
        "print(\"✅ Adversarial training complete! Model saved as 'bilstm_model_adversarial.h5'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxW0LDo0YNjp"
      },
      "source": [
        "**Part 6: Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP4ZY-D4X6zp",
        "outputId": "6b82f8f6-f2c0-4a12-9e6b-e47c5d2e75e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "#Step 1: Load Trained Model & Data\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import foolbox as fb\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the trained adversarial model\n",
        "bilstm_model = load_model(\"bilstm_model_adversarial.h5\")\n",
        "\n",
        "# Load test dataset\n",
        "with open(\"features.pkl\", \"rb\") as f:\n",
        "    _, test_lr_features, _, y_test_encoded = pickle.load(f)\n",
        "\n",
        "# Convert test data to TensorFlow tensor\n",
        "test_features_tf = tf.convert_to_tensor(test_lr_features, dtype=tf.float32)\n",
        "true_labels = np.argmax(y_test_encoded, axis=1)  # Convert one-hot labels to class indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SvZXWIOX6fT",
        "outputId": "fc2d9a19-002e-477c-ca3b-c0d7f3639b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step\n",
            "✅ Test Accuracy on Clean Data: 0.99994086\n"
          ]
        }
      ],
      "source": [
        "#Step 2: Evaluate Model on Clean Test Data\n",
        "# Evaluate on clean test data\n",
        "test_predictions = bilstm_model.predict(test_lr_features)\n",
        "test_pred_labels = np.argmax(test_predictions, axis=1)\n",
        "\n",
        "# Compute Accuracy\n",
        "accuracy_clean = accuracy_score(true_labels, test_pred_labels)\n",
        "print(f\"✅ Test Accuracy on Clean Data: {accuracy_clean:.8f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o25ojgUyX6bo",
        "outputId": "42cec1cf-b6f5-4492-b690-61625aa320f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Running FGSM Attack...\n",
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step\n",
            "✅ FGSM Attack Accuracy: 0.99994086\n"
          ]
        }
      ],
      "source": [
        "#Step 3: Evaluate Robustness Against FGSM, PGD, and CW Attacks\n",
        "\n",
        "print(\"\\n🔹 Running FGSM Attack...\")\n",
        "fmodel = fb.TensorFlowModel(bilstm_model, bounds=(0, 1))\n",
        "attack_fgsm = fb.attacks.FGSM()\n",
        "adv_fgsm, _, _ = attack_fgsm(fmodel, test_features_tf, true_labels, epsilons=0.02)\n",
        "\n",
        "# Get model predictions on FGSM adversarial examples\n",
        "fgsm_preds = bilstm_model.predict(adv_fgsm.numpy())\n",
        "fgsm_preds_labels = np.argmax(fgsm_preds, axis=1)\n",
        "\n",
        "# Compute FGSM Accuracy\n",
        "accuracy_fgsm = accuracy_score(true_labels, fgsm_preds_labels)\n",
        "print(f\"✅ FGSM Attack Accuracy: {accuracy_fgsm:.8f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJKxtBI3YUfc",
        "outputId": "182c4034-aa26-4f6c-ae23-e6a70964402f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Running PGD Attack...\n",
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step\n",
            "✅ PGD Attack Accuracy: 0.99994086\n"
          ]
        }
      ],
      "source": [
        "#PGD Attack\n",
        "\n",
        "print(\"\\n🔹 Running PGD Attack...\")\n",
        "attack_pgd = fb.attacks.LinfPGD(steps=10)\n",
        "adv_pgd, _, _ = attack_pgd(fmodel, test_features_tf, true_labels, epsilons=0.02)\n",
        "\n",
        "# Get model predictions on PGD adversarial examples\n",
        "pgd_preds = bilstm_model.predict(adv_pgd.numpy())\n",
        "pgd_preds_labels = np.argmax(pgd_preds, axis=1)\n",
        "\n",
        "# Compute PGD Accuracy\n",
        "accuracy_pgd = accuracy_score(true_labels, pgd_preds_labels)\n",
        "print(f\"✅ PGD Attack Accuracy: {accuracy_pgd:.8f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h40XFzeaYUbt",
        "outputId": "94fe4d5d-b851-4da4-cf3a-0a55865913df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Running CW Attack...\n",
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step\n",
            "✅ CW Attack Accuracy: 0.10000000\n"
          ]
        }
      ],
      "source": [
        "#CW Attack\n",
        "\n",
        "print(\"\\n🔹 Running CW Attack...\")\n",
        "attack_cw = fb.attacks.L2CarliniWagnerAttack(binary_search_steps=10, steps=10)\n",
        "adv_cw, _, _ = attack_cw(fmodel, test_features_tf, true_labels, epsilons=0.01)\n",
        "\n",
        "# Get model predictions on CW adversarial examples\n",
        "cw_preds = bilstm_model.predict(adv_cw.numpy())\n",
        "cw_preds_labels = np.argmax(cw_preds, axis=1)\n",
        "\n",
        "# Compute CW Accuracy\n",
        "accuracy_cw = accuracy_score(true_labels, cw_preds_labels)\n",
        "print(f\"✅ CW Attack Accuracy: {accuracy_cw:.8f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeCLbKBeYmi7",
        "outputId": "f8c17066-51ae-4bfd-b8bc-77a2cbb172ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Evaluation metrics saved successfully!\n"
          ]
        }
      ],
      "source": [
        "#Step 4: Save Evaluation Metrics\n",
        "\n",
        "# Save results\n",
        "evaluation_results = {\n",
        "    \"clean_accuracy\": accuracy_clean,\n",
        "    \"fgsm_accuracy\": accuracy_fgsm,\n",
        "    \"pgd_accuracy\": accuracy_pgd,\n",
        "    \"cw_accuracy\": accuracy_cw,\n",
        "}\n",
        "\n",
        "with open(\"evaluation_results.pkl\", \"wb\") as f:\n",
        "    pickle.dump(evaluation_results, f)\n",
        "\n",
        "print(\"\\n✅ Evaluation metrics saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XSvj_wiacKy"
      },
      "source": [
        "**Improving CW Robustness**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKFOIC7SaRsv"
      },
      "source": [
        "**🔧 Step 1: Update CW Adversarial Training Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BBXiCpm1aSmz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "\n",
        "def generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=0.01, steps=10, batch_size=256):\n",
        "    \"\"\"\n",
        "    Generate Carlini-Wagner (CW) adversarial examples in batches.\n",
        "    \"\"\"\n",
        "    fmodel = fb.TensorFlowModel(model, bounds=(0, 1))\n",
        "    cw_attack = fb.attacks.L2CarliniWagnerAttack(binary_search_steps=10, steps=steps)\n",
        "\n",
        "    print(f\"\\n🔹 Generating CW Adversarial Examples (epsilon={epsilon}, steps={steps})...\")\n",
        "\n",
        "    # Convert labels to class indices\n",
        "    train_labels_indices = np.argmax(train_labels, axis=1)\n",
        "    train_features_tf = tf.convert_to_tensor(train_features, dtype=tf.float32)\n",
        "\n",
        "    adv_examples_list = []\n",
        "\n",
        "    for i in range(0, len(train_features), batch_size):\n",
        "        batch_features = train_features_tf[i:i + batch_size]\n",
        "        batch_labels = train_labels_indices[i:i + batch_size]\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        adv_batch = cw_attack(fmodel, batch_features, batch_labels, epsilons=epsilon)\n",
        "\n",
        "        if isinstance(adv_batch, (tuple, list)):\n",
        "            adv_batch_np = np.array(adv_batch[0])\n",
        "        elif tf.is_tensor(adv_batch):\n",
        "            adv_batch_np = adv_batch.numpy()\n",
        "        else:\n",
        "            adv_batch_np = adv_batch\n",
        "\n",
        "        adv_examples_list.append(adv_batch_np)\n",
        "\n",
        "    # Ensure consistent shape\n",
        "    adv_examples_np = np.concatenate(adv_examples_list, axis=0)\n",
        "\n",
        "    return adv_examples_np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp0lwUuYaYBS"
      },
      "source": [
        "**🔧 Step 2: Train with Stronger CW Adversarial Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "36W7a7XzaVoX"
      },
      "outputs": [],
      "source": [
        "def adversarial_training_with_cw(model, train_features, train_labels, batch_size=64, epochs=5):\n",
        "    \"\"\"\n",
        "    Train the model using a combination of clean, FGSM, PGD, and CW adversarial examples.\n",
        "    \"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\n🔹 Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Increase CW attack strength per epoch\n",
        "        cw_steps = 20 + (epoch * 5)\n",
        "        cw_epsilon = 0.005 + (epoch / epochs) * 0.02\n",
        "\n",
        "        print(f\"\\n🔹 Generating CW Adversarial Examples (steps={cw_steps}, epsilon={cw_epsilon})...\")\n",
        "        adv_cw = generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=cw_epsilon, steps=cw_steps)\n",
        "\n",
        "        print(f\"\\n🔹 Generating PGD Adversarial Examples...\")\n",
        "        attack_pgd = fb.attacks.LinfPGD(steps=10)\n",
        "        adv_pgd, _, _ = attack_pgd(fb.TensorFlowModel(model, bounds=(0, 1)), tf.convert_to_tensor(train_features, dtype=tf.float32), np.argmax(train_labels, axis=1), epsilons=0.02)\n",
        "\n",
        "        print(f\"\\n🔹 Generating FGSM Adversarial Examples...\")\n",
        "        attack_fgsm = fb.attacks.FGSM()\n",
        "        adv_fgsm, _, _ = attack_fgsm(fb.TensorFlowModel(model, bounds=(0, 1)), tf.convert_to_tensor(train_features, dtype=tf.float32), np.argmax(train_labels, axis=1), epsilons=0.01)\n",
        "\n",
        "        # Convert back to NumPy\n",
        "        adv_pgd = adv_pgd.numpy()\n",
        "        adv_fgsm = adv_fgsm.numpy()\n",
        "\n",
        "        # Ensure all shapes are consistent before concatenation\n",
        "        min_shape = min(train_features.shape[1], adv_cw.shape[1], adv_pgd.shape[1], adv_fgsm.shape[1])\n",
        "        train_features = train_features[:, :min_shape]\n",
        "        adv_cw = adv_cw[:, :min_shape]\n",
        "        adv_pgd = adv_pgd[:, :min_shape]\n",
        "        adv_fgsm = adv_fgsm[:, :min_shape]\n",
        "\n",
        "        # Combine clean and adversarial examples\n",
        "        combined_features = np.vstack([train_features, adv_cw, adv_pgd, adv_fgsm])\n",
        "        combined_labels = np.vstack([train_labels, train_labels, train_labels, train_labels])\n",
        "\n",
        "        # Shuffle dataset\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((combined_features, combined_labels))\n",
        "        dataset = dataset.shuffle(buffer_size=len(combined_features)).batch(batch_size)\n",
        "\n",
        "        print(\"🔹 Training on CW-Enhanced Adversarial Dataset...\")\n",
        "        model.fit(dataset, epochs=1, verbose=1)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6J51d4lwKOu"
      },
      "source": [
        "**📌 Step 3: Re-run CW Training & Re-Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L00SRdKBwJzh",
        "outputId": "77264952-8a0c-48df-f19f-9fdf8636c9d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔹 Epoch 1/5\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (steps=20, epsilon=0.005)...\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (epsilon=0.005, steps=20)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-24-a4dbf15f0567>\", line 2, in <cell line: 0>\n",
            "    bilstm_model = adversarial_training_with_cw(bilstm_model, train_lr_features, y_train_encoded, batch_size=64, epochs=5)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-23-0095a5e8a279>\", line 13, in adversarial_training_with_cw\n",
            "    adv_cw = generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=cw_epsilon, steps=cw_steps)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-22-d23b7b4f0134>\", line 25, in generate_cw_adversarial_examples\n",
            "    adv_batch = cw_attack(fmodel, batch_features, batch_labels, epsilons=epsilon)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/foolbox/attacks/base.py\", line 416, in __call__\n",
            "    xp = self.run(model, x, criterion, early_stop=early_stop, **kwargs)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/foolbox/attacks/carlini_wagner.py\", line 170, in run\n",
            "    loss, (perturbed, logits), gradient = loss_aux_and_grad(delta, consts_)\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/eagerpy/tensor/tensorflow.py\", line 482, in value_and_grad\n",
            "    grad = tape.gradient(loss.raw, x_.raw)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/backprop.py\", line 1066, in gradient\n",
            "    flat_grad = imperative_grad.imperative_grad(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/imperative_grad.py\", line 67, in imperative_grad\n",
            "    return pywrap_tfe.TFE_Py_TapeGradient(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/backprop.py\", line 148, in _gradient_function\n",
            "    return grad_fn(mock_op, *out_grads)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/array_grad.py\", line 865, in _TransposeGrad\n",
            "    return [array_ops.transpose(grad, array_ops.invert_permutation(p)), None]\n",
            "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 4666, in invert_permutation\n",
            "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1684, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "               ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 948, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 987, in getmodule\n",
            "    for modname, module in sys.modules.copy().items():\n",
            "                           ^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-a4dbf15f0567>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model with enhanced CW adversarial training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbilstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial_training_with_cw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbilstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_lr_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-0095a5e8a279>\u001b[0m in \u001b[0;36madversarial_training_with_cw\u001b[0;34m(model, train_features, train_labels, batch_size, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n🔹 Generating CW Adversarial Examples (steps={cw_steps}, epsilon={cw_epsilon})...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0madv_cw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_cw_adversarial_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcw_epsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcw_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-d23b7b4f0134>\u001b[0m in \u001b[0;36mgenerate_cw_adversarial_examples\u001b[0;34m(model, train_features, train_labels, epsilon, steps, batch_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Generate adversarial examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0madv_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcw_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/foolbox/attacks/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# run the actual attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/foolbox/attacks/carlini_wagner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mperturbed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_aux_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0mdelta\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/eagerpy/tensor/tensorflow.py\u001b[0m in \u001b[0;36mvalue_and_grad\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    481\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorFlowTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_TransposeGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvert_permutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36minvert_permutation\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m   4665\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4666\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   4667\u001b[0m         _ctx, \"InvertPermutation\", name, x)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "# Train the model with enhanced CW adversarial training\n",
        "bilstm_model = adversarial_training_with_cw(bilstm_model, train_lr_features, y_train_encoded, batch_size=64, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdCB7v9EJb4H"
      },
      "source": [
        "**Optimized Code: Faster Adversarial Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "kbqTCt85JZ0z",
        "outputId": "77140632-d638-4da7-b8b4-ece10b821fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Epoch 1/3\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (steps=40, epsilon=0.03)...\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (epsilon=0.03, steps=40)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-bb1e6fa8741d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Train the model with optimized CW adversarial training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mbilstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial_training_with_cw_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbilstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_lr_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-bb1e6fa8741d>\u001b[0m in \u001b[0;36madversarial_training_with_cw_optimized\u001b[0;34m(model, train_features, train_labels, batch_size, epochs, sample_ratio)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n🔹 Generating CW Adversarial Examples (steps={cw_steps}, epsilon={cw_epsilon})...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0madv_cw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_cw_adversarial_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcw_epsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcw_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n🔹 Generating PGD Adversarial Examples...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-a7c2d4bd0e27>\u001b[0m in \u001b[0;36mgenerate_cw_adversarial_examples\u001b[0;34m(model, train_features, train_labels, epsilon, steps, batch_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Generate adversarial examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0madv_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcw_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/foolbox/attacks/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# run the actual attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mxpcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/foolbox/attacks/carlini_wagner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mperturbed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_aux_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0mdelta\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/eagerpy/tensor/tensorflow.py\u001b[0m in \u001b[0;36mvalue_and_grad\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/foolbox/attacks/carlini_wagner.py\u001b[0m in \u001b[0;36mloss_fun\u001b[0;34m(delta, consts)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mis_adv_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mis_adv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_adv_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0mis_adv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_adv_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mis_adv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_adv_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/eagerpy/tensor/base.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorOrScalar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munwrap1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/override_binary_operator.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/tensor_math_operator_overrides.py\u001b[0m in \u001b[0;36m_add_dispatch_factory\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1715\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0mTV_AddV2_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TV_AddV2_T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBFloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComplex128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComplex64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHalf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUInt16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUInt32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUInt64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUInt8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAnnotated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTV_AddV2_T\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAnnotated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTV_AddV2_T\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAnnotated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTV_AddV2_T\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   r\"\"\"Returns x + y element-wise.\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "\n",
        "# ✅ Force eager execution for TF (Fix for NotImplementedError)\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "def safe_numpy(tensor):\n",
        "    \"\"\"Convert tensor to numpy only if eager execution is enabled\"\"\"\n",
        "    if tf.executing_eagerly():\n",
        "        return tensor.numpy()\n",
        "    return tensor  # Return unchanged if eager execution is disabled\n",
        "# **Generate CW Adversarial Examples (Optimized for Stability)**\n",
        "#def generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=0.03, steps=40, batch_size=256):\n",
        "\n",
        "def adversarial_training_with_cw_optimized(model, train_features, train_labels, batch_size=64, epochs=2, sample_ratio=0.5):\n",
        "    \"\"\"\n",
        "    Train the model using a combination of clean, FGSM, PGD, and CW adversarial examples.\n",
        "    \"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\n🔹 Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Increase CW attack strength per epoch\n",
        "        #cw_steps = 10 + (epoch * 5)\n",
        "        #cw_epsilon = 0.005 + (epoch / epochs) * 0.02\n",
        "\n",
        "        cw_steps = 40 + (epoch * 10)  # Increase steps for better optimization\n",
        "        cw_epsilon = 0.03 + (epoch / epochs) * 0.02  # Increase attack strength\n",
        "\n",
        "        print(f\"\\n🔹 Generating CW Adversarial Examples (steps={cw_steps}, epsilon={cw_epsilon})...\")\n",
        "        adv_cw = generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=cw_epsilon, steps=cw_steps)\n",
        "\n",
        "        print(f\"\\n🔹 Generating PGD Adversarial Examples...\")\n",
        "        attack_pgd = fb.attacks.LinfPGD(steps=10)\n",
        "        adv_pgd, _, _ = attack_pgd(fb.TensorFlowModel(model, bounds=(0, 1)), tf.convert_to_tensor(train_features, dtype=tf.float32), np.argmax(train_labels, axis=1), epsilons=0.02)\n",
        "\n",
        "        print(f\"\\n🔹 Generating FGSM Adversarial Examples...\")\n",
        "        attack_fgsm = fb.attacks.FGSM()\n",
        "        adv_fgsm, _, _ = attack_fgsm(fb.TensorFlowModel(model, bounds=(0, 1)), tf.convert_to_tensor(train_features, dtype=tf.float32), np.argmax(train_labels, axis=1), epsilons=0.01)\n",
        "\n",
        "        # Convert back to NumPy\n",
        "        adv_pgd = adv_pgd.numpy()\n",
        "        adv_fgsm = adv_fgsm.numpy()\n",
        "\n",
        "        # Ensure all shapes are consistent before concatenation\n",
        "        min_shape = min(train_features.shape[1], adv_cw.shape[1], adv_pgd.shape[1], adv_fgsm.shape[1])\n",
        "        train_features = train_features[:, :min_shape]\n",
        "        adv_cw = adv_cw[:, :min_shape]\n",
        "        adv_pgd = adv_pgd[:, :min_shape]\n",
        "        adv_fgsm = adv_fgsm[:, :min_shape]\n",
        "\n",
        "        # Combine clean and adversarial examples\n",
        "        combined_features = np.vstack([train_features, adv_cw, adv_pgd, adv_fgsm])\n",
        "        combined_labels = np.vstack([train_labels, train_labels, train_labels, train_labels])\n",
        "\n",
        "        # **Fix: Recompile the model to reset the optimizer**\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "\n",
        "        # Shuffle dataset\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((combined_features, combined_labels))\n",
        "        dataset = dataset.shuffle(buffer_size=len(combined_features)).batch(batch_size)\n",
        "\n",
        "        print(\"🔹 Training on CW-Optimized Adversarial Dataset...\")\n",
        "        model.fit(dataset, epochs=1, verbose=1)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train the model with optimized CW adversarial training\n",
        "bilstm_model = adversarial_training_with_cw_optimized(bilstm_model, train_lr_features, y_train_encoded, batch_size=64, epochs=3, sample_ratio=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import foolbox as fb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate_adversarial_robustness(model, test_features, test_labels, epsilon=0.02):\n",
        "    \"\"\"\n",
        "    Evaluate model robustness against FGSM, PGD, and CW attacks.\n",
        "    \"\"\"\n",
        "    fmodel = fb.TensorFlowModel(model, bounds=(0, 1))\n",
        "\n",
        "    print(\"\\n🔹 Running FGSM Attack...\")\n",
        "    attack_fgsm = fb.attacks.FGSM()\n",
        "    adv_fgsm, *_ = attack_fgsm(fmodel, tf.convert_to_tensor(test_features, dtype=tf.float32), np.argmax(test_labels, axis=1), epsilons=epsilon)\n",
        "    fgsm_predictions = np.argmax(model.predict(adv_fgsm.numpy()), axis=1)\n",
        "    fgsm_accuracy = accuracy_score(np.argmax(test_labels, axis=1), fgsm_predictions)\n",
        "\n",
        "    print(\"\\n🔹 Running PGD Attack...\")\n",
        "    attack_pgd = fb.attacks.LinfPGD(steps=10)\n",
        "    adv_pgd, *_ = attack_pgd(fmodel, tf.convert_to_tensor(test_features, dtype=tf.float32), np.argmax(test_labels, axis=1), epsilons=epsilon)\n",
        "    pgd_predictions = np.argmax(model.predict(adv_pgd.numpy()), axis=1)\n",
        "    pgd_accuracy = accuracy_score(np.argmax(test_labels, axis=1), pgd_predictions)\n",
        "\n",
        "    print(\"\\n🔹 Running CW Attack...\")\n",
        "    attack_cw = fb.attacks.L2CarliniWagnerAttack(binary_search_steps=5, steps=10)\n",
        "    adv_cw, *_ = attack_cw(fmodel, tf.convert_to_tensor(test_features, dtype=tf.float32), np.argmax(test_labels, axis=1), epsilons=epsilon)\n",
        "    cw_predictions = np.argmax(model.predict(adv_cw.numpy()), axis=1)\n",
        "    cw_accuracy = accuracy_score(np.argmax(test_labels, axis=1), cw_predictions)\n",
        "\n",
        "    return fgsm_accuracy, pgd_accuracy, cw_accuracy"
      ],
      "metadata": {
        "id": "R_6MvCIAffBm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQoMZ3FMwSrN"
      },
      "source": [
        "**📌 Step 4: Re-Evaluate CW Attack Performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PRRsk_INwTj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b46cad69-a91a-47c0-b8a9-57f801c5babd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Running FGSM Attack...\n",
            "\u001b[1m   3/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:39\u001b[0m 27ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 29ms/step\n",
            "\n",
            "🔹 Running PGD Attack...\n",
            "\u001b[1m   3/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:41\u001b[0m 28ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 29ms/step\n",
            "\n",
            "🔹 Running CW Attack...\n",
            "\u001b[1m   3/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:40\u001b[0m 28ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 28ms/step\n",
            "\n",
            "✅ FGSM Attack Accuracy (After CW Training): 0.99994086\n",
            "✅ PGD Attack Accuracy (After CW Training): 0.99994086\n",
            "✅ CW Attack Accuracy (After CW Training): 0.10000000\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model performance against adversarial attacks\n",
        "fgsm_acc, pgd_acc, cw_acc = evaluate_adversarial_robustness(bilstm_model, test_lr_features, y_test_encoded)\n",
        "\n",
        "# Print Updated Accuracy After CW Training\n",
        "print(f\"\\n✅ FGSM Attack Accuracy (After CW Training): {fgsm_acc:.8f}\")\n",
        "print(f\"✅ PGD Attack Accuracy (After CW Training): {pgd_acc:.8f}\")\n",
        "print(f\"✅ CW Attack Accuracy (After CW Training): {cw_acc:.8f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "\n",
        "# ✅ Ensure eager execution for TensorFlow (fixes certain execution issues)\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "def safe_numpy(tensor):\n",
        "    \"\"\"Convert tensor to numpy only if eager execution is enabled\"\"\"\n",
        "    if tf.executing_eagerly():\n",
        "        return tensor.numpy()\n",
        "    return tensor  # Return unchanged if eager execution is disabled\n",
        "\n",
        "# **Generate CW Adversarial Examples (Optimized for Stability)**\n",
        "def generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=0.03, steps=40, batch_size=256):\n",
        "    \"\"\"\n",
        "    Generate Carlini-Wagner (CW) adversarial examples in batches with increased attack strength.\n",
        "    \"\"\"\n",
        "    fmodel = fb.TensorFlowModel(model, bounds=(0, 1))\n",
        "    cw_attack = fb.attacks.L2CarliniWagnerAttack(binary_search_steps=10, steps=steps)\n",
        "\n",
        "    print(f\"\\n🔹 Generating CW Adversarial Examples (epsilon={epsilon}, steps={steps})...\")\n",
        "\n",
        "    # Convert labels to class indices\n",
        "    train_labels_indices = np.argmax(train_labels, axis=1)\n",
        "    train_features_tf = tf.convert_to_tensor(train_features, dtype=tf.float32)\n",
        "\n",
        "    adv_examples_list = []\n",
        "\n",
        "    for i in range(0, len(train_features), batch_size):\n",
        "        batch_features = train_features_tf[i:i + batch_size]\n",
        "        batch_labels = train_labels_indices[i:i + batch_size]\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        adv_batch = cw_attack(fmodel, batch_features, batch_labels, epsilons=epsilon)\n",
        "\n",
        "        # Convert to NumPy format\n",
        "        if isinstance(adv_batch, (tuple, list)):\n",
        "            adv_batch_np = np.array(adv_batch[0])\n",
        "        elif tf.is_tensor(adv_batch):\n",
        "            adv_batch_np = adv_batch.numpy()\n",
        "        else:\n",
        "            adv_batch_np = adv_batch\n",
        "\n",
        "        adv_examples_list.append(adv_batch_np)\n",
        "\n",
        "    # Stack adversarial examples\n",
        "    adv_examples_np = np.vstack(adv_examples_list)\n",
        "\n",
        "    return adv_examples_np\n",
        "\n",
        "# **Optimized CW Adversarial Training**\n",
        "def adversarial_training_with_cw_optimized(model, train_features, train_labels, batch_size=64, epochs=3, sample_ratio=0.5):\n",
        "    \"\"\"\n",
        "    Train the model using a combination of clean, FGSM, PGD, and CW adversarial examples.\n",
        "    \"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\n🔹 Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Increase CW attack strength per epoch\n",
        "        cw_steps = 40 + (epoch * 10)  # Increase steps for better optimization\n",
        "        cw_epsilon = 0.03 + (epoch / epochs) * 0.02  # Increase attack strength\n",
        "\n",
        "        print(f\"\\n🔹 Generating CW Adversarial Examples (steps={cw_steps}, epsilon={cw_epsilon})...\")\n",
        "        adv_cw = generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=cw_epsilon, steps=cw_steps)\n",
        "\n",
        "        print(f\"\\n🔹 Generating PGD Adversarial Examples...\")\n",
        "        attack_pgd = fb.attacks.LinfPGD(steps=10)\n",
        "        adv_pgd, _, _ = attack_pgd(fb.TensorFlowModel(model, bounds=(0, 1)), tf.convert_to_tensor(train_features, dtype=tf.float32), np.argmax(train_labels, axis=1), epsilons=0.02)\n",
        "\n",
        "        print(f\"\\n🔹 Generating FGSM Adversarial Examples...\")\n",
        "        attack_fgsm = fb.attacks.FGSM()\n",
        "        adv_fgsm, _, _ = attack_fgsm(fb.TensorFlowModel(model, bounds=(0, 1)), tf.convert_to_tensor(train_features, dtype=tf.float32), np.argmax(train_labels, axis=1), epsilons=0.01)\n",
        "\n",
        "        # Convert back to NumPy\n",
        "        adv_pgd = safe_numpy(adv_pgd)\n",
        "        adv_fgsm = safe_numpy(adv_fgsm)\n",
        "\n",
        "        # **Reduce dataset size to control training time**\n",
        "        sample_size = int(len(train_features) * sample_ratio)\n",
        "        train_features = train_features[:sample_size]\n",
        "        train_labels = train_labels[:sample_size]\n",
        "        adv_cw = adv_cw[:sample_size]\n",
        "        adv_pgd = adv_pgd[:sample_size]\n",
        "        adv_fgsm = adv_fgsm[:sample_size]\n",
        "\n",
        "        # Ensure all shapes are consistent before concatenation\n",
        "        min_shape = min(train_features.shape[1], adv_cw.shape[1], adv_pgd.shape[1], adv_fgsm.shape[1])\n",
        "        train_features = train_features[:, :min_shape]\n",
        "        adv_cw = adv_cw[:, :min_shape]\n",
        "        adv_pgd = adv_pgd[:, :min_shape]\n",
        "        adv_fgsm = adv_fgsm[:, :min_shape]\n",
        "\n",
        "        # Combine clean and adversarial examples\n",
        "        combined_features = np.vstack([train_features, adv_cw, adv_pgd, adv_fgsm])\n",
        "        combined_labels = np.vstack([train_labels, train_labels, train_labels, train_labels])\n",
        "\n",
        "        # **Fix: Recompile the model to reset the optimizer**\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), metrics=['accuracy'])\n",
        "\n",
        "        # Shuffle dataset\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((combined_features, combined_labels))\n",
        "        dataset = dataset.shuffle(buffer_size=len(combined_features)).batch(batch_size)\n",
        "\n",
        "        print(\"🔹 Training on CW-Optimized Adversarial Dataset...\")\n",
        "        model.fit(dataset, epochs=1, verbose=1)\n",
        "\n",
        "    return model\n",
        "\n",
        "# **Train the Model with Optimized CW Adversarial Training**\n",
        "bilstm_model = adversarial_training_with_cw_optimized(bilstm_model, train_lr_features, y_train_encoded, batch_size=64, epochs=2, sample_ratio=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZAoo76fqF5z",
        "outputId": "74e7437b-f87a-4892-edd9-a758d67742ad"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Epoch 1/2\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (steps=40, epsilon=0.03)...\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (epsilon=0.03, steps=40)...\n",
            "\n",
            "🔹 Generating PGD Adversarial Examples...\n",
            "\n",
            "🔹 Generating FGSM Adversarial Examples...\n",
            "🔹 Training on CW-Optimized Adversarial Dataset...\n",
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m829s\u001b[0m 143ms/step - accuracy: 0.7742 - loss: 0.8249\n",
            "\n",
            "🔹 Epoch 2/2\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (steps=50, epsilon=0.04)...\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (epsilon=0.04, steps=50)...\n",
            "\n",
            "🔹 Generating PGD Adversarial Examples...\n",
            "\n",
            "🔹 Generating FGSM Adversarial Examples...\n",
            "🔹 Training on CW-Optimized Adversarial Dataset...\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 139ms/step - accuracy: 0.7755 - loss: 0.8220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance against adversarial attacks\n",
        "fgsm_acc, pgd_acc, cw_acc = evaluate_adversarial_robustness(bilstm_model, test_lr_features, y_test_encoded)\n",
        "\n",
        "# Print Updated Accuracy After CW Training\n",
        "print(f\"\\n✅ FGSM Attack Accuracy (After CW Training): {fgsm_acc:.8f}\")\n",
        "print(f\"✅ PGD Attack Accuracy (After CW Training): {pgd_acc:.8f}\")\n",
        "print(f\"✅ CW Attack Accuracy (After CW Training): {cw_acc:.8f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6tYt6e0bt_W",
        "outputId": "d3ec029d-1637-417e-b272-dba78898739a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Running FGSM Attack...\n",
            "\u001b[1m   5/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 27ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 28ms/step\n",
            "\n",
            "🔹 Running PGD Attack...\n",
            "\u001b[1m   3/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 30ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 28ms/step\n",
            "\n",
            "🔹 Running CW Attack...\n",
            "\u001b[1m   5/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 27ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 28ms/step\n",
            "\n",
            "✅ FGSM Attack Accuracy (After CW Training): 0.99994086\n",
            "✅ PGD Attack Accuracy (After CW Training): 0.99994086\n",
            "✅ CW Attack Accuracy (After CW Training): 0.10000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IYQ8OG6ajcG"
      },
      "source": [
        "**🔧 Step 3: Defensive Distillation (Optional)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hK9rpJe6aktV"
      },
      "outputs": [],
      "source": [
        "# Apply defensive distillation\n",
        "def defensive_distillation(model, train_features, train_labels, temperature=5):\n",
        "    \"\"\"\n",
        "    Use soft labels to make CW attacks less effective.\n",
        "    \"\"\"\n",
        "    soft_labels = model.predict(train_features) ** (1 / temperature)\n",
        "    return model.fit(train_features, soft_labels, epochs=5, batch_size=64, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**✅ Step 1: Implement Adversarial Loss Function**"
      ],
      "metadata": {
        "id": "o_y9771WVQ5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "\n",
        "# ✅ Ensure Eager Execution is Enabled (Fix for NotImplementedError)\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "def adversarial_loss(model, clean_features, adv_features, labels, alpha=1.0, beta=0.5):\n",
        "    \"\"\"\n",
        "    Compute total loss: classification loss + adversarial penalty loss.\n",
        "\n",
        "    - `alpha`: Weight of standard classification loss\n",
        "    - `beta`: Weight of adversarial penalty loss\n",
        "    \"\"\"\n",
        "    mse_loss = tf.keras.losses.MeanSquaredError()  # Instantiate MSE loss function\n",
        "\n",
        "    # Forward pass on clean and adversarial samples\n",
        "    clean_logits = model(clean_features)\n",
        "    adv_logits = model(adv_features)\n",
        "\n",
        "    # Classification loss (cross-entropy)\n",
        "    classification_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(labels, clean_logits))\n",
        "\n",
        "    # Adversarial penalty loss: minimize difference between clean & adversarial logits\n",
        "    adversarial_penalty = tf.reduce_mean(mse_loss(clean_logits, adv_logits))  # FIXED\n",
        "\n",
        "    # Total loss (weighted sum of classification and adversarial loss)\n",
        "    total_loss = alpha * classification_loss + beta * adversarial_penalty\n",
        "\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "yfPFU0NqVKYN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**✅ Step 2: Modify Training Loop to Include Adversarial Loss**"
      ],
      "metadata": {
        "id": "zWsASq-uVcQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adversarial_training_with_loss(model, train_features, train_labels, batch_size=64, epochs=3):\n",
        "    \"\"\"\n",
        "    Train the model using a combination of clean, FGSM, PGD, and CW adversarial examples.\n",
        "    \"\"\"\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam()  # Reinitialize optimizer\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\n🔹 Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Increase CW attack strength per epoch\n",
        "        cw_steps = 40 + (epoch * 10)  # Increase steps for better optimization\n",
        "        cw_epsilon = 0.03 + (epoch / epochs) * 0.02  # Increase attack strength\n",
        "\n",
        "        print(f\"\\n🔹 Generating CW Adversarial Examples (steps={cw_steps}, epsilon={cw_epsilon})...\")\n",
        "        adv_cw = generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=cw_epsilon, steps=cw_steps)\n",
        "\n",
        "        print(f\"\\n🔹 Generating PGD Adversarial Examples...\")\n",
        "        attack_pgd = fb.attacks.LinfPGD(steps=10)\n",
        "        adv_pgd, _, _ = attack_pgd(fb.TensorFlowModel(model, bounds=(0, 1)), tf.convert_to_tensor(train_features, dtype=tf.float32), np.argmax(train_labels, axis=1), epsilons=0.02)\n",
        "\n",
        "        print(f\"\\n🔹 Generating FGSM Adversarial Examples...\")\n",
        "        attack_fgsm = fb.attacks.FGSM()\n",
        "        adv_fgsm, _, _ = attack_fgsm(fb.TensorFlowModel(model, bounds=(0, 1)), tf.convert_to_tensor(train_features, dtype=tf.float32), np.argmax(train_labels, axis=1), epsilons=0.01)\n",
        "\n",
        "        # Convert back to NumPy\n",
        "        adv_pgd = adv_pgd.numpy()\n",
        "        adv_fgsm = adv_fgsm.numpy()\n",
        "\n",
        "        # Ensure all shapes are consistent before concatenation\n",
        "        min_shape = min(train_features.shape[1], adv_cw.shape[1], adv_pgd.shape[1], adv_fgsm.shape[1])\n",
        "        train_features = train_features[:, :min_shape]\n",
        "        adv_cw = adv_cw[:, :min_shape]\n",
        "        adv_pgd = adv_pgd[:, :min_shape]\n",
        "        adv_fgsm = adv_fgsm[:, :min_shape]\n",
        "\n",
        "        # Combine clean and adversarial examples\n",
        "        combined_features = np.vstack([train_features, adv_cw, adv_pgd, adv_fgsm])\n",
        "        combined_labels = np.vstack([train_labels, train_labels, train_labels, train_labels])\n",
        "\n",
        "        # Shuffle dataset\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((combined_features, combined_labels))\n",
        "        dataset = dataset.shuffle(buffer_size=len(combined_features)).batch(batch_size)\n",
        "\n",
        "        print(\"🔹 Training on CW-Optimized Adversarial Dataset...\")\n",
        "\n",
        "        # Custom Training Loop to Apply Adversarial Loss\n",
        "        for step, (batch_x, batch_y) in enumerate(dataset):\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Compute adversarial loss\n",
        "                loss = adversarial_loss(model, batch_x, adv_cw[:len(batch_x)], batch_y)\n",
        "\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "            if step % 500 == 0:\n",
        "                print(f\"Step {step}: Loss = {tf.reduce_mean(loss).numpy():.6f}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "M_tqTomTVXmZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "\n",
        "def generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=0.01, steps=40, batch_size=256):\n",
        "    \"\"\"\n",
        "    Generate Carlini-Wagner (CW) adversarial examples in batches for stability.\n",
        "    \"\"\"\n",
        "    fmodel = fb.TensorFlowModel(model, bounds=(0, 1))\n",
        "    cw_attack = fb.attacks.L2CarliniWagnerAttack(binary_search_steps=5, steps=steps)\n",
        "\n",
        "    print(f\"\\n🔹 Generating CW Adversarial Examples (epsilon={epsilon}, steps={steps})...\")\n",
        "\n",
        "    # Convert labels to class indices\n",
        "    train_labels_indices = np.argmax(train_labels, axis=1)\n",
        "    train_features_tf = tf.convert_to_tensor(train_features, dtype=tf.float32)\n",
        "\n",
        "    adv_examples_list = []\n",
        "\n",
        "    for i in range(0, len(train_features), batch_size):\n",
        "        batch_features = train_features_tf[i:i + batch_size]\n",
        "        batch_labels = train_labels_indices[i:i + batch_size]\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        adv_batch = cw_attack(fmodel, batch_features, batch_labels, epsilons=epsilon)\n",
        "\n",
        "        # Convert to NumPy format\n",
        "        if isinstance(adv_batch, (tuple, list)):\n",
        "            adv_batch_np = np.array(adv_batch[0])\n",
        "        elif tf.is_tensor(adv_batch):\n",
        "            adv_batch_np = adv_batch.numpy()\n",
        "        else:\n",
        "            adv_batch_np = adv_batch\n",
        "\n",
        "        adv_examples_list.append(adv_batch_np)\n",
        "\n",
        "    # Combine all batches into a single NumPy array\n",
        "    adv_examples_np = np.concatenate(adv_examples_list, axis=0)\n",
        "\n",
        "    return adv_examples_np"
      ],
      "metadata": {
        "id": "D2rXUrAKWHDR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with optimized CW adversarial training\n",
        "bilstm_model = adversarial_training_with_loss(bilstm_model, train_lr_features, y_train_encoded, batch_size=64, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpBhsLS3Vl4X",
        "outputId": "054bbfdc-0859-4c3c-c5fa-90e8f5cfa063"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Epoch 1/3\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (steps=40, epsilon=0.03)...\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (epsilon=0.03, steps=40)...\n",
            "\n",
            "🔹 Generating PGD Adversarial Examples...\n",
            "\n",
            "🔹 Generating FGSM Adversarial Examples...\n",
            "🔹 Training on CW-Optimized Adversarial Dataset...\n",
            "Step 0: Loss = 0.582018\n",
            "Step 500: Loss = 0.609233\n",
            "Step 1000: Loss = 0.645282\n",
            "Step 1500: Loss = 0.833731\n",
            "Step 2000: Loss = 0.535553\n",
            "Step 2500: Loss = 0.641524\n",
            "Step 3000: Loss = 0.606448\n",
            "Step 3500: Loss = 0.649551\n",
            "Step 4000: Loss = 0.430348\n",
            "Step 4500: Loss = 0.535532\n",
            "Step 5000: Loss = 0.505344\n",
            "Step 5500: Loss = 0.395422\n",
            "Step 6000: Loss = 0.653648\n",
            "Step 6500: Loss = 0.717371\n",
            "Step 7000: Loss = 0.860825\n",
            "Step 7500: Loss = 0.680958\n",
            "Step 8000: Loss = 0.434894\n",
            "Step 8500: Loss = 0.645679\n",
            "Step 9000: Loss = 0.821846\n",
            "Step 9500: Loss = 0.749335\n",
            "Step 10000: Loss = 0.675520\n",
            "Step 10500: Loss = 0.572534\n",
            "Step 11000: Loss = 0.503450\n",
            "Step 11500: Loss = 0.502582\n",
            "Step 12000: Loss = 0.549880\n",
            "Step 12500: Loss = 0.861760\n",
            "Step 13000: Loss = 0.508387\n",
            "Step 13500: Loss = 0.749923\n",
            "Step 14000: Loss = 0.657296\n",
            "Step 14500: Loss = 0.505125\n",
            "Step 15000: Loss = 0.435492\n",
            "Step 15500: Loss = 0.470813\n",
            "Step 16000: Loss = 0.502273\n",
            "Step 16500: Loss = 0.644795\n",
            "Step 17000: Loss = 0.573764\n",
            "Step 17500: Loss = 0.715726\n",
            "Step 18000: Loss = 0.678245\n",
            "Step 18500: Loss = 0.605187\n",
            "Step 19000: Loss = 0.751459\n",
            "Step 19500: Loss = 0.614639\n",
            "Step 20000: Loss = 0.641187\n",
            "Step 20500: Loss = 0.360982\n",
            "Step 21000: Loss = 0.575366\n",
            "Step 21500: Loss = 0.645994\n",
            "Step 22000: Loss = 0.571545\n",
            "Step 22500: Loss = 0.435909\n",
            "Step 23000: Loss = 0.612695\n",
            "Step 23500: Loss = 0.401825\n",
            "Step 24000: Loss = 0.639633\n",
            "Step 24500: Loss = 0.676559\n",
            "Step 25000: Loss = 0.725064\n",
            "Step 25500: Loss = 0.544107\n",
            "Step 26000: Loss = 0.585601\n",
            "Step 26500: Loss = 0.643879\n",
            "Step 27000: Loss = 0.610055\n",
            "Step 27500: Loss = 0.783696\n",
            "Step 28000: Loss = 0.845798\n",
            "Step 28500: Loss = 0.649229\n",
            "Step 29000: Loss = 0.827062\n",
            "Step 29500: Loss = 0.681890\n",
            "Step 30000: Loss = 0.685085\n",
            "Step 30500: Loss = 0.588183\n",
            "Step 31000: Loss = 0.542599\n",
            "Step 31500: Loss = 0.655756\n",
            "Step 32000: Loss = 0.617547\n",
            "Step 32500: Loss = 0.750905\n",
            "Step 33000: Loss = 0.618904\n",
            "Step 33500: Loss = 0.577310\n",
            "Step 34000: Loss = 0.760391\n",
            "Step 34500: Loss = 0.639088\n",
            "Step 35000: Loss = 0.714466\n",
            "Step 35500: Loss = 0.819244\n",
            "Step 36000: Loss = 0.539641\n",
            "Step 36500: Loss = 0.432628\n",
            "Step 37000: Loss = 0.501166\n",
            "Step 37500: Loss = 0.431913\n",
            "Step 38000: Loss = 0.537634\n",
            "Step 38500: Loss = 0.612319\n",
            "Step 39000: Loss = 0.782918\n",
            "Step 39500: Loss = 0.678955\n",
            "Step 40000: Loss = 0.466087\n",
            "Step 40500: Loss = 0.644261\n",
            "Step 41000: Loss = 0.643095\n",
            "Step 41500: Loss = 0.473963\n",
            "Step 42000: Loss = 0.538016\n",
            "Step 42500: Loss = 0.707396\n",
            "Step 43000: Loss = 0.572016\n",
            "Step 43500: Loss = 0.646717\n",
            "Step 44000: Loss = 0.640530\n",
            "Step 44500: Loss = 0.755585\n",
            "Step 45000: Loss = 0.329146\n",
            "Step 45500: Loss = 0.889828\n",
            "Step 46000: Loss = 0.643969\n",
            "\n",
            "🔹 Epoch 2/3\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (steps=50, epsilon=0.03666666666666667)...\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (epsilon=0.03666666666666667, steps=50)...\n",
            "\n",
            "🔹 Generating PGD Adversarial Examples...\n",
            "\n",
            "🔹 Generating FGSM Adversarial Examples...\n",
            "🔹 Training on CW-Optimized Adversarial Dataset...\n",
            "Step 0: Loss = 0.472887\n",
            "Step 500: Loss = 0.540538\n",
            "Step 1000: Loss = 0.395038\n",
            "Step 1500: Loss = 0.577573\n",
            "Step 2000: Loss = 0.502030\n",
            "Step 2500: Loss = 0.757235\n",
            "Step 3000: Loss = 0.648784\n",
            "Step 3500: Loss = 0.645086\n",
            "Step 4000: Loss = 0.571333\n",
            "Step 4500: Loss = 0.638422\n",
            "Step 5000: Loss = 0.466832\n",
            "Step 5500: Loss = 0.549092\n",
            "Step 6000: Loss = 0.398046\n",
            "Step 6500: Loss = 0.643387\n",
            "Step 7000: Loss = 0.715758\n",
            "Step 7500: Loss = 0.641317\n",
            "Step 8000: Loss = 0.500826\n",
            "Step 8500: Loss = 0.538688\n",
            "Step 9000: Loss = 0.539237\n",
            "Step 9500: Loss = 0.715097\n",
            "Step 10000: Loss = 0.468909\n",
            "Step 10500: Loss = 0.712006\n",
            "Step 11000: Loss = 0.361464\n",
            "Step 11500: Loss = 0.467625\n",
            "Step 12000: Loss = 0.468932\n",
            "Step 12500: Loss = 0.358414\n",
            "Step 13000: Loss = 0.606420\n",
            "Step 13500: Loss = 0.719277\n",
            "Step 14000: Loss = 0.718085\n",
            "Step 14500: Loss = 0.471507\n",
            "Step 15000: Loss = 0.537760\n",
            "Step 15500: Loss = 0.364766\n",
            "Step 16000: Loss = 0.756674\n",
            "Step 16500: Loss = 0.609995\n",
            "Step 17000: Loss = 0.607814\n",
            "Step 17500: Loss = 0.609068\n",
            "Step 18000: Loss = 0.608040\n",
            "Step 18500: Loss = 0.644120\n",
            "Step 19000: Loss = 0.614787\n",
            "Step 19500: Loss = 0.643163\n",
            "Step 20000: Loss = 0.713742\n",
            "Step 20500: Loss = 0.503730\n",
            "Step 21000: Loss = 0.434734\n",
            "Step 21500: Loss = 0.539523\n",
            "Step 22000: Loss = 0.724211\n",
            "Step 22500: Loss = 0.400223\n",
            "Step 23000: Loss = 0.538342\n",
            "Step 23500: Loss = 0.642795\n",
            "Step 24000: Loss = 0.501756\n",
            "Step 24500: Loss = 0.679816\n",
            "Step 25000: Loss = 0.678318\n",
            "Step 25500: Loss = 0.607272\n",
            "Step 26000: Loss = 0.612776\n",
            "Step 26500: Loss = 0.577318\n",
            "Step 27000: Loss = 0.577199\n",
            "Step 27500: Loss = 0.539327\n",
            "Step 28000: Loss = 0.434744\n",
            "Step 28500: Loss = 0.540846\n",
            "Step 29000: Loss = 0.539172\n",
            "Step 29500: Loss = 0.896850\n",
            "Step 30000: Loss = 0.644985\n",
            "Step 30500: Loss = 1.005180\n",
            "Step 31000: Loss = 0.431883\n",
            "Step 31500: Loss = 0.576798\n",
            "Step 32000: Loss = 0.536395\n",
            "Step 32500: Loss = 0.503900\n",
            "Step 33000: Loss = 0.433289\n",
            "Step 33500: Loss = 0.575617\n",
            "Step 34000: Loss = 0.642143\n",
            "Step 34500: Loss = 0.540695\n",
            "Step 35000: Loss = 0.574278\n",
            "Step 35500: Loss = 0.538269\n",
            "Step 36000: Loss = 0.607433\n",
            "Step 36500: Loss = 0.607399\n",
            "Step 37000: Loss = 0.645371\n",
            "Step 37500: Loss = 0.888525\n",
            "Step 38000: Loss = 0.827165\n",
            "Step 38500: Loss = 0.681055\n",
            "Step 39000: Loss = 0.749677\n",
            "Step 39500: Loss = 0.642285\n",
            "Step 40000: Loss = 0.783702\n",
            "Step 40500: Loss = 0.610583\n",
            "Step 41000: Loss = 0.471997\n",
            "Step 41500: Loss = 0.430966\n",
            "Step 42000: Loss = 0.534381\n",
            "Step 42500: Loss = 0.483502\n",
            "Step 43000: Loss = 0.433853\n",
            "Step 43500: Loss = 0.502590\n",
            "Step 44000: Loss = 0.469448\n",
            "Step 44500: Loss = 0.790039\n",
            "Step 45000: Loss = 0.534776\n",
            "Step 45500: Loss = 0.718371\n",
            "Step 46000: Loss = 0.469936\n",
            "\n",
            "🔹 Epoch 3/3\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (steps=60, epsilon=0.043333333333333335)...\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (epsilon=0.043333333333333335, steps=60)...\n",
            "\n",
            "🔹 Generating PGD Adversarial Examples...\n",
            "\n",
            "🔹 Generating FGSM Adversarial Examples...\n",
            "🔹 Training on CW-Optimized Adversarial Dataset...\n",
            "Step 0: Loss = 0.577303\n",
            "Step 500: Loss = 0.504035\n",
            "Step 1000: Loss = 1.069823\n",
            "Step 1500: Loss = 0.717718\n",
            "Step 2000: Loss = 0.716607\n",
            "Step 2500: Loss = 0.641913\n",
            "Step 3000: Loss = 0.540606\n",
            "Step 3500: Loss = 0.576171\n",
            "Step 4000: Loss = 0.433290\n",
            "Step 4500: Loss = 0.501895\n",
            "Step 5000: Loss = 0.536971\n",
            "Step 5500: Loss = 0.468763\n",
            "Step 6000: Loss = 0.611526\n",
            "Step 6500: Loss = 0.504892\n",
            "Step 7000: Loss = 0.498301\n",
            "Step 7500: Loss = 0.505553\n",
            "Step 8000: Loss = 0.545452\n",
            "Step 8500: Loss = 0.503779\n",
            "Step 9000: Loss = 0.255770\n",
            "Step 9500: Loss = 0.431953\n",
            "Step 10000: Loss = 0.540029\n",
            "Step 10500: Loss = 0.751459\n",
            "Step 11000: Loss = 0.748553\n",
            "Step 11500: Loss = 0.568759\n",
            "Step 12000: Loss = 0.538675\n",
            "Step 12500: Loss = 0.538712\n",
            "Step 13000: Loss = 0.572053\n",
            "Step 13500: Loss = 0.539067\n",
            "Step 14000: Loss = 0.719558\n",
            "Step 14500: Loss = 0.748676\n",
            "Step 15000: Loss = 0.713266\n",
            "Step 15500: Loss = 0.398749\n",
            "Step 16000: Loss = 0.640950\n",
            "Step 16500: Loss = 0.642032\n",
            "Step 17000: Loss = 0.607407\n",
            "Step 17500: Loss = 0.574688\n",
            "Step 18000: Loss = 0.676211\n",
            "Step 18500: Loss = 0.606010\n",
            "Step 19000: Loss = 0.541038\n",
            "Step 19500: Loss = 0.890723\n",
            "Step 20000: Loss = 0.609069\n",
            "Step 20500: Loss = 0.643762\n",
            "Step 21000: Loss = 0.538363\n",
            "Step 21500: Loss = 0.609759\n",
            "Step 22000: Loss = 0.608558\n",
            "Step 22500: Loss = 0.609589\n",
            "Step 23000: Loss = 0.855392\n",
            "Step 23500: Loss = 0.502754\n",
            "Step 24000: Loss = 0.750874\n",
            "Step 24500: Loss = 0.609759\n",
            "Step 25000: Loss = 0.720948\n",
            "Step 25500: Loss = 0.645200\n",
            "Step 26000: Loss = 0.539010\n",
            "Step 26500: Loss = 0.505964\n",
            "Step 27000: Loss = 0.607686\n",
            "Step 27500: Loss = 0.610297\n",
            "Step 28000: Loss = 0.532696\n",
            "Step 28500: Loss = 0.505975\n",
            "Step 29000: Loss = 0.462768\n",
            "Step 29500: Loss = 0.646056\n",
            "Step 30000: Loss = 0.862281\n",
            "Step 30500: Loss = 0.502111\n",
            "Step 31000: Loss = 0.541358\n",
            "Step 31500: Loss = 0.748875\n",
            "Step 32000: Loss = 0.470549\n",
            "Step 32500: Loss = 0.652587\n",
            "Step 33000: Loss = 0.716121\n",
            "Step 33500: Loss = 0.713802\n",
            "Step 34000: Loss = 0.817872\n",
            "Step 34500: Loss = 0.575075\n",
            "Step 35000: Loss = 0.432483\n",
            "Step 35500: Loss = 0.570971\n",
            "Step 36000: Loss = 0.793175\n",
            "Step 36500: Loss = 0.538285\n",
            "Step 37000: Loss = 0.716868\n",
            "Step 37500: Loss = 0.611640\n",
            "Step 38000: Loss = 0.928338\n",
            "Step 38500: Loss = 0.790443\n",
            "Step 39000: Loss = 0.578417\n",
            "Step 39500: Loss = 0.574084\n",
            "Step 40000: Loss = 0.538903\n",
            "Step 40500: Loss = 0.716412\n",
            "Step 41000: Loss = 0.756907\n",
            "Step 41500: Loss = 0.718322\n",
            "Step 42000: Loss = 0.573554\n",
            "Step 42500: Loss = 0.640453\n",
            "Step 43000: Loss = 0.570432\n",
            "Step 43500: Loss = 0.611011\n",
            "Step 44000: Loss = 0.470169\n",
            "Step 44500: Loss = 0.688919\n",
            "Step 45000: Loss = 0.434655\n",
            "Step 45500: Loss = 0.507141\n",
            "Step 46000: Loss = 0.647720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import foolbox as fb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate_adversarial_robustness(model, test_features, test_labels, epsilon=0.02):\n",
        "    \"\"\"\n",
        "    Evaluate model robustness against FGSM, PGD, and CW attacks.\n",
        "    \"\"\"\n",
        "    fmodel = fb.TensorFlowModel(model, bounds=(0, 1))\n",
        "\n",
        "    print(\"\\n🔹 Running FGSM Attack...\")\n",
        "    attack_fgsm = fb.attacks.FGSM()\n",
        "    adv_fgsm, *_ = attack_fgsm(fmodel, tf.convert_to_tensor(test_features, dtype=tf.float32), np.argmax(test_labels, axis=1), epsilons=epsilon)\n",
        "    fgsm_predictions = np.argmax(model.predict(adv_fgsm.numpy()), axis=1)\n",
        "    fgsm_accuracy = accuracy_score(np.argmax(test_labels, axis=1), fgsm_predictions)\n",
        "\n",
        "    print(\"\\n🔹 Running PGD Attack...\")\n",
        "    attack_pgd = fb.attacks.LinfPGD(steps=10)\n",
        "    adv_pgd, *_ = attack_pgd(fmodel, tf.convert_to_tensor(test_features, dtype=tf.float32), np.argmax(test_labels, axis=1), epsilons=epsilon)\n",
        "    pgd_predictions = np.argmax(model.predict(adv_pgd.numpy()), axis=1)\n",
        "    pgd_accuracy = accuracy_score(np.argmax(test_labels, axis=1), pgd_predictions)\n",
        "\n",
        "    print(\"\\n🔹 Running CW Attack...\")\n",
        "    attack_cw = fb.attacks.L2CarliniWagnerAttack(binary_search_steps=5, steps=10)\n",
        "    adv_cw, *_ = attack_cw(fmodel, tf.convert_to_tensor(test_features, dtype=tf.float32), np.argmax(test_labels, axis=1), epsilons=epsilon)\n",
        "    cw_predictions = np.argmax(model.predict(adv_cw.numpy()), axis=1)\n",
        "    cw_accuracy = accuracy_score(np.argmax(test_labels, axis=1), cw_predictions)\n",
        "\n",
        "    return fgsm_accuracy, pgd_accuracy, cw_accuracy"
      ],
      "metadata": {
        "id": "CgB17-sqarui"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance against adversarial attacks\n",
        "fgsm_acc, pgd_acc, cw_acc = evaluate_adversarial_robustness(bilstm_model, test_lr_features, y_test_encoded)\n",
        "\n",
        "# Print Updated Accuracy After CW Training\n",
        "print(f\"\\n✅ FGSM Attack Accuracy (After CW Training): {fgsm_acc:.8f}\")\n",
        "print(f\"✅ PGD Attack Accuracy (After CW Training): {pgd_acc:.8f}\")\n",
        "print(f\"✅ CW Attack Accuracy (After CW Training): {cw_acc:.8f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxWANrY_VrQZ",
        "outputId": "43a58eb6-74b7-45f8-c641-0fb6f02fa5d7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Running FGSM Attack...\n",
            "\u001b[1m   1/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:41\u001b[0m 90ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 43ms/step\n",
            "\n",
            "🔹 Running PGD Attack...\n",
            "\u001b[1m   3/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:03\u001b[0m 42ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 43ms/step\n",
            "\n",
            "🔹 Running CW Attack...\n",
            "\u001b[1m   1/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:02\u001b[0m 73ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 43ms/step\n",
            "\n",
            "✅ FGSM Attack Accuracy (After CW Training): 0.99994624\n",
            "✅ PGD Attack Accuracy (After CW Training): 0.99995161\n",
            "✅ CW Attack Accuracy (After CW Training): 0.10000000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNagSQYIStAo1EskKImoNh7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}