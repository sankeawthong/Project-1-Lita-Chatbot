{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankeawthong/Project-1-Lita-Chatbot/blob/main/%5B20250206%5D%20Update%20without%20CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zi8pwJKYJJ6F"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DX2I_3uFMMxS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyfvH2qXM4WT"
      },
      "source": [
        "**PART 1: Data Preprocessing & Balancing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EIXtl20gMOtK"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "dataset = pd.read_csv(\"Dataset_10Classes.csv\")\n",
        "\n",
        "# Handle missing values\n",
        "dataset = dataset.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "8zTnYg60JY-E",
        "outputId": "d167545e-4e3a-475f-ad0d-67be19b21658"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         ID_Cb     id       dur proto service state  spkts  dpkts  sbytes  \\\n",
              "0            1      1  0.121478   tcp       -   FIN      6      4     258   \n",
              "1            2      2  0.649902   tcp       -   FIN     14     38     734   \n",
              "2            3      3  1.623129   tcp       -   FIN      8     16     364   \n",
              "3            4      4  1.681642   tcp     ftp   FIN     12     12     628   \n",
              "4            5      5  0.449454   tcp       -   FIN     10      6     534   \n",
              "...        ...    ...       ...   ...     ...   ...    ...    ...     ...   \n",
              "257668  257669  82328  0.000005   udp       -   INT      2      0     104   \n",
              "257669  257670  82329  1.106101   tcp       -   FIN     20      8   18062   \n",
              "257670  257671  82330  0.000000   arp       -   INT      1      0      46   \n",
              "257671  257672  82331  0.000000   arp       -   INT      1      0      46   \n",
              "257672  257673  82332  0.000009   udp       -   INT      2      0     104   \n",
              "\n",
              "        dbytes  ...  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
              "0          172  ...               1             0           0   \n",
              "1        42014  ...               2             0           0   \n",
              "2        13186  ...               3             0           0   \n",
              "3          770  ...               3             1           1   \n",
              "4          268  ...              40             0           0   \n",
              "...        ...  ...             ...           ...         ...   \n",
              "257668       0  ...               2             0           0   \n",
              "257669     354  ...               1             0           0   \n",
              "257670       0  ...               1             0           0   \n",
              "257671       0  ...               1             0           0   \n",
              "257672       0  ...               1             0           0   \n",
              "\n",
              "        ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \\\n",
              "0                      0           1           1                0      Normal   \n",
              "1                      0           1           6                0      Normal   \n",
              "2                      0           2           6                0      Normal   \n",
              "3                      0           2           1                0      Normal   \n",
              "4                      0           2          39                0      Normal   \n",
              "...                  ...         ...         ...              ...         ...   \n",
              "257668                 0           2           1                0      Normal   \n",
              "257669                 0           3           2                0      Normal   \n",
              "257670                 0           1           1                1      Normal   \n",
              "257671                 0           1           1                1      Normal   \n",
              "257672                 0           1           1                0      Normal   \n",
              "\n",
              "        label  Class  \n",
              "0           0      0  \n",
              "1           0      0  \n",
              "2           0      0  \n",
              "3           0      0  \n",
              "4           0      0  \n",
              "...       ...    ...  \n",
              "257668      0      0  \n",
              "257669      0      0  \n",
              "257670      0      0  \n",
              "257671      0      0  \n",
              "257672      0      0  \n",
              "\n",
              "[257673 rows x 47 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97487a70-0a25-4495-bd46-1fe5387adb90\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID_Cb</th>\n",
              "      <th>id</th>\n",
              "      <th>dur</th>\n",
              "      <th>proto</th>\n",
              "      <th>service</th>\n",
              "      <th>state</th>\n",
              "      <th>spkts</th>\n",
              "      <th>dpkts</th>\n",
              "      <th>sbytes</th>\n",
              "      <th>dbytes</th>\n",
              "      <th>...</th>\n",
              "      <th>ct_dst_src_ltm</th>\n",
              "      <th>is_ftp_login</th>\n",
              "      <th>ct_ftp_cmd</th>\n",
              "      <th>ct_flw_http_mthd</th>\n",
              "      <th>ct_src_ltm</th>\n",
              "      <th>ct_srv_dst</th>\n",
              "      <th>is_sm_ips_ports</th>\n",
              "      <th>attack_cat</th>\n",
              "      <th>label</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.121478</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>258</td>\n",
              "      <td>172</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.649902</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>14</td>\n",
              "      <td>38</td>\n",
              "      <td>734</td>\n",
              "      <td>42014</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1.623129</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>364</td>\n",
              "      <td>13186</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.681642</td>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp</td>\n",
              "      <td>FIN</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>628</td>\n",
              "      <td>770</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0.449454</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>534</td>\n",
              "      <td>268</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257668</th>\n",
              "      <td>257669</td>\n",
              "      <td>82328</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257669</th>\n",
              "      <td>257670</td>\n",
              "      <td>82329</td>\n",
              "      <td>1.106101</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>18062</td>\n",
              "      <td>354</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257670</th>\n",
              "      <td>257671</td>\n",
              "      <td>82330</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>arp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257671</th>\n",
              "      <td>257672</td>\n",
              "      <td>82331</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>arp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257672</th>\n",
              "      <td>257673</td>\n",
              "      <td>82332</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>257673 rows × 47 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97487a70-0a25-4495-bd46-1fe5387adb90')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-97487a70-0a25-4495-bd46-1fe5387adb90 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-97487a70-0a25-4495-bd46-1fe5387adb90');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3616b332-6113-480c-887d-f7c5d707d175\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3616b332-6113-480c-887d-f7c5d707d175')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3616b332-6113-480c-887d-f7c5d707d175 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f1f3f284-6b45-4734-9a46-d5bef0825973\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f1f3f284-6b45-4734-9a46-d5bef0825973 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLHABU7lMKFS",
        "outputId": "5a60674e-fbd4-4e56-ef94-e6bfb84fb3c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Preprocessing complete! Data saved to 'preprocessed_data.pkl'.\n"
          ]
        }
      ],
      "source": [
        "# Encode categorical columns\n",
        "for column in dataset.columns:\n",
        "    if dataset[column].dtype == 'object':\n",
        "        dataset[column] = LabelEncoder().fit_transform(dataset[column])\n",
        "\n",
        "# Separate features & target\n",
        "X = dataset.drop(['Class'], axis=1)\n",
        "y = dataset['Class']\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Balance dataset using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X, y = smote.fit_resample(X, y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Save preprocessed data\n",
        "with open(\"preprocessed_data.pkl\", \"wb\") as f:\n",
        "    pickle.dump((X_train, X_test, y_train, y_test), f)\n",
        "\n",
        "print(\"✅ Preprocessing complete! Data saved to 'preprocessed_data.pkl'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXfLTTuzM1TU"
      },
      "source": [
        "**PART 2: Feature Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7MsZuluMfpB",
        "outputId": "b703fad4-9e0a-4155-8717-99623c6b8367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Feature extraction complete! Data saved to 'features.pkl'.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load preprocessed data\n",
        "with open(\"preprocessed_data.pkl\", \"rb\") as f:\n",
        "    X_train, X_test, y_train, y_test = pickle.load(f)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "lr_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=500, random_state=42)\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Extract probability features\n",
        "train_lr_features = lr_model.predict_proba(X_train)\n",
        "test_lr_features = lr_model.predict_proba(X_test)\n",
        "\n",
        "# Expand dimensions for BiLSTM\n",
        "train_lr_features = np.expand_dims(train_lr_features, axis=1)\n",
        "test_lr_features = np.expand_dims(test_lr_features, axis=1)\n",
        "\n",
        "# One-hot encode labels\n",
        "num_classes = len(np.unique(y_train))\n",
        "y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "# Save features and labels\n",
        "with open(\"features.pkl\", \"wb\") as f:\n",
        "    pickle.dump((train_lr_features, test_lr_features, y_train_encoded, y_test_encoded), f)\n",
        "\n",
        "print(\"✅ Feature extraction complete! Data saved to 'features.pkl'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do8DMX5CMzYT"
      },
      "source": [
        "**PART 3: Build & Train BiLSTM Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7kmwP8eMjEj",
        "outputId": "b205cef2-c7b4-4e90-e925-08be5c93a554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.9149 - loss: 1.1083 - val_accuracy: 0.9999 - val_loss: 0.3058\n",
            "Epoch 2/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.3417 - val_accuracy: 0.9999 - val_loss: 0.2501\n",
            "Epoch 3/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.2938 - val_accuracy: 0.9999 - val_loss: 0.2348\n",
            "Epoch 4/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.2801 - val_accuracy: 0.9999 - val_loss: 0.2306\n",
            "Epoch 5/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.2764 - val_accuracy: 0.9999 - val_loss: 0.2297\n",
            "Epoch 6/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.2753 - val_accuracy: 0.9999 - val_loss: 0.2285\n",
            "Epoch 7/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.2747 - val_accuracy: 0.9999 - val_loss: 0.2290\n",
            "Epoch 8/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.2749 - val_accuracy: 0.9999 - val_loss: 0.2281\n",
            "Epoch 9/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.2745 - val_accuracy: 0.9999 - val_loss: 0.2281\n",
            "Epoch 10/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.2724 - val_accuracy: 0.9999 - val_loss: 0.2274\n",
            "Epoch 11/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.2694 - val_accuracy: 0.9999 - val_loss: 0.2260\n",
            "Epoch 12/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.2688 - val_accuracy: 0.9999 - val_loss: 0.2263\n",
            "Epoch 13/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.2687 - val_accuracy: 0.9999 - val_loss: 0.2261\n",
            "Epoch 14/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.2689 - val_accuracy: 0.9999 - val_loss: 0.2265\n",
            "Epoch 15/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.2686 - val_accuracy: 0.9999 - val_loss: 0.2262\n",
            "Epoch 16/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.2686 - val_accuracy: 0.9999 - val_loss: 0.2262\n",
            "Epoch 17/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.2686 - val_accuracy: 0.9999 - val_loss: 0.2261\n",
            "Epoch 18/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.2687 - val_accuracy: 0.9999 - val_loss: 0.2261\n",
            "Epoch 19/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.2687 - val_accuracy: 0.9999 - val_loss: 0.2262\n",
            "Epoch 20/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.2688 - val_accuracy: 0.9999 - val_loss: 0.2262\n",
            "Epoch 21/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.2689 - val_accuracy: 0.9999 - val_loss: 0.2260\n",
            "Epoch 22/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.2687 - val_accuracy: 0.9999 - val_loss: 0.2261\n",
            "Epoch 23/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.2688 - val_accuracy: 0.9999 - val_loss: 0.2260\n",
            "Epoch 24/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.2688 - val_accuracy: 0.9999 - val_loss: 0.2261\n",
            "Epoch 25/25\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.2687 - val_accuracy: 0.9999 - val_loss: 0.2263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model training complete! Model saved to 'bilstm_model.h5'.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout, Input\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Load feature data\n",
        "with open(\"features.pkl\", \"rb\") as f:\n",
        "    train_lr_features, test_lr_features, y_train_encoded, y_test_encoded = pickle.load(f)\n",
        "\n",
        "# Define BiLSTM model\n",
        "bilstm_model = Sequential([\n",
        "    Input(shape=(1, train_lr_features.shape[2])),\n",
        "    Bidirectional(LSTM(32, return_sequences=True, kernel_regularizer=l2(0.002))),\n",
        "    Dropout(0.5),\n",
        "    Bidirectional(LSTM(16, kernel_regularizer=l2(0.002))),\n",
        "    Dropout(0.5),\n",
        "    Dense(y_train_encoded.shape[1], activation='softmax', kernel_regularizer=l2(0.002))\n",
        "])\n",
        "bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "bilstm_model.fit(\n",
        "    train_lr_features, y_train_encoded,\n",
        "    validation_data=(test_lr_features, y_test_encoded),\n",
        "    epochs=25, batch_size=256, verbose=1\n",
        ")\n",
        "\n",
        "# Save model\n",
        "bilstm_model.save(\"bilstm_model.h5\")\n",
        "print(\"✅ Model training complete! Model saved to 'bilstm_model.h5'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdyV67HBP-kg",
        "outputId": "9cadbe47-dba2-4dc5-958e-dfd04fed40ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step\n",
            "Accuracy: 0.9999139784946236\n",
            "Precision: 0.9999140154722778\n",
            "Recall: 0.9999139784946236\n",
            "F1-score: 0.9999139751636471\n"
          ]
        }
      ],
      "source": [
        "# prompt: Please display a model Accuracy, precision, recall, and f1-score\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pickle\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout, Input\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# ... (Your existing code from Part 1 to Part 3) ...\n",
        "\n",
        "# Load the saved model\n",
        "bilstm_model = tf.keras.models.load_model(\"bilstm_model.h5\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_encoded = bilstm_model.predict(test_lr_features)\n",
        "y_pred = np.argmax(y_pred_encoded, axis=1)\n",
        "y_true = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRG7SmIbMpsI"
      },
      "source": [
        "**PART 4: Generate Adversarial Examples**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDBMoIlFQdin",
        "outputId": "274f4a59-4c1c-479f-823d-6c275e01382a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting foolbox\n",
            "  Downloading foolbox-3.3.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from foolbox) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from foolbox) (1.13.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from foolbox) (75.1.0)\n",
            "Collecting eagerpy>=0.30.0 (from foolbox)\n",
            "  Downloading eagerpy-0.30.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: GitPython>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from foolbox) (3.1.44)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.11/dist-packages (from foolbox) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.11/dist-packages (from foolbox) (2.32.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython>=3.0.7->foolbox) (4.0.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox) (2024.12.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (5.0.2)\n",
            "Downloading foolbox-3.3.4-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eagerpy-0.30.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: eagerpy, foolbox\n",
            "Successfully installed eagerpy-0.30.0 foolbox-3.3.4\n"
          ]
        }
      ],
      "source": [
        "!pip install foolbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPcjbQpnMm7V",
        "outputId": "aef77f54-3bb9-4884-c47a-d76cd394fdd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Error: Physical devices cannot be modified after being initialized\n",
            "✅ Model recompiled successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/foolbox/models/tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Generating FGSM Attack...\n",
            "🔹 Running LinfFastGradientAttack (ε=0.01)...\n",
            "\n",
            "🔹 Generating PGD Attack...\n",
            "🔹 Running LinfProjectedGradientDescentAttack (ε=0.02)...\n",
            "\n",
            "🔹 Generating CW Attack (Optimized)...\n",
            "🔹 Running L2CarliniWagnerAttack (ε=0.01)...\n",
            "\n",
            "✅ Adversarial examples generated & saved to 'adversarial_examples.pkl'.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "# ✅ Step 1: Set TensorFlow to Allocate GPU Memory Dynamically\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"✅ Enabled dynamic GPU memory allocation\")\n",
        "    except RuntimeError as e:\n",
        "        print(\"❌ Error:\", e)\n",
        "\n",
        "# ✅ Step 2: Load Model & Data\n",
        "bilstm_model = load_model(\"bilstm_model.h5\")\n",
        "\n",
        "# ✅ Step 3: Recompile Model After Loading\n",
        "bilstm_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "print(\"✅ Model recompiled successfully!\")\n",
        "\n",
        "# ✅ Step 4: Load Features & Labels\n",
        "with open(\"features.pkl\", \"rb\") as f:\n",
        "    train_lr_features, test_lr_features, y_train_encoded, y_test_encoded = pickle.load(f)\n",
        "\n",
        "# ✅ Step 5: Convert to Foolbox Model\n",
        "fmodel = fb.TensorFlowModel(bilstm_model, bounds=(0, 1))\n",
        "\n",
        "# ✅ Step 6: Define Adversarial Example Generation Function\n",
        "def generate_adversarial_examples(attack, eps):\n",
        "    print(f\"🔹 Running {attack.__class__.__name__} (ε={eps})...\")\n",
        "    raw_adversarials, *_ = attack(\n",
        "        fmodel,\n",
        "        tf.convert_to_tensor(test_lr_features, dtype=tf.float32),\n",
        "        np.argmax(y_test_encoded, axis=1),\n",
        "        epsilons=eps\n",
        "    )\n",
        "    return raw_adversarials.numpy()\n",
        "\n",
        "# ✅ Step 7: Run Attacks\n",
        "print(\"\\n🔹 Generating FGSM Attack...\")\n",
        "adv_fgsm = generate_adversarial_examples(fb.attacks.FGSM(), 0.01)\n",
        "\n",
        "print(\"\\n🔹 Generating PGD Attack...\")\n",
        "adv_pgd = generate_adversarial_examples(fb.attacks.LinfPGD(steps=10), 0.02)\n",
        "\n",
        "print(\"\\n🔹 Generating CW Attack (Optimized)...\")\n",
        "adv_cw = generate_adversarial_examples(fb.attacks.L2CarliniWagnerAttack(binary_search_steps=3, steps=5), 0.01)\n",
        "\n",
        "# ✅ Step 8: Save Adversarial Examples\n",
        "with open(\"adversarial_examples.pkl\", \"wb\") as f:\n",
        "    pickle.dump((adv_fgsm, adv_pgd, adv_cw), f)\n",
        "\n",
        "print(\"\\n✅ Adversarial examples generated & saved to 'adversarial_examples.pkl'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCELSg0LNBYC"
      },
      "source": [
        "**PART 5: Adversarial Training & Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1S-Cm2KM-2n",
        "outputId": "f17c224a-879b-4183-b583-c0752b16ab20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m11625/11625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - accuracy: 0.3253 - loss: 2.2541\n",
            "Epoch 2/5\n",
            "\u001b[1m11625/11625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - accuracy: 0.3241 - loss: 2.1963\n",
            "Epoch 3/5\n",
            "\u001b[1m11625/11625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - accuracy: 0.3255 - loss: 2.1950\n",
            "Epoch 4/5\n",
            "\u001b[1m11625/11625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7ms/step - accuracy: 0.3252 - loss: 2.1958\n",
            "Epoch 5/5\n",
            "\u001b[1m11625/11625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7ms/step - accuracy: 0.3241 - loss: 2.1968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Adversarial training complete! Model saved as 'bilstm_model_adversarial.h5'.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "# Load model, adversarial examples & data\n",
        "bilstm_model = load_model(\"bilstm_model.h5\")\n",
        "\n",
        "with open(\"features.pkl\", \"rb\") as f:\n",
        "    train_lr_features, test_lr_features, y_train_encoded, y_test_encoded = pickle.load(f)\n",
        "\n",
        "with open(\"adversarial_examples.pkl\", \"rb\") as f:\n",
        "    adv_fgsm, adv_pgd, adv_cw = pickle.load(f)\n",
        "\n",
        "# Ensure all adversarial examples have the same shape as train_lr_features\n",
        "min_samples = min(train_lr_features.shape[0], adv_fgsm.shape[0], adv_pgd.shape[0], adv_cw.shape[0])\n",
        "\n",
        "# Trim all feature sets to the minimum number of samples to avoid mismatch\n",
        "train_lr_features = train_lr_features[:min_samples]\n",
        "adv_fgsm = adv_fgsm[:min_samples]\n",
        "adv_pgd = adv_pgd[:min_samples]\n",
        "adv_cw = adv_cw[:min_samples]\n",
        "\n",
        "# Trim labels to match the correct number of features\n",
        "y_train_encoded = y_train_encoded[:min_samples]\n",
        "\n",
        "# Combine clean and adversarial data\n",
        "combined_features = np.vstack([train_lr_features, adv_fgsm, adv_pgd, adv_cw])\n",
        "combined_labels = np.vstack([y_train_encoded] * 4)  # Ensure correct duplication\n",
        "\n",
        "# Ensure combined features and labels match in shape\n",
        "assert combined_features.shape[0] == combined_labels.shape[0], \"Mismatch in features & labels!\"\n",
        "\n",
        "# Recompile model (ensuring it's ready for training)\n",
        "bilstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Retrain model with adversarial data\n",
        "bilstm_model.fit(combined_features, combined_labels, epochs=5, batch_size=64, verbose=1)\n",
        "\n",
        "# Save updated model\n",
        "bilstm_model.save(\"bilstm_model_adversarial.h5\")\n",
        "print(\"✅ Adversarial training complete! Model saved as 'bilstm_model_adversarial.h5'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxW0LDo0YNjp"
      },
      "source": [
        "**Part 6: Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP4ZY-D4X6zp",
        "outputId": "6b82f8f6-f2c0-4a12-9e6b-e47c5d2e75e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "#Step 1: Load Trained Model & Data\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import foolbox as fb\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the trained adversarial model\n",
        "bilstm_model = load_model(\"bilstm_model_adversarial.h5\")\n",
        "\n",
        "# Load test dataset\n",
        "with open(\"features.pkl\", \"rb\") as f:\n",
        "    _, test_lr_features, _, y_test_encoded = pickle.load(f)\n",
        "\n",
        "# Convert test data to TensorFlow tensor\n",
        "test_features_tf = tf.convert_to_tensor(test_lr_features, dtype=tf.float32)\n",
        "true_labels = np.argmax(y_test_encoded, axis=1)  # Convert one-hot labels to class indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SvZXWIOX6fT",
        "outputId": "fc2d9a19-002e-477c-ca3b-c0d7f3639b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step\n",
            "✅ Test Accuracy on Clean Data: 0.99994086\n"
          ]
        }
      ],
      "source": [
        "#Step 2: Evaluate Model on Clean Test Data\n",
        "# Evaluate on clean test data\n",
        "test_predictions = bilstm_model.predict(test_lr_features)\n",
        "test_pred_labels = np.argmax(test_predictions, axis=1)\n",
        "\n",
        "# Compute Accuracy\n",
        "accuracy_clean = accuracy_score(true_labels, test_pred_labels)\n",
        "print(f\"✅ Test Accuracy on Clean Data: {accuracy_clean:.8f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o25ojgUyX6bo",
        "outputId": "42cec1cf-b6f5-4492-b690-61625aa320f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Running FGSM Attack...\n",
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step\n",
            "✅ FGSM Attack Accuracy: 0.99994086\n"
          ]
        }
      ],
      "source": [
        "#Step 3: Evaluate Robustness Against FGSM, PGD, and CW Attacks\n",
        "\n",
        "print(\"\\n🔹 Running FGSM Attack...\")\n",
        "fmodel = fb.TensorFlowModel(bilstm_model, bounds=(0, 1))\n",
        "attack_fgsm = fb.attacks.FGSM()\n",
        "adv_fgsm, _, _ = attack_fgsm(fmodel, test_features_tf, true_labels, epsilons=0.02)\n",
        "\n",
        "# Get model predictions on FGSM adversarial examples\n",
        "fgsm_preds = bilstm_model.predict(adv_fgsm.numpy())\n",
        "fgsm_preds_labels = np.argmax(fgsm_preds, axis=1)\n",
        "\n",
        "# Compute FGSM Accuracy\n",
        "accuracy_fgsm = accuracy_score(true_labels, fgsm_preds_labels)\n",
        "print(f\"✅ FGSM Attack Accuracy: {accuracy_fgsm:.8f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJKxtBI3YUfc",
        "outputId": "182c4034-aa26-4f6c-ae23-e6a70964402f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Running PGD Attack...\n",
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step\n",
            "✅ PGD Attack Accuracy: 0.99994086\n"
          ]
        }
      ],
      "source": [
        "#PGD Attack\n",
        "\n",
        "print(\"\\n🔹 Running PGD Attack...\")\n",
        "attack_pgd = fb.attacks.LinfPGD(steps=10)\n",
        "adv_pgd, _, _ = attack_pgd(fmodel, test_features_tf, true_labels, epsilons=0.02)\n",
        "\n",
        "# Get model predictions on PGD adversarial examples\n",
        "pgd_preds = bilstm_model.predict(adv_pgd.numpy())\n",
        "pgd_preds_labels = np.argmax(pgd_preds, axis=1)\n",
        "\n",
        "# Compute PGD Accuracy\n",
        "accuracy_pgd = accuracy_score(true_labels, pgd_preds_labels)\n",
        "print(f\"✅ PGD Attack Accuracy: {accuracy_pgd:.8f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h40XFzeaYUbt",
        "outputId": "94fe4d5d-b851-4da4-cf3a-0a55865913df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Running CW Attack...\n",
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step\n",
            "✅ CW Attack Accuracy: 0.10000000\n"
          ]
        }
      ],
      "source": [
        "#CW Attack\n",
        "\n",
        "print(\"\\n🔹 Running CW Attack...\")\n",
        "attack_cw = fb.attacks.L2CarliniWagnerAttack(binary_search_steps=10, steps=10)\n",
        "adv_cw, _, _ = attack_cw(fmodel, test_features_tf, true_labels, epsilons=0.01)\n",
        "\n",
        "# Get model predictions on CW adversarial examples\n",
        "cw_preds = bilstm_model.predict(adv_cw.numpy())\n",
        "cw_preds_labels = np.argmax(cw_preds, axis=1)\n",
        "\n",
        "# Compute CW Accuracy\n",
        "accuracy_cw = accuracy_score(true_labels, cw_preds_labels)\n",
        "print(f\"✅ CW Attack Accuracy: {accuracy_cw:.8f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeCLbKBeYmi7",
        "outputId": "f8c17066-51ae-4bfd-b8bc-77a2cbb172ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Evaluation metrics saved successfully!\n"
          ]
        }
      ],
      "source": [
        "#Step 4: Save Evaluation Metrics\n",
        "\n",
        "# Save results\n",
        "evaluation_results = {\n",
        "    \"clean_accuracy\": accuracy_clean,\n",
        "    \"fgsm_accuracy\": accuracy_fgsm,\n",
        "    \"pgd_accuracy\": accuracy_pgd,\n",
        "    \"cw_accuracy\": accuracy_cw,\n",
        "}\n",
        "\n",
        "with open(\"evaluation_results.pkl\", \"wb\") as f:\n",
        "    pickle.dump(evaluation_results, f)\n",
        "\n",
        "print(\"\\n✅ Evaluation metrics saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XSvj_wiacKy"
      },
      "source": [
        "**Improving CW Robustness**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKFOIC7SaRsv"
      },
      "source": [
        "**🔧 Step 1: Update CW Adversarial Training Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BBXiCpm1aSmz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "\n",
        "def generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=0.01, steps=10, batch_size=256):\n",
        "    \"\"\"\n",
        "    Generate Carlini-Wagner (CW) adversarial examples in batches.\n",
        "    \"\"\"\n",
        "    fmodel = fb.TensorFlowModel(model, bounds=(0, 1))\n",
        "    cw_attack = fb.attacks.L2CarliniWagnerAttack(binary_search_steps=10, steps=steps)\n",
        "\n",
        "    print(f\"\\n🔹 Generating CW Adversarial Examples (epsilon={epsilon}, steps={steps})...\")\n",
        "\n",
        "    # Convert labels to class indices\n",
        "    train_labels_indices = np.argmax(train_labels, axis=1)\n",
        "    train_features_tf = tf.convert_to_tensor(train_features, dtype=tf.float32)\n",
        "\n",
        "    adv_examples_list = []\n",
        "\n",
        "    for i in range(0, len(train_features), batch_size):\n",
        "        batch_features = train_features_tf[i:i + batch_size]\n",
        "        batch_labels = train_labels_indices[i:i + batch_size]\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        adv_batch = cw_attack(fmodel, batch_features, batch_labels, epsilons=epsilon)\n",
        "\n",
        "        if isinstance(adv_batch, (tuple, list)):\n",
        "            adv_batch_np = np.array(adv_batch[0])\n",
        "        elif tf.is_tensor(adv_batch):\n",
        "            adv_batch_np = adv_batch.numpy()\n",
        "        else:\n",
        "            adv_batch_np = adv_batch\n",
        "\n",
        "        adv_examples_list.append(adv_batch_np)\n",
        "\n",
        "    # Ensure consistent shape\n",
        "    adv_examples_np = np.concatenate(adv_examples_list, axis=0)\n",
        "\n",
        "    return adv_examples_np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp0lwUuYaYBS"
      },
      "source": [
        "**🔧 Step 2: Train with Stronger CW Adversarial Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "36W7a7XzaVoX"
      },
      "outputs": [],
      "source": [
        "def adversarial_training_with_cw(model, train_features, train_labels, batch_size=64, epochs=5):\n",
        "    \"\"\"\n",
        "    Train the model using a combination of clean, FGSM, PGD, and CW adversarial examples.\n",
        "    \"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\n🔹 Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Increase CW attack strength per epoch\n",
        "        cw_steps = 20 + (epoch * 5)\n",
        "        cw_epsilon = 0.005 + (epoch / epochs) * 0.02\n",
        "\n",
        "        print(f\"\\n🔹 Generating CW Adversarial Examples (steps={cw_steps}, epsilon={cw_epsilon})...\")\n",
        "        adv_cw = generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=cw_epsilon, steps=cw_steps)\n",
        "\n",
        "        print(f\"\\n🔹 Generating PGD Adversarial Examples...\")\n",
        "        attack_pgd = fb.attacks.LinfPGD(steps=10)\n",
        "        adv_pgd, _, _ = attack_pgd(fb.TensorFlowModel(model, bounds=(0, 1)), tf.convert_to_tensor(train_features, dtype=tf.float32), np.argmax(train_labels, axis=1), epsilons=0.02)\n",
        "\n",
        "        print(f\"\\n🔹 Generating FGSM Adversarial Examples...\")\n",
        "        attack_fgsm = fb.attacks.FGSM()\n",
        "        adv_fgsm, _, _ = attack_fgsm(fb.TensorFlowModel(model, bounds=(0, 1)), tf.convert_to_tensor(train_features, dtype=tf.float32), np.argmax(train_labels, axis=1), epsilons=0.01)\n",
        "\n",
        "        # Convert back to NumPy\n",
        "        adv_pgd = adv_pgd.numpy()\n",
        "        adv_fgsm = adv_fgsm.numpy()\n",
        "\n",
        "        # Ensure all shapes are consistent before concatenation\n",
        "        min_shape = min(train_features.shape[1], adv_cw.shape[1], adv_pgd.shape[1], adv_fgsm.shape[1])\n",
        "        train_features = train_features[:, :min_shape]\n",
        "        adv_cw = adv_cw[:, :min_shape]\n",
        "        adv_pgd = adv_pgd[:, :min_shape]\n",
        "        adv_fgsm = adv_fgsm[:, :min_shape]\n",
        "\n",
        "        # Combine clean and adversarial examples\n",
        "        combined_features = np.vstack([train_features, adv_cw, adv_pgd, adv_fgsm])\n",
        "        combined_labels = np.vstack([train_labels, train_labels, train_labels, train_labels])\n",
        "\n",
        "        # Shuffle dataset\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((combined_features, combined_labels))\n",
        "        dataset = dataset.shuffle(buffer_size=len(combined_features)).batch(batch_size)\n",
        "\n",
        "        print(\"🔹 Training on CW-Enhanced Adversarial Dataset...\")\n",
        "        model.fit(dataset, epochs=1, verbose=1)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6J51d4lwKOu"
      },
      "source": [
        "**📌 Step 3: Re-run CW Training & Re-Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L00SRdKBwJzh",
        "outputId": "77264952-8a0c-48df-f19f-9fdf8636c9d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔹 Epoch 1/5\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (steps=20, epsilon=0.005)...\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (epsilon=0.005, steps=20)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-24-a4dbf15f0567>\", line 2, in <cell line: 0>\n",
            "    bilstm_model = adversarial_training_with_cw(bilstm_model, train_lr_features, y_train_encoded, batch_size=64, epochs=5)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-23-0095a5e8a279>\", line 13, in adversarial_training_with_cw\n",
            "    adv_cw = generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=cw_epsilon, steps=cw_steps)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-22-d23b7b4f0134>\", line 25, in generate_cw_adversarial_examples\n",
            "    adv_batch = cw_attack(fmodel, batch_features, batch_labels, epsilons=epsilon)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/foolbox/attacks/base.py\", line 416, in __call__\n",
            "    xp = self.run(model, x, criterion, early_stop=early_stop, **kwargs)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/foolbox/attacks/carlini_wagner.py\", line 170, in run\n",
            "    loss, (perturbed, logits), gradient = loss_aux_and_grad(delta, consts_)\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/eagerpy/tensor/tensorflow.py\", line 482, in value_and_grad\n",
            "    grad = tape.gradient(loss.raw, x_.raw)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/backprop.py\", line 1066, in gradient\n",
            "    flat_grad = imperative_grad.imperative_grad(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/imperative_grad.py\", line 67, in imperative_grad\n",
            "    return pywrap_tfe.TFE_Py_TapeGradient(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/backprop.py\", line 148, in _gradient_function\n",
            "    return grad_fn(mock_op, *out_grads)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/array_grad.py\", line 865, in _TransposeGrad\n",
            "    return [array_ops.transpose(grad, array_ops.invert_permutation(p)), None]\n",
            "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 4666, in invert_permutation\n",
            "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1684, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "               ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 948, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 987, in getmodule\n",
            "    for modname, module in sys.modules.copy().items():\n",
            "                           ^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-a4dbf15f0567>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model with enhanced CW adversarial training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbilstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial_training_with_cw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbilstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_lr_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-0095a5e8a279>\u001b[0m in \u001b[0;36madversarial_training_with_cw\u001b[0;34m(model, train_features, train_labels, batch_size, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n🔹 Generating CW Adversarial Examples (steps={cw_steps}, epsilon={cw_epsilon})...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0madv_cw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_cw_adversarial_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcw_epsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcw_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-d23b7b4f0134>\u001b[0m in \u001b[0;36mgenerate_cw_adversarial_examples\u001b[0;34m(model, train_features, train_labels, epsilon, steps, batch_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Generate adversarial examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0madv_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcw_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/foolbox/attacks/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# run the actual attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/foolbox/attacks/carlini_wagner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mperturbed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_aux_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0mdelta\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/eagerpy/tensor/tensorflow.py\u001b[0m in \u001b[0;36mvalue_and_grad\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    481\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorFlowTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_TransposeGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvert_permutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36minvert_permutation\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m   4665\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4666\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   4667\u001b[0m         _ctx, \"InvertPermutation\", name, x)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "# Train the model with enhanced CW adversarial training\n",
        "bilstm_model = adversarial_training_with_cw(bilstm_model, train_lr_features, y_train_encoded, batch_size=64, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdCB7v9EJb4H"
      },
      "source": [
        "**Optimized Code: Faster Adversarial Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "kbqTCt85JZ0z",
        "outputId": "77140632-d638-4da7-b8b4-ece10b821fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Epoch 1/3\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (steps=40, epsilon=0.03)...\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (epsilon=0.03, steps=40)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-bb1e6fa8741d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Train the model with optimized CW adversarial training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mbilstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial_training_with_cw_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbilstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_lr_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-bb1e6fa8741d>\u001b[0m in \u001b[0;36madversarial_training_with_cw_optimized\u001b[0;34m(model, train_features, train_labels, batch_size, epochs, sample_ratio)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n🔹 Generating CW Adversarial Examples (steps={cw_steps}, epsilon={cw_epsilon})...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0madv_cw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_cw_adversarial_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcw_epsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcw_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n🔹 Generating PGD Adversarial Examples...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-a7c2d4bd0e27>\u001b[0m in \u001b[0;36mgenerate_cw_adversarial_examples\u001b[0;34m(model, train_features, train_labels, epsilon, steps, batch_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Generate adversarial examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0madv_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcw_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/foolbox/attacks/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# run the actual attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mxpcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/foolbox/attacks/carlini_wagner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mperturbed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_aux_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0mdelta\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/eagerpy/tensor/tensorflow.py\u001b[0m in \u001b[0;36mvalue_and_grad\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/foolbox/attacks/carlini_wagner.py\u001b[0m in \u001b[0;36mloss_fun\u001b[0;34m(delta, consts)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mis_adv_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mis_adv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_adv_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0mis_adv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_adv_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mis_adv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_adv_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/eagerpy/tensor/base.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorOrScalar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munwrap1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/override_binary_operator.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/tensor_math_operator_overrides.py\u001b[0m in \u001b[0;36m_add_dispatch_factory\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1715\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0mTV_AddV2_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TV_AddV2_T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBFloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComplex128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComplex64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHalf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUInt16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUInt32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUInt64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_atypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUInt8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAnnotated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTV_AddV2_T\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAnnotated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTV_AddV2_T\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAnnotated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTV_AddV2_T\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   r\"\"\"Returns x + y element-wise.\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "\n",
        "# ✅ Force eager execution for TF (Fix for NotImplementedError)\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "def safe_numpy(tensor):\n",
        "    \"\"\"Convert tensor to numpy only if eager execution is enabled\"\"\"\n",
        "    if tf.executing_eagerly():\n",
        "        return tensor.numpy()\n",
        "    return tensor  # Return unchanged if eager execution is disabled\n",
        "# **Generate CW Adversarial Examples (Optimized for Stability)**\n",
        "#def generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=0.03, steps=40, batch_size=256):\n",
        "\n",
        "def adversarial_training_with_cw_optimized(model, train_features, train_labels, batch_size=64, epochs=2, sample_ratio=0.5):\n",
        "    \"\"\"\n",
        "    Train the model using a combination of clean, FGSM, PGD, and CW adversarial examples.\n",
        "    \"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\n🔹 Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Increase CW attack strength per epoch\n",
        "        #cw_steps = 10 + (epoch * 5)\n",
        "        #cw_epsilon = 0.005 + (epoch / epochs) * 0.02\n",
        "\n",
        "        cw_steps = 40 + (epoch * 10)  # Increase steps for better optimization\n",
        "        cw_epsilon = 0.03 + (epoch / epochs) * 0.02  # Increase attack strength\n",
        "\n",
        "        print(f\"\\n🔹 Generating CW Adversarial Examples (steps={cw_steps}, epsilon={cw_epsilon})...\")\n",
        "        adv_cw = generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=cw_epsilon, steps=cw_steps)\n",
        "\n",
        "        print(f\"\\n🔹 Generating PGD Adversarial Examples...\")\n",
        "        attack_pgd = fb.attacks.LinfPGD(steps=10)\n",
        "        adv_pgd, _, _ = attack_pgd(fb.TensorFlowModel(model, bounds=(0, 1)), tf.convert_to_tensor(train_features, dtype=tf.float32), np.argmax(train_labels, axis=1), epsilons=0.02)\n",
        "\n",
        "        print(f\"\\n🔹 Generating FGSM Adversarial Examples...\")\n",
        "        attack_fgsm = fb.attacks.FGSM()\n",
        "        adv_fgsm, _, _ = attack_fgsm(fb.TensorFlowModel(model, bounds=(0, 1)), tf.convert_to_tensor(train_features, dtype=tf.float32), np.argmax(train_labels, axis=1), epsilons=0.01)\n",
        "\n",
        "        # Convert back to NumPy\n",
        "        adv_pgd = adv_pgd.numpy()\n",
        "        adv_fgsm = adv_fgsm.numpy()\n",
        "\n",
        "        # Ensure all shapes are consistent before concatenation\n",
        "        min_shape = min(train_features.shape[1], adv_cw.shape[1], adv_pgd.shape[1], adv_fgsm.shape[1])\n",
        "        train_features = train_features[:, :min_shape]\n",
        "        adv_cw = adv_cw[:, :min_shape]\n",
        "        adv_pgd = adv_pgd[:, :min_shape]\n",
        "        adv_fgsm = adv_fgsm[:, :min_shape]\n",
        "\n",
        "        # Combine clean and adversarial examples\n",
        "        combined_features = np.vstack([train_features, adv_cw, adv_pgd, adv_fgsm])\n",
        "        combined_labels = np.vstack([train_labels, train_labels, train_labels, train_labels])\n",
        "\n",
        "        # **Fix: Recompile the model to reset the optimizer**\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "\n",
        "        # Shuffle dataset\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((combined_features, combined_labels))\n",
        "        dataset = dataset.shuffle(buffer_size=len(combined_features)).batch(batch_size)\n",
        "\n",
        "        print(\"🔹 Training on CW-Optimized Adversarial Dataset...\")\n",
        "        model.fit(dataset, epochs=1, verbose=1)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train the model with optimized CW adversarial training\n",
        "bilstm_model = adversarial_training_with_cw_optimized(bilstm_model, train_lr_features, y_train_encoded, batch_size=64, epochs=3, sample_ratio=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import foolbox as fb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate_adversarial_robustness(model, test_features, test_labels, epsilon=0.02):\n",
        "    \"\"\"\n",
        "    Evaluate model robustness against FGSM, PGD, and CW attacks.\n",
        "    \"\"\"\n",
        "    fmodel = fb.TensorFlowModel(model, bounds=(0, 1))\n",
        "\n",
        "    print(\"\\n🔹 Running FGSM Attack...\")\n",
        "    attack_fgsm = fb.attacks.FGSM()\n",
        "    adv_fgsm, *_ = attack_fgsm(fmodel, tf.convert_to_tensor(test_features, dtype=tf.float32), np.argmax(test_labels, axis=1), epsilons=epsilon)\n",
        "    fgsm_predictions = np.argmax(model.predict(adv_fgsm.numpy()), axis=1)\n",
        "    fgsm_accuracy = accuracy_score(np.argmax(test_labels, axis=1), fgsm_predictions)\n",
        "\n",
        "    print(\"\\n🔹 Running PGD Attack...\")\n",
        "    attack_pgd = fb.attacks.LinfPGD(steps=10)\n",
        "    adv_pgd, *_ = attack_pgd(fmodel, tf.convert_to_tensor(test_features, dtype=tf.float32), np.argmax(test_labels, axis=1), epsilons=epsilon)\n",
        "    pgd_predictions = np.argmax(model.predict(adv_pgd.numpy()), axis=1)\n",
        "    pgd_accuracy = accuracy_score(np.argmax(test_labels, axis=1), pgd_predictions)\n",
        "\n",
        "    print(\"\\n🔹 Running CW Attack...\")\n",
        "    attack_cw = fb.attacks.L2CarliniWagnerAttack(binary_search_steps=5, steps=10)\n",
        "    adv_cw, *_ = attack_cw(fmodel, tf.convert_to_tensor(test_features, dtype=tf.float32), np.argmax(test_labels, axis=1), epsilons=epsilon)\n",
        "    cw_predictions = np.argmax(model.predict(adv_cw.numpy()), axis=1)\n",
        "    cw_accuracy = accuracy_score(np.argmax(test_labels, axis=1), cw_predictions)\n",
        "\n",
        "    return fgsm_accuracy, pgd_accuracy, cw_accuracy"
      ],
      "metadata": {
        "id": "R_6MvCIAffBm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQoMZ3FMwSrN"
      },
      "source": [
        "**📌 Step 4: Re-Evaluate CW Attack Performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PRRsk_INwTj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b46cad69-a91a-47c0-b8a9-57f801c5babd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Running FGSM Attack...\n",
            "\u001b[1m   3/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:39\u001b[0m 27ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 29ms/step\n",
            "\n",
            "🔹 Running PGD Attack...\n",
            "\u001b[1m   3/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:41\u001b[0m 28ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 29ms/step\n",
            "\n",
            "🔹 Running CW Attack...\n",
            "\u001b[1m   3/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:40\u001b[0m 28ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 28ms/step\n",
            "\n",
            "✅ FGSM Attack Accuracy (After CW Training): 0.99994086\n",
            "✅ PGD Attack Accuracy (After CW Training): 0.99994086\n",
            "✅ CW Attack Accuracy (After CW Training): 0.10000000\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model performance against adversarial attacks\n",
        "fgsm_acc, pgd_acc, cw_acc = evaluate_adversarial_robustness(bilstm_model, test_lr_features, y_test_encoded)\n",
        "\n",
        "# Print Updated Accuracy After CW Training\n",
        "print(f\"\\n✅ FGSM Attack Accuracy (After CW Training): {fgsm_acc:.8f}\")\n",
        "print(f\"✅ PGD Attack Accuracy (After CW Training): {pgd_acc:.8f}\")\n",
        "print(f\"✅ CW Attack Accuracy (After CW Training): {cw_acc:.8f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "\n",
        "# ✅ Ensure eager execution for TensorFlow (fixes certain execution issues)\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "def safe_numpy(tensor):\n",
        "    \"\"\"Convert tensor to numpy only if eager execution is enabled\"\"\"\n",
        "    if tf.executing_eagerly():\n",
        "        return tensor.numpy()\n",
        "    return tensor  # Return unchanged if eager execution is disabled\n",
        "\n",
        "# **Generate CW Adversarial Examples (Optimized for Stability)**\n",
        "def generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=0.03, steps=40, batch_size=256):\n",
        "    \"\"\"\n",
        "    Generate Carlini-Wagner (CW) adversarial examples in batches with increased attack strength.\n",
        "    \"\"\"\n",
        "    fmodel = fb.TensorFlowModel(model, bounds=(0, 1))\n",
        "    cw_attack = fb.attacks.L2CarliniWagnerAttack(binary_search_steps=10, steps=steps)\n",
        "\n",
        "    print(f\"\\n🔹 Generating CW Adversarial Examples (epsilon={epsilon}, steps={steps})...\")\n",
        "\n",
        "    # Convert labels to class indices\n",
        "    train_labels_indices = np.argmax(train_labels, axis=1)\n",
        "    train_features_tf = tf.convert_to_tensor(train_features, dtype=tf.float32)\n",
        "\n",
        "    adv_examples_list = []\n",
        "\n",
        "    for i in range(0, len(train_features), batch_size):\n",
        "        batch_features = train_features_tf[i:i + batch_size]\n",
        "        batch_labels = train_labels_indices[i:i + batch_size]\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        adv_batch = cw_attack(fmodel, batch_features, batch_labels, epsilons=epsilon)\n",
        "\n",
        "        # Convert to NumPy format\n",
        "        if isinstance(adv_batch, (tuple, list)):\n",
        "            adv_batch_np = np.array(adv_batch[0])\n",
        "        elif tf.is_tensor(adv_batch):\n",
        "            adv_batch_np = adv_batch.numpy()\n",
        "        else:\n",
        "            adv_batch_np = adv_batch\n",
        "\n",
        "        adv_examples_list.append(adv_batch_np)\n",
        "\n",
        "    # Stack adversarial examples\n",
        "    adv_examples_np = np.vstack(adv_examples_list)\n",
        "\n",
        "    return adv_examples_np\n",
        "\n",
        "# **Optimized CW Adversarial Training**\n",
        "def adversarial_training_with_cw_optimized(model, train_features, train_labels, batch_size=64, epochs=3, sample_ratio=0.5):\n",
        "    \"\"\"\n",
        "    Train the model using a combination of clean, FGSM, PGD, and CW adversarial examples.\n",
        "    \"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\n🔹 Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Increase CW attack strength per epoch\n",
        "        cw_steps = 40 + (epoch * 10)  # Increase steps for better optimization\n",
        "        cw_epsilon = 0.03 + (epoch / epochs) * 0.02  # Increase attack strength\n",
        "\n",
        "        print(f\"\\n🔹 Generating CW Adversarial Examples (steps={cw_steps}, epsilon={cw_epsilon})...\")\n",
        "        adv_cw = generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=cw_epsilon, steps=cw_steps)\n",
        "\n",
        "        print(f\"\\n🔹 Generating PGD Adversarial Examples...\")\n",
        "        attack_pgd = fb.attacks.LinfPGD(steps=10)\n",
        "        adv_pgd, _, _ = attack_pgd(fb.TensorFlowModel(model, bounds=(0, 1)), tf.convert_to_tensor(train_features, dtype=tf.float32), np.argmax(train_labels, axis=1), epsilons=0.02)\n",
        "\n",
        "        print(f\"\\n🔹 Generating FGSM Adversarial Examples...\")\n",
        "        attack_fgsm = fb.attacks.FGSM()\n",
        "        adv_fgsm, _, _ = attack_fgsm(fb.TensorFlowModel(model, bounds=(0, 1)), tf.convert_to_tensor(train_features, dtype=tf.float32), np.argmax(train_labels, axis=1), epsilons=0.01)\n",
        "\n",
        "        # Convert back to NumPy\n",
        "        adv_pgd = safe_numpy(adv_pgd)\n",
        "        adv_fgsm = safe_numpy(adv_fgsm)\n",
        "\n",
        "        # **Reduce dataset size to control training time**\n",
        "        sample_size = int(len(train_features) * sample_ratio)\n",
        "        train_features = train_features[:sample_size]\n",
        "        train_labels = train_labels[:sample_size]\n",
        "        adv_cw = adv_cw[:sample_size]\n",
        "        adv_pgd = adv_pgd[:sample_size]\n",
        "        adv_fgsm = adv_fgsm[:sample_size]\n",
        "\n",
        "        # Ensure all shapes are consistent before concatenation\n",
        "        min_shape = min(train_features.shape[1], adv_cw.shape[1], adv_pgd.shape[1], adv_fgsm.shape[1])\n",
        "        train_features = train_features[:, :min_shape]\n",
        "        adv_cw = adv_cw[:, :min_shape]\n",
        "        adv_pgd = adv_pgd[:, :min_shape]\n",
        "        adv_fgsm = adv_fgsm[:, :min_shape]\n",
        "\n",
        "        # Combine clean and adversarial examples\n",
        "        combined_features = np.vstack([train_features, adv_cw, adv_pgd, adv_fgsm])\n",
        "        combined_labels = np.vstack([train_labels, train_labels, train_labels, train_labels])\n",
        "\n",
        "        # **Fix: Recompile the model to reset the optimizer**\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), metrics=['accuracy'])\n",
        "\n",
        "        # Shuffle dataset\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((combined_features, combined_labels))\n",
        "        dataset = dataset.shuffle(buffer_size=len(combined_features)).batch(batch_size)\n",
        "\n",
        "        print(\"🔹 Training on CW-Optimized Adversarial Dataset...\")\n",
        "        model.fit(dataset, epochs=1, verbose=1)\n",
        "\n",
        "    return model\n",
        "\n",
        "# **Train the Model with Optimized CW Adversarial Training**\n",
        "bilstm_model = adversarial_training_with_cw_optimized(bilstm_model, train_lr_features, y_train_encoded, batch_size=64, epochs=2, sample_ratio=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZAoo76fqF5z",
        "outputId": "74e7437b-f87a-4892-edd9-a758d67742ad"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Epoch 1/2\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (steps=40, epsilon=0.03)...\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (epsilon=0.03, steps=40)...\n",
            "\n",
            "🔹 Generating PGD Adversarial Examples...\n",
            "\n",
            "🔹 Generating FGSM Adversarial Examples...\n",
            "🔹 Training on CW-Optimized Adversarial Dataset...\n",
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m829s\u001b[0m 143ms/step - accuracy: 0.7742 - loss: 0.8249\n",
            "\n",
            "🔹 Epoch 2/2\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (steps=50, epsilon=0.04)...\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (epsilon=0.04, steps=50)...\n",
            "\n",
            "🔹 Generating PGD Adversarial Examples...\n",
            "\n",
            "🔹 Generating FGSM Adversarial Examples...\n",
            "🔹 Training on CW-Optimized Adversarial Dataset...\n",
            "\u001b[1m2907/2907\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 139ms/step - accuracy: 0.7755 - loss: 0.8220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance against adversarial attacks\n",
        "fgsm_acc, pgd_acc, cw_acc = evaluate_adversarial_robustness(bilstm_model, test_lr_features, y_test_encoded)\n",
        "\n",
        "# Print Updated Accuracy After CW Training\n",
        "print(f\"\\n✅ FGSM Attack Accuracy (After CW Training): {fgsm_acc:.8f}\")\n",
        "print(f\"✅ PGD Attack Accuracy (After CW Training): {pgd_acc:.8f}\")\n",
        "print(f\"✅ CW Attack Accuracy (After CW Training): {cw_acc:.8f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6tYt6e0bt_W",
        "outputId": "d3ec029d-1637-417e-b272-dba78898739a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Running FGSM Attack...\n",
            "\u001b[1m   5/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 27ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 28ms/step\n",
            "\n",
            "🔹 Running PGD Attack...\n",
            "\u001b[1m   3/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:56\u001b[0m 30ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 28ms/step\n",
            "\n",
            "🔹 Running CW Attack...\n",
            "\u001b[1m   5/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 27ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 28ms/step\n",
            "\n",
            "✅ FGSM Attack Accuracy (After CW Training): 0.99994086\n",
            "✅ PGD Attack Accuracy (After CW Training): 0.99994086\n",
            "✅ CW Attack Accuracy (After CW Training): 0.10000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IYQ8OG6ajcG"
      },
      "source": [
        "**🔧 Step 3: Defensive Distillation (Optional)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hK9rpJe6aktV"
      },
      "outputs": [],
      "source": [
        "# Apply defensive distillation\n",
        "def defensive_distillation(model, train_features, train_labels, temperature=5):\n",
        "    \"\"\"\n",
        "    Use soft labels to make CW attacks less effective.\n",
        "    \"\"\"\n",
        "    soft_labels = model.predict(train_features) ** (1 / temperature)\n",
        "    return model.fit(train_features, soft_labels, epochs=5, batch_size=64, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**✅ Step 1: Implement Adversarial Loss Function**"
      ],
      "metadata": {
        "id": "o_y9771WVQ5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "\n",
        "# ✅ Ensure Eager Execution is Enabled (Fix for NotImplementedError)\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "def adversarial_loss(model, clean_features, adv_features, labels, alpha=1.0, beta=0.5):\n",
        "    \"\"\"\n",
        "    Compute total loss: classification loss + adversarial penalty loss.\n",
        "\n",
        "    - `alpha`: Weight of standard classification loss\n",
        "    - `beta`: Weight of adversarial penalty loss\n",
        "    \"\"\"\n",
        "    mse_loss = tf.keras.losses.MeanSquaredError()  # Instantiate MSE loss function\n",
        "\n",
        "    # Forward pass on clean and adversarial samples\n",
        "    clean_logits = model(clean_features)\n",
        "    adv_logits = model(adv_features)\n",
        "\n",
        "    # Classification loss (cross-entropy)\n",
        "    classification_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(labels, clean_logits))\n",
        "\n",
        "    # Adversarial penalty loss: minimize difference between clean & adversarial logits\n",
        "    adversarial_penalty = tf.reduce_mean(mse_loss(clean_logits, adv_logits))  # FIXED\n",
        "\n",
        "    # Total loss (weighted sum of classification and adversarial loss)\n",
        "    total_loss = alpha * classification_loss + beta * adversarial_penalty\n",
        "\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "yfPFU0NqVKYN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**✅ Step 2: Modify Training Loop to Include Adversarial Loss**"
      ],
      "metadata": {
        "id": "zWsASq-uVcQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adversarial_training_with_loss(model, train_features, train_labels, batch_size=64, epochs=3):\n",
        "    \"\"\"\n",
        "    Train the model using a combination of clean, FGSM, PGD, and CW adversarial examples.\n",
        "    \"\"\"\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam()  # Reinitialize optimizer\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\n🔹 Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Increase CW attack strength per epoch\n",
        "        cw_steps = 40 + (epoch * 10)  # Increase steps for better optimization\n",
        "        cw_epsilon = 0.03 + (epoch / epochs) * 0.02  # Increase attack strength\n",
        "\n",
        "        print(f\"\\n🔹 Generating CW Adversarial Examples (steps={cw_steps}, epsilon={cw_epsilon})...\")\n",
        "        adv_cw = generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=cw_epsilon, steps=cw_steps)\n",
        "\n",
        "        print(f\"\\n🔹 Generating PGD Adversarial Examples...\")\n",
        "        attack_pgd = fb.attacks.LinfPGD(steps=10)\n",
        "        adv_pgd, _, _ = attack_pgd(fb.TensorFlowModel(model, bounds=(0, 1)), tf.convert_to_tensor(train_features, dtype=tf.float32), np.argmax(train_labels, axis=1), epsilons=0.02)\n",
        "\n",
        "        print(f\"\\n🔹 Generating FGSM Adversarial Examples...\")\n",
        "        attack_fgsm = fb.attacks.FGSM()\n",
        "        adv_fgsm, _, _ = attack_fgsm(fb.TensorFlowModel(model, bounds=(0, 1)), tf.convert_to_tensor(train_features, dtype=tf.float32), np.argmax(train_labels, axis=1), epsilons=0.01)\n",
        "\n",
        "        # Convert back to NumPy\n",
        "        adv_pgd = adv_pgd.numpy()\n",
        "        adv_fgsm = adv_fgsm.numpy()\n",
        "\n",
        "        # Ensure all shapes are consistent before concatenation\n",
        "        min_shape = min(train_features.shape[1], adv_cw.shape[1], adv_pgd.shape[1], adv_fgsm.shape[1])\n",
        "        train_features = train_features[:, :min_shape]\n",
        "        adv_cw = adv_cw[:, :min_shape]\n",
        "        adv_pgd = adv_pgd[:, :min_shape]\n",
        "        adv_fgsm = adv_fgsm[:, :min_shape]\n",
        "\n",
        "        # Combine clean and adversarial examples\n",
        "        combined_features = np.vstack([train_features, adv_cw, adv_pgd, adv_fgsm])\n",
        "        combined_labels = np.vstack([train_labels, train_labels, train_labels, train_labels])\n",
        "\n",
        "        # Shuffle dataset\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((combined_features, combined_labels))\n",
        "        dataset = dataset.shuffle(buffer_size=len(combined_features)).batch(batch_size)\n",
        "\n",
        "        print(\"🔹 Training on CW-Optimized Adversarial Dataset...\")\n",
        "\n",
        "        # Custom Training Loop to Apply Adversarial Loss\n",
        "        for step, (batch_x, batch_y) in enumerate(dataset):\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Compute adversarial loss\n",
        "                loss = adversarial_loss(model, batch_x, adv_cw[:len(batch_x)], batch_y)\n",
        "\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "            if step % 500 == 0:\n",
        "                print(f\"Step {step}: Loss = {tf.reduce_mean(loss).numpy():.6f}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "M_tqTomTVXmZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "\n",
        "def generate_cw_adversarial_examples(model, train_features, train_labels, epsilon=0.01, steps=40, batch_size=256):\n",
        "    \"\"\"\n",
        "    Generate Carlini-Wagner (CW) adversarial examples in batches for stability.\n",
        "    \"\"\"\n",
        "    fmodel = fb.TensorFlowModel(model, bounds=(0, 1))\n",
        "    cw_attack = fb.attacks.L2CarliniWagnerAttack(binary_search_steps=5, steps=steps)\n",
        "\n",
        "    print(f\"\\n🔹 Generating CW Adversarial Examples (epsilon={epsilon}, steps={steps})...\")\n",
        "\n",
        "    # Convert labels to class indices\n",
        "    train_labels_indices = np.argmax(train_labels, axis=1)\n",
        "    train_features_tf = tf.convert_to_tensor(train_features, dtype=tf.float32)\n",
        "\n",
        "    adv_examples_list = []\n",
        "\n",
        "    for i in range(0, len(train_features), batch_size):\n",
        "        batch_features = train_features_tf[i:i + batch_size]\n",
        "        batch_labels = train_labels_indices[i:i + batch_size]\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        adv_batch = cw_attack(fmodel, batch_features, batch_labels, epsilons=epsilon)\n",
        "\n",
        "        # Convert to NumPy format\n",
        "        if isinstance(adv_batch, (tuple, list)):\n",
        "            adv_batch_np = np.array(adv_batch[0])\n",
        "        elif tf.is_tensor(adv_batch):\n",
        "            adv_batch_np = adv_batch.numpy()\n",
        "        else:\n",
        "            adv_batch_np = adv_batch\n",
        "\n",
        "        adv_examples_list.append(adv_batch_np)\n",
        "\n",
        "    # Combine all batches into a single NumPy array\n",
        "    adv_examples_np = np.concatenate(adv_examples_list, axis=0)\n",
        "\n",
        "    return adv_examples_np"
      ],
      "metadata": {
        "id": "D2rXUrAKWHDR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with optimized CW adversarial training\n",
        "bilstm_model = adversarial_training_with_loss(bilstm_model, train_lr_features, y_train_encoded, batch_size=64, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpBhsLS3Vl4X",
        "outputId": "054bbfdc-0859-4c3c-c5fa-90e8f5cfa063"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Epoch 1/3\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (steps=40, epsilon=0.03)...\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (epsilon=0.03, steps=40)...\n",
            "\n",
            "🔹 Generating PGD Adversarial Examples...\n",
            "\n",
            "🔹 Generating FGSM Adversarial Examples...\n",
            "🔹 Training on CW-Optimized Adversarial Dataset...\n",
            "Step 0: Loss = 0.582018\n",
            "Step 500: Loss = 0.609233\n",
            "Step 1000: Loss = 0.645282\n",
            "Step 1500: Loss = 0.833731\n",
            "Step 2000: Loss = 0.535553\n",
            "Step 2500: Loss = 0.641524\n",
            "Step 3000: Loss = 0.606448\n",
            "Step 3500: Loss = 0.649551\n",
            "Step 4000: Loss = 0.430348\n",
            "Step 4500: Loss = 0.535532\n",
            "Step 5000: Loss = 0.505344\n",
            "Step 5500: Loss = 0.395422\n",
            "Step 6000: Loss = 0.653648\n",
            "Step 6500: Loss = 0.717371\n",
            "Step 7000: Loss = 0.860825\n",
            "Step 7500: Loss = 0.680958\n",
            "Step 8000: Loss = 0.434894\n",
            "Step 8500: Loss = 0.645679\n",
            "Step 9000: Loss = 0.821846\n",
            "Step 9500: Loss = 0.749335\n",
            "Step 10000: Loss = 0.675520\n",
            "Step 10500: Loss = 0.572534\n",
            "Step 11000: Loss = 0.503450\n",
            "Step 11500: Loss = 0.502582\n",
            "Step 12000: Loss = 0.549880\n",
            "Step 12500: Loss = 0.861760\n",
            "Step 13000: Loss = 0.508387\n",
            "Step 13500: Loss = 0.749923\n",
            "Step 14000: Loss = 0.657296\n",
            "Step 14500: Loss = 0.505125\n",
            "Step 15000: Loss = 0.435492\n",
            "Step 15500: Loss = 0.470813\n",
            "Step 16000: Loss = 0.502273\n",
            "Step 16500: Loss = 0.644795\n",
            "Step 17000: Loss = 0.573764\n",
            "Step 17500: Loss = 0.715726\n",
            "Step 18000: Loss = 0.678245\n",
            "Step 18500: Loss = 0.605187\n",
            "Step 19000: Loss = 0.751459\n",
            "Step 19500: Loss = 0.614639\n",
            "Step 20000: Loss = 0.641187\n",
            "Step 20500: Loss = 0.360982\n",
            "Step 21000: Loss = 0.575366\n",
            "Step 21500: Loss = 0.645994\n",
            "Step 22000: Loss = 0.571545\n",
            "Step 22500: Loss = 0.435909\n",
            "Step 23000: Loss = 0.612695\n",
            "Step 23500: Loss = 0.401825\n",
            "Step 24000: Loss = 0.639633\n",
            "Step 24500: Loss = 0.676559\n",
            "Step 25000: Loss = 0.725064\n",
            "Step 25500: Loss = 0.544107\n",
            "Step 26000: Loss = 0.585601\n",
            "Step 26500: Loss = 0.643879\n",
            "Step 27000: Loss = 0.610055\n",
            "Step 27500: Loss = 0.783696\n",
            "Step 28000: Loss = 0.845798\n",
            "Step 28500: Loss = 0.649229\n",
            "Step 29000: Loss = 0.827062\n",
            "Step 29500: Loss = 0.681890\n",
            "Step 30000: Loss = 0.685085\n",
            "Step 30500: Loss = 0.588183\n",
            "Step 31000: Loss = 0.542599\n",
            "Step 31500: Loss = 0.655756\n",
            "Step 32000: Loss = 0.617547\n",
            "Step 32500: Loss = 0.750905\n",
            "Step 33000: Loss = 0.618904\n",
            "Step 33500: Loss = 0.577310\n",
            "Step 34000: Loss = 0.760391\n",
            "Step 34500: Loss = 0.639088\n",
            "Step 35000: Loss = 0.714466\n",
            "Step 35500: Loss = 0.819244\n",
            "Step 36000: Loss = 0.539641\n",
            "Step 36500: Loss = 0.432628\n",
            "Step 37000: Loss = 0.501166\n",
            "Step 37500: Loss = 0.431913\n",
            "Step 38000: Loss = 0.537634\n",
            "Step 38500: Loss = 0.612319\n",
            "Step 39000: Loss = 0.782918\n",
            "Step 39500: Loss = 0.678955\n",
            "Step 40000: Loss = 0.466087\n",
            "Step 40500: Loss = 0.644261\n",
            "Step 41000: Loss = 0.643095\n",
            "Step 41500: Loss = 0.473963\n",
            "Step 42000: Loss = 0.538016\n",
            "Step 42500: Loss = 0.707396\n",
            "Step 43000: Loss = 0.572016\n",
            "Step 43500: Loss = 0.646717\n",
            "Step 44000: Loss = 0.640530\n",
            "Step 44500: Loss = 0.755585\n",
            "Step 45000: Loss = 0.329146\n",
            "Step 45500: Loss = 0.889828\n",
            "Step 46000: Loss = 0.643969\n",
            "\n",
            "🔹 Epoch 2/3\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (steps=50, epsilon=0.03666666666666667)...\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (epsilon=0.03666666666666667, steps=50)...\n",
            "\n",
            "🔹 Generating PGD Adversarial Examples...\n",
            "\n",
            "🔹 Generating FGSM Adversarial Examples...\n",
            "🔹 Training on CW-Optimized Adversarial Dataset...\n",
            "Step 0: Loss = 0.472887\n",
            "Step 500: Loss = 0.540538\n",
            "Step 1000: Loss = 0.395038\n",
            "Step 1500: Loss = 0.577573\n",
            "Step 2000: Loss = 0.502030\n",
            "Step 2500: Loss = 0.757235\n",
            "Step 3000: Loss = 0.648784\n",
            "Step 3500: Loss = 0.645086\n",
            "Step 4000: Loss = 0.571333\n",
            "Step 4500: Loss = 0.638422\n",
            "Step 5000: Loss = 0.466832\n",
            "Step 5500: Loss = 0.549092\n",
            "Step 6000: Loss = 0.398046\n",
            "Step 6500: Loss = 0.643387\n",
            "Step 7000: Loss = 0.715758\n",
            "Step 7500: Loss = 0.641317\n",
            "Step 8000: Loss = 0.500826\n",
            "Step 8500: Loss = 0.538688\n",
            "Step 9000: Loss = 0.539237\n",
            "Step 9500: Loss = 0.715097\n",
            "Step 10000: Loss = 0.468909\n",
            "Step 10500: Loss = 0.712006\n",
            "Step 11000: Loss = 0.361464\n",
            "Step 11500: Loss = 0.467625\n",
            "Step 12000: Loss = 0.468932\n",
            "Step 12500: Loss = 0.358414\n",
            "Step 13000: Loss = 0.606420\n",
            "Step 13500: Loss = 0.719277\n",
            "Step 14000: Loss = 0.718085\n",
            "Step 14500: Loss = 0.471507\n",
            "Step 15000: Loss = 0.537760\n",
            "Step 15500: Loss = 0.364766\n",
            "Step 16000: Loss = 0.756674\n",
            "Step 16500: Loss = 0.609995\n",
            "Step 17000: Loss = 0.607814\n",
            "Step 17500: Loss = 0.609068\n",
            "Step 18000: Loss = 0.608040\n",
            "Step 18500: Loss = 0.644120\n",
            "Step 19000: Loss = 0.614787\n",
            "Step 19500: Loss = 0.643163\n",
            "Step 20000: Loss = 0.713742\n",
            "Step 20500: Loss = 0.503730\n",
            "Step 21000: Loss = 0.434734\n",
            "Step 21500: Loss = 0.539523\n",
            "Step 22000: Loss = 0.724211\n",
            "Step 22500: Loss = 0.400223\n",
            "Step 23000: Loss = 0.538342\n",
            "Step 23500: Loss = 0.642795\n",
            "Step 24000: Loss = 0.501756\n",
            "Step 24500: Loss = 0.679816\n",
            "Step 25000: Loss = 0.678318\n",
            "Step 25500: Loss = 0.607272\n",
            "Step 26000: Loss = 0.612776\n",
            "Step 26500: Loss = 0.577318\n",
            "Step 27000: Loss = 0.577199\n",
            "Step 27500: Loss = 0.539327\n",
            "Step 28000: Loss = 0.434744\n",
            "Step 28500: Loss = 0.540846\n",
            "Step 29000: Loss = 0.539172\n",
            "Step 29500: Loss = 0.896850\n",
            "Step 30000: Loss = 0.644985\n",
            "Step 30500: Loss = 1.005180\n",
            "Step 31000: Loss = 0.431883\n",
            "Step 31500: Loss = 0.576798\n",
            "Step 32000: Loss = 0.536395\n",
            "Step 32500: Loss = 0.503900\n",
            "Step 33000: Loss = 0.433289\n",
            "Step 33500: Loss = 0.575617\n",
            "Step 34000: Loss = 0.642143\n",
            "Step 34500: Loss = 0.540695\n",
            "Step 35000: Loss = 0.574278\n",
            "Step 35500: Loss = 0.538269\n",
            "Step 36000: Loss = 0.607433\n",
            "Step 36500: Loss = 0.607399\n",
            "Step 37000: Loss = 0.645371\n",
            "Step 37500: Loss = 0.888525\n",
            "Step 38000: Loss = 0.827165\n",
            "Step 38500: Loss = 0.681055\n",
            "Step 39000: Loss = 0.749677\n",
            "Step 39500: Loss = 0.642285\n",
            "Step 40000: Loss = 0.783702\n",
            "Step 40500: Loss = 0.610583\n",
            "Step 41000: Loss = 0.471997\n",
            "Step 41500: Loss = 0.430966\n",
            "Step 42000: Loss = 0.534381\n",
            "Step 42500: Loss = 0.483502\n",
            "Step 43000: Loss = 0.433853\n",
            "Step 43500: Loss = 0.502590\n",
            "Step 44000: Loss = 0.469448\n",
            "Step 44500: Loss = 0.790039\n",
            "Step 45000: Loss = 0.534776\n",
            "Step 45500: Loss = 0.718371\n",
            "Step 46000: Loss = 0.469936\n",
            "\n",
            "🔹 Epoch 3/3\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (steps=60, epsilon=0.043333333333333335)...\n",
            "\n",
            "🔹 Generating CW Adversarial Examples (epsilon=0.043333333333333335, steps=60)...\n",
            "\n",
            "🔹 Generating PGD Adversarial Examples...\n",
            "\n",
            "🔹 Generating FGSM Adversarial Examples...\n",
            "🔹 Training on CW-Optimized Adversarial Dataset...\n",
            "Step 0: Loss = 0.577303\n",
            "Step 500: Loss = 0.504035\n",
            "Step 1000: Loss = 1.069823\n",
            "Step 1500: Loss = 0.717718\n",
            "Step 2000: Loss = 0.716607\n",
            "Step 2500: Loss = 0.641913\n",
            "Step 3000: Loss = 0.540606\n",
            "Step 3500: Loss = 0.576171\n",
            "Step 4000: Loss = 0.433290\n",
            "Step 4500: Loss = 0.501895\n",
            "Step 5000: Loss = 0.536971\n",
            "Step 5500: Loss = 0.468763\n",
            "Step 6000: Loss = 0.611526\n",
            "Step 6500: Loss = 0.504892\n",
            "Step 7000: Loss = 0.498301\n",
            "Step 7500: Loss = 0.505553\n",
            "Step 8000: Loss = 0.545452\n",
            "Step 8500: Loss = 0.503779\n",
            "Step 9000: Loss = 0.255770\n",
            "Step 9500: Loss = 0.431953\n",
            "Step 10000: Loss = 0.540029\n",
            "Step 10500: Loss = 0.751459\n",
            "Step 11000: Loss = 0.748553\n",
            "Step 11500: Loss = 0.568759\n",
            "Step 12000: Loss = 0.538675\n",
            "Step 12500: Loss = 0.538712\n",
            "Step 13000: Loss = 0.572053\n",
            "Step 13500: Loss = 0.539067\n",
            "Step 14000: Loss = 0.719558\n",
            "Step 14500: Loss = 0.748676\n",
            "Step 15000: Loss = 0.713266\n",
            "Step 15500: Loss = 0.398749\n",
            "Step 16000: Loss = 0.640950\n",
            "Step 16500: Loss = 0.642032\n",
            "Step 17000: Loss = 0.607407\n",
            "Step 17500: Loss = 0.574688\n",
            "Step 18000: Loss = 0.676211\n",
            "Step 18500: Loss = 0.606010\n",
            "Step 19000: Loss = 0.541038\n",
            "Step 19500: Loss = 0.890723\n",
            "Step 20000: Loss = 0.609069\n",
            "Step 20500: Loss = 0.643762\n",
            "Step 21000: Loss = 0.538363\n",
            "Step 21500: Loss = 0.609759\n",
            "Step 22000: Loss = 0.608558\n",
            "Step 22500: Loss = 0.609589\n",
            "Step 23000: Loss = 0.855392\n",
            "Step 23500: Loss = 0.502754\n",
            "Step 24000: Loss = 0.750874\n",
            "Step 24500: Loss = 0.609759\n",
            "Step 25000: Loss = 0.720948\n",
            "Step 25500: Loss = 0.645200\n",
            "Step 26000: Loss = 0.539010\n",
            "Step 26500: Loss = 0.505964\n",
            "Step 27000: Loss = 0.607686\n",
            "Step 27500: Loss = 0.610297\n",
            "Step 28000: Loss = 0.532696\n",
            "Step 28500: Loss = 0.505975\n",
            "Step 29000: Loss = 0.462768\n",
            "Step 29500: Loss = 0.646056\n",
            "Step 30000: Loss = 0.862281\n",
            "Step 30500: Loss = 0.502111\n",
            "Step 31000: Loss = 0.541358\n",
            "Step 31500: Loss = 0.748875\n",
            "Step 32000: Loss = 0.470549\n",
            "Step 32500: Loss = 0.652587\n",
            "Step 33000: Loss = 0.716121\n",
            "Step 33500: Loss = 0.713802\n",
            "Step 34000: Loss = 0.817872\n",
            "Step 34500: Loss = 0.575075\n",
            "Step 35000: Loss = 0.432483\n",
            "Step 35500: Loss = 0.570971\n",
            "Step 36000: Loss = 0.793175\n",
            "Step 36500: Loss = 0.538285\n",
            "Step 37000: Loss = 0.716868\n",
            "Step 37500: Loss = 0.611640\n",
            "Step 38000: Loss = 0.928338\n",
            "Step 38500: Loss = 0.790443\n",
            "Step 39000: Loss = 0.578417\n",
            "Step 39500: Loss = 0.574084\n",
            "Step 40000: Loss = 0.538903\n",
            "Step 40500: Loss = 0.716412\n",
            "Step 41000: Loss = 0.756907\n",
            "Step 41500: Loss = 0.718322\n",
            "Step 42000: Loss = 0.573554\n",
            "Step 42500: Loss = 0.640453\n",
            "Step 43000: Loss = 0.570432\n",
            "Step 43500: Loss = 0.611011\n",
            "Step 44000: Loss = 0.470169\n",
            "Step 44500: Loss = 0.688919\n",
            "Step 45000: Loss = 0.434655\n",
            "Step 45500: Loss = 0.507141\n",
            "Step 46000: Loss = 0.647720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import foolbox as fb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate_adversarial_robustness(model, test_features, test_labels, epsilon=0.02):\n",
        "    \"\"\"\n",
        "    Evaluate model robustness against FGSM, PGD, and CW attacks.\n",
        "    \"\"\"\n",
        "    fmodel = fb.TensorFlowModel(model, bounds=(0, 1))\n",
        "\n",
        "    print(\"\\n🔹 Running FGSM Attack...\")\n",
        "    attack_fgsm = fb.attacks.FGSM()\n",
        "    adv_fgsm, *_ = attack_fgsm(fmodel, tf.convert_to_tensor(test_features, dtype=tf.float32), np.argmax(test_labels, axis=1), epsilons=epsilon)\n",
        "    fgsm_predictions = np.argmax(model.predict(adv_fgsm.numpy()), axis=1)\n",
        "    fgsm_accuracy = accuracy_score(np.argmax(test_labels, axis=1), fgsm_predictions)\n",
        "\n",
        "    print(\"\\n🔹 Running PGD Attack...\")\n",
        "    attack_pgd = fb.attacks.LinfPGD(steps=10)\n",
        "    adv_pgd, *_ = attack_pgd(fmodel, tf.convert_to_tensor(test_features, dtype=tf.float32), np.argmax(test_labels, axis=1), epsilons=epsilon)\n",
        "    pgd_predictions = np.argmax(model.predict(adv_pgd.numpy()), axis=1)\n",
        "    pgd_accuracy = accuracy_score(np.argmax(test_labels, axis=1), pgd_predictions)\n",
        "\n",
        "    print(\"\\n🔹 Running CW Attack...\")\n",
        "    attack_cw = fb.attacks.L2CarliniWagnerAttack(binary_search_steps=5, steps=10)\n",
        "    adv_cw, *_ = attack_cw(fmodel, tf.convert_to_tensor(test_features, dtype=tf.float32), np.argmax(test_labels, axis=1), epsilons=epsilon)\n",
        "    cw_predictions = np.argmax(model.predict(adv_cw.numpy()), axis=1)\n",
        "    cw_accuracy = accuracy_score(np.argmax(test_labels, axis=1), cw_predictions)\n",
        "\n",
        "    return fgsm_accuracy, pgd_accuracy, cw_accuracy"
      ],
      "metadata": {
        "id": "CgB17-sqarui"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance against adversarial attacks\n",
        "fgsm_acc, pgd_acc, cw_acc = evaluate_adversarial_robustness(bilstm_model, test_lr_features, y_test_encoded)\n",
        "\n",
        "# Print Updated Accuracy After CW Training\n",
        "print(f\"\\n✅ FGSM Attack Accuracy (After CW Training): {fgsm_acc:.8f}\")\n",
        "print(f\"✅ PGD Attack Accuracy (After CW Training): {pgd_acc:.8f}\")\n",
        "print(f\"✅ CW Attack Accuracy (After CW Training): {cw_acc:.8f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxWANrY_VrQZ",
        "outputId": "43a58eb6-74b7-45f8-c641-0fb6f02fa5d7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Running FGSM Attack...\n",
            "\u001b[1m   1/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:41\u001b[0m 90ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 43ms/step\n",
            "\n",
            "🔹 Running PGD Attack...\n",
            "\u001b[1m   3/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:03\u001b[0m 42ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 43ms/step\n",
            "\n",
            "🔹 Running CW Attack...\n",
            "\u001b[1m   1/5813\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:02\u001b[0m 73ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 43ms/step\n",
            "\n",
            "✅ FGSM Attack Accuracy (After CW Training): 0.99994624\n",
            "✅ PGD Attack Accuracy (After CW Training): 0.99995161\n",
            "✅ CW Attack Accuracy (After CW Training): 0.10000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**🔹 Step 1: Update Code to Remove CW Attack**"
      ],
      "metadata": {
        "id": "-L_2o3g1i5lx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import foolbox as fb\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# ✅ Load trained model\n",
        "bilstm_model = load_model(\"bilstm_model.h5\")\n",
        "\n",
        "# ✅ Load dataset features\n",
        "with open(\"features.pkl\", \"rb\") as f:\n",
        "    train_lr_features, test_lr_features, y_train_encoded, y_test_encoded = pickle.load(f)\n",
        "\n",
        "# ✅ Convert to Foolbox-compatible model\n",
        "fmodel = fb.TensorFlowModel(bilstm_model, bounds=(0, 1))\n",
        "\n",
        "# ✅ Generate adversarial examples for FGSM & PGD\n",
        "def generate_adversarial_examples(attack, eps):\n",
        "    \"\"\"Generate adversarial examples using Foolbox attacks.\"\"\"\n",
        "    raw_adversarials, *_ = attack(fmodel,\n",
        "                                  tf.convert_to_tensor(test_lr_features, dtype=tf.float32),\n",
        "                                  np.argmax(y_test_encoded, axis=1),\n",
        "                                  epsilons=eps)\n",
        "    return raw_adversarials.numpy()\n",
        "\n",
        "print(\"🔹 Generating FGSM Adversarial Examples...\")\n",
        "adv_fgsm = generate_adversarial_examples(fb.attacks.FGSM(), 0.01)\n",
        "\n",
        "print(\"🔹 Generating PGD Adversarial Examples...\")\n",
        "adv_pgd = generate_adversarial_examples(fb.attacks.LinfPGD(steps=10), 0.02)\n",
        "\n",
        "# ✅ Evaluate model on adversarial examples\n",
        "def evaluate_adversarial_robustness(model, adv_examples, true_labels):\n",
        "    \"\"\"Evaluate model accuracy on adversarial examples.\"\"\"\n",
        "    adv_predictions = np.argmax(model.predict(adv_examples), axis=1)\n",
        "    true_labels = np.argmax(true_labels, axis=1)\n",
        "    return np.mean(adv_predictions == true_labels)\n",
        "\n",
        "# ✅ Compute adversarial accuracy\n",
        "fgsm_acc = evaluate_adversarial_robustness(bilstm_model, adv_fgsm, y_test_encoded)\n",
        "pgd_acc = evaluate_adversarial_robustness(bilstm_model, adv_pgd, y_test_encoded)\n",
        "\n",
        "# ✅ Save results\n",
        "evaluation_results = {\n",
        "    \"clean_accuracy\": np.mean(np.argmax(bilstm_model.predict(test_lr_features), axis=1) == np.argmax(y_test_encoded, axis=1)),\n",
        "    \"fgsm_accuracy\": fgsm_acc,\n",
        "    \"pgd_accuracy\": pgd_acc,\n",
        "}\n",
        "\n",
        "with open(\"evaluation_results.pkl\", \"wb\") as f:\n",
        "    pickle.dump(evaluation_results, f)\n",
        "\n",
        "print(f\"\\n✅ Final Model Evaluation:\")\n",
        "print(f\"✅ FGSM Attack Accuracy: {fgsm_acc:.8f}\")\n",
        "print(f\"✅ PGD Attack Accuracy: {pgd_acc:.8f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuran5QCixE8",
        "outputId": "bf7d1d8b-3e7c-4fc7-a9fa-23184a3d3abd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/foolbox/models/tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Generating FGSM Adversarial Examples...\n",
            "🔹 Generating PGD Adversarial Examples...\n",
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step\n",
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step\n",
            "\u001b[1m5813/5813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step\n",
            "\n",
            "✅ Final Model Evaluation:\n",
            "✅ FGSM Attack Accuracy: 0.99989785\n",
            "✅ PGD Attack Accuracy: 0.99989785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**🔹 Step 2: Generate Final Tables & Graphs**"
      ],
      "metadata": {
        "id": "b71FZrT9jB7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# ✅ Load evaluation results\n",
        "with open(\"evaluation_results.pkl\", \"rb\") as f:\n",
        "    evaluation_results = pickle.load(f)\n",
        "\n",
        "# ✅ Convert results to a DataFrame for better readability\n",
        "df_results = pd.DataFrame(evaluation_results.items(), columns=[\"Attack Type\", \"Accuracy\"])\n",
        "\n",
        "# ✅ Display results\n",
        "print(df_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMGs1CC3m5_W",
        "outputId": "5ffcb9ca-cc96-4675-df98-529b82db0de5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Attack Type  Accuracy\n",
            "0  clean_accuracy  0.999914\n",
            "1   fgsm_accuracy  0.999898\n",
            "2    pgd_accuracy  0.999898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "print(tabulate(df_results, headers='keys', tablefmt='grid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRrS-l-0nCb4",
        "outputId": "79d105c7-340d-4f9e-e1f2-dde468458fe7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------------+------------+\n",
            "|    | Attack Type    |   Accuracy |\n",
            "+====+================+============+\n",
            "|  0 | clean_accuracy |   0.999914 |\n",
            "+----+----------------+------------+\n",
            "|  1 | fgsm_accuracy  |   0.999898 |\n",
            "+----+----------------+------------+\n",
            "|  2 | pgd_accuracy   |   0.999898 |\n",
            "+----+----------------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib-venn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUTIksXDnRFm",
        "outputId": "4bcf6812-9878-4139-c62f-62a74d97600c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from matplotlib-venn) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from matplotlib-venn) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from matplotlib-venn) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->matplotlib-venn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib-venn) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y libfluidsynth1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xrD7m-VnVUY",
        "outputId": "e455115b-7b71-4ae5-9440-03c2e8e0527c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Package 'libfluidsynth1' has no installation candidate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.python.org/pypi/libarchive\n",
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "import libarchive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-JSajrRnaap",
        "outputId": "f1b25e60-e8cc-477f-ca32-149f302621e5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.3) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting libarchive\n",
            "  Downloading libarchive-0.4.7.tar.gz (23 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nose (from libarchive)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: libarchive\n",
            "  Building wheel for libarchive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libarchive: filename=libarchive-0.4.7-py3-none-any.whl size=31631 sha256=c727fd2380248cf4eaef991a4307722ce8696d5be7197ea62d7d2adcfac5c611\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/98/bd/4893d6923dd027f455b250367d402bfd69a6f4416581df46db\n",
            "Successfully built libarchive\n",
            "Installing collected packages: nose, libarchive\n",
            "Successfully installed libarchive-0.4.7 nose-1.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.python.org/pypi/pydot\n",
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "import pydot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYo6IKyLnez_",
        "outputId": "5a5ebb56-5497-4db5-d24b-21b3cb5077c0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydot in /usr/local/lib/python3.11/dist-packages (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=3.0.9 in /usr/local/lib/python3.11/dist-packages (from pydot) (3.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cartopy\n",
        "import cartopy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_pIeVSBnhgB",
        "outputId": "4a9bd18a-a651-428e-e5b1-10aa7e91b832"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cartopy\n",
            "  Downloading Cartopy-0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from cartopy) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from cartopy) (3.10.0)\n",
            "Requirement already satisfied: shapely>=1.8 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.0.6)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from cartopy) (24.2)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.11/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.11/dist-packages (from cartopy) (3.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->cartopy) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyproj>=3.3.1->cartopy) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->cartopy) (1.17.0)\n",
            "Downloading Cartopy-0.24.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cartopy\n",
            "Successfully installed cartopy-0.24.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt  # Import matplotlib for plotting\n",
        "\n",
        "# ✅ Load evaluation results\n",
        "with open(\"evaluation_results.pkl\", \"rb\") as f:\n",
        "    eval_results = pickle.load(f)\n",
        "\n",
        "# ✅ Create DataFrame\n",
        "df_results = pd.DataFrame({\n",
        "    \"Metric\": [\"Clean Accuracy\", \"FGSM Attack Accuracy\", \"PGD Attack Accuracy\"],\n",
        "    \"Accuracy\": [eval_results[\"clean_accuracy\"], eval_results[\"fgsm_accuracy\"], eval_results[\"pgd_accuracy\"]]\n",
        "})\n",
        "\n",
        "# ✅ Display results using pandas (since ace_tools is unavailable)\n",
        "print(df_results)\n",
        "\n",
        "# ✅ Display results in a formatted table using tabulate\n",
        "from tabulate import tabulate\n",
        "print(tabulate(df_results, headers='keys', tablefmt='grid'))\n",
        "\n",
        "# ✅ Plot adversarial accuracy comparison\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar([\"Clean\", \"FGSM\", \"PGD\"], [eval_results[\"clean_accuracy\"], eval_results[\"fgsm_accuracy\"], eval_results[\"pgd_accuracy\"]])\n",
        "plt.xlabel(\"Evaluation Scenario\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model Performance on Adversarial Attacks (FGSM & PGD)\")\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "sXeuEbrmi-65",
        "outputId": "53479a07-b5dc-493d-dfeb-339b3dc69bb8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Metric  Accuracy\n",
            "0        Clean Accuracy  0.999914\n",
            "1  FGSM Attack Accuracy  0.999898\n",
            "2   PGD Attack Accuracy  0.999898\n",
            "+----+----------------------+------------+\n",
            "|    | Metric               |   Accuracy |\n",
            "+====+======================+============+\n",
            "|  0 | Clean Accuracy       |   0.999914 |\n",
            "+----+----------------------+------------+\n",
            "|  1 | FGSM Attack Accuracy |   0.999898 |\n",
            "+----+----------------------+------------+\n",
            "|  2 | PGD Attack Accuracy  |   0.999898 |\n",
            "+----+----------------------+------------+\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**📈 Generate Bar Graph for Attack Performance**"
      ],
      "metadata": {
        "id": "nnxfcnTijV8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ✅ Plot adversarial accuracy comparison\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar([\"Clean\", \"FGSM\", \"PGD\"], [eval_results[\"clean_accuracy\"], eval_results[\"fgsm_accuracy\"], eval_results[\"pgd_accuracy\"]])\n",
        "plt.xlabel(\"Evaluation Scenario\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model Performance on Adversarial Attacks (FGSM & PGD)\")\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "HW-7fJM7jX5J",
        "outputId": "5eddb62c-5563-4b2b-8d6c-b2f5f02fe051"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNXW4jRklfTjNDJyy9v1UTc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}